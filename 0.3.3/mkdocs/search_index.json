{
    "docs": [
        {
            "location": "/", 
            "text": "Keras: Deep Learning library for Theano and TensorFlow\n\n\nYou have just found Keras.\n\n\nKeras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either \nTensorFlow\n or \nTheano\n. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n\n\nUse Keras if you need a deep learning library that:\n\n\n\n\nallows for easy and fast prototyping (through total modularity, minimalism, and extensibility).\n\n\nsupports both convolutional networks and recurrent networks, as well as combinations of the two.\n\n\nsupports arbitrary connectivity schemes (including multi-input and multi-output training).\n\n\nruns seamlessly on CPU and GPU.\n\n\n\n\nRead the documentation at \nKeras.io\n.\n\n\nKeras is compatible with: \nPython 2.7-3.5\n.\n\n\n\n\nGuiding principles\n\n\n\n\n\n\nModularity.\n A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n\n\n\n\n\n\nMinimalism.\n Each module should be kept short and simple. Every piece of code should be transparent upon first reading. No black magic: it hurts iteration speed and ability to innovate.\n\n\n\n\n\n\nEasy extensibility.\n New modules are dead simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.\n\n\n\n\n\n\nWork with Python\n. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.\n\n\n\n\n\n\n\n\nGetting started: 30 seconds to Keras\n\n\nThe core datastructure of Keras is a \nmodel\n, a way to organize layers. There are two types of models: \nSequential\n and \nGraph\n.\n\n\nHere's the \nSequential\n model (a linear pile of layers):\n\n\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\n\n\n\nStacking layers is as easy as \n.add()\n:\n\n\nfrom keras.layers.core import Dense, Activation\n\nmodel.add(Dense(output_dim=64, input_dim=100, init=\nglorot_uniform\n))\nmodel.add(Activation(\nrelu\n))\nmodel.add(Dense(output_dim=10, init=\nglorot_uniform\n))\nmodel.add(Activation(\nsoftmax\n))\n\n\n\n\nOnce your model looks good, configure its learning process with \n.compile()\n:\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd')\n\n\n\n\nIf you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n\n\nfrom keras.optimizers import SGD\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n\n\n\n\nYou can now iterate on your training data in batches:\n\n\nmodel.fit(X_train, Y_train, nb_epoch=5, batch_size=32)\n\n\n\n\nAlternatively, you can feed batches to your model manually:\n\n\nmodel.train_on_batch(X_batch, Y_batch)\n\n\n\n\nEvaluate your performance in one line:\n\n\nobjective_score = model.evaluate(X_test, Y_test, batch_size=32)\n\n\n\n\nOr generate predictions on new data:\n\n\nclasses = model.predict_classes(X_test, batch_size=32)\nproba = model.predict_proba(X_test, batch_size=32)\n\n\n\n\nBuilding a network of LSTMs, a deep CNN, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n\n\nHave a look at these \nstarter examples\n.\n\n\nIn the \nexamples folder\n of the repo, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, neural turing machines, etc.\n\n\n\n\nInstallation\n\n\nKeras uses the following dependencies:\n\n\n\n\nnumpy, scipy\n\n\npyyaml\n\n\nHDF5 and h5py (optional, required if you use model saving/loading functions)\n\n\nOptional but recommended if you use CNNs: cuDNN.\n\n\n\n\nWhen using the Theano backend:\n\n\n\n\nTheano\n\n\nSee installation instructions\n.\n\n\n\n\n\n\n\n\nNote\n: You should use the latest version of Theano, not the PyPI version. Install it with:\n\n\nsudo pip install git+git://github.com/Theano/Theano.git\n\n\n\n\nWhen using the TensorFlow backend:\n\n\n\n\nTensorFlow\n\n\nSee installation instructions\n.\n\n\n\n\n\n\n\n\nTo install Keras, \ncd\n to the Keras folder and run the install command:\n\n\nsudo python setup.py install\n\n\n\n\nYou can also install Keras from PyPI:\n\n\nsudo pip install keras\n\n\n\n\n\n\nSwitching from Theano to TensorFlow\n\n\nBy default, Keras will use Theano as its tensor manipulation library. \nFollow these instructions\n to configure the Keras backend.\n\n\n\n\nSupport\n\n\nYou can ask questions and join the development discussion on the \nKeras Google group\n.\n\n\nYou can also post bug reports and feature requests in \nGithub issues\n. Make sure to read \nour guidelines\n first.\n\n\n\n\nWhy this name, Keras?\n\n\nKeras (\u03ba\u03ad\u03c1\u03b1\u03c2) means \nhorn\n in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the \nOdyssey\n, where dream spirits (\nOneiroi\n, singular \nOneiros\n) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words \u03ba\u03ad\u03c1\u03b1\u03c2 (horn) / \u03ba\u03c1\u03b1\u03af\u03bd\u03c9 (fulfill), and \u1f10\u03bb\u03ad\u03c6\u03b1\u03c2 (ivory) / \u1f10\u03bb\u03b5\u03c6\u03b1\u03af\u03c1\u03bf\u03bc\u03b1\u03b9 (deceive).\n\n\nKeras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).\n\n\n\n\n\"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them.\"\n Homer, Odyssey 19. 562 ff (Shewring translation).", 
            "title": "Home"
        }, 
        {
            "location": "/#keras-deep-learning-library-for-theano-and-tensorflow", 
            "text": "", 
            "title": "Keras: Deep Learning library for Theano and TensorFlow"
        }, 
        {
            "location": "/#you-have-just-found-keras", 
            "text": "Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either  TensorFlow  or  Theano . It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.  Use Keras if you need a deep learning library that:   allows for easy and fast prototyping (through total modularity, minimalism, and extensibility).  supports both convolutional networks and recurrent networks, as well as combinations of the two.  supports arbitrary connectivity schemes (including multi-input and multi-output training).  runs seamlessly on CPU and GPU.   Read the documentation at  Keras.io .  Keras is compatible with:  Python 2.7-3.5 .", 
            "title": "You have just found Keras."
        }, 
        {
            "location": "/#guiding-principles", 
            "text": "Modularity.  A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.    Minimalism.  Each module should be kept short and simple. Every piece of code should be transparent upon first reading. No black magic: it hurts iteration speed and ability to innovate.    Easy extensibility.  New modules are dead simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.    Work with Python . No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.", 
            "title": "Guiding principles"
        }, 
        {
            "location": "/#getting-started-30-seconds-to-keras", 
            "text": "The core datastructure of Keras is a  model , a way to organize layers. There are two types of models:  Sequential  and  Graph .  Here's the  Sequential  model (a linear pile of layers):  from keras.models import Sequential\n\nmodel = Sequential()  Stacking layers is as easy as  .add() :  from keras.layers.core import Dense, Activation\n\nmodel.add(Dense(output_dim=64, input_dim=100, init= glorot_uniform ))\nmodel.add(Activation( relu ))\nmodel.add(Dense(output_dim=10, init= glorot_uniform ))\nmodel.add(Activation( softmax ))  Once your model looks good, configure its learning process with  .compile() :  model.compile(loss='categorical_crossentropy', optimizer='sgd')  If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).  from keras.optimizers import SGD\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))  You can now iterate on your training data in batches:  model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)  Alternatively, you can feed batches to your model manually:  model.train_on_batch(X_batch, Y_batch)  Evaluate your performance in one line:  objective_score = model.evaluate(X_test, Y_test, batch_size=32)  Or generate predictions on new data:  classes = model.predict_classes(X_test, batch_size=32)\nproba = model.predict_proba(X_test, batch_size=32)  Building a network of LSTMs, a deep CNN, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?  Have a look at these  starter examples .  In the  examples folder  of the repo, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, neural turing machines, etc.", 
            "title": "Getting started: 30 seconds to Keras"
        }, 
        {
            "location": "/#installation", 
            "text": "Keras uses the following dependencies:   numpy, scipy  pyyaml  HDF5 and h5py (optional, required if you use model saving/loading functions)  Optional but recommended if you use CNNs: cuDNN.   When using the Theano backend:   Theano  See installation instructions .     Note : You should use the latest version of Theano, not the PyPI version. Install it with:  sudo pip install git+git://github.com/Theano/Theano.git  When using the TensorFlow backend:   TensorFlow  See installation instructions .     To install Keras,  cd  to the Keras folder and run the install command:  sudo python setup.py install  You can also install Keras from PyPI:  sudo pip install keras", 
            "title": "Installation"
        }, 
        {
            "location": "/#switching-from-theano-to-tensorflow", 
            "text": "By default, Keras will use Theano as its tensor manipulation library.  Follow these instructions  to configure the Keras backend.", 
            "title": "Switching from Theano to TensorFlow"
        }, 
        {
            "location": "/#support", 
            "text": "You can ask questions and join the development discussion on the  Keras Google group .  You can also post bug reports and feature requests in  Github issues . Make sure to read  our guidelines  first.", 
            "title": "Support"
        }, 
        {
            "location": "/#why-this-name-keras", 
            "text": "Keras (\u03ba\u03ad\u03c1\u03b1\u03c2) means  horn  in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the  Odyssey , where dream spirits ( Oneiroi , singular  Oneiros ) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words \u03ba\u03ad\u03c1\u03b1\u03c2 (horn) / \u03ba\u03c1\u03b1\u03af\u03bd\u03c9 (fulfill), and \u1f10\u03bb\u03ad\u03c6\u03b1\u03c2 (ivory) / \u1f10\u03bb\u03b5\u03c6\u03b1\u03af\u03c1\u03bf\u03bc\u03b1\u03b9 (deceive).  Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).   \"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them.\"  Homer, Odyssey 19. 562 ff (Shewring translation).", 
            "title": "Why this name, Keras?"
        }, 
        {
            "location": "/documentation/", 
            "text": "Keras Documentation Index\n\n\nIntroduction\n\n\n\n\nHome\n\n\nIndex\n\n\nExamples\n\n\nFAQ\n\n\nBackend\n\n\n\n\n\n\nBase functionality\n\n\n\n\nOptimizers\n\n\nObjectives\n\n\nModels\n\n\nActivations\n\n\nInitializations\n\n\nRegularizers\n\n\nConstraints\n\n\nCallbacks\n\n\nDatasets\n\n\n\n\n\n\nLayers\n\n\n\n\nCore\n\n\nConvolutional\n\n\nRecurrent\n\n\nAdvanced Activations\n\n\nNormalization\n\n\nEmbeddings\n\n\n\n\n\n\nPreprocessing\n\n\n\n\nSequence\n\n\nText\n\n\nImage", 
            "title": "Index"
        }, 
        {
            "location": "/documentation/#keras-documentation-index", 
            "text": "", 
            "title": "Keras Documentation Index"
        }, 
        {
            "location": "/documentation/#introduction", 
            "text": "Home  Index  Examples  FAQ  Backend", 
            "title": "Introduction"
        }, 
        {
            "location": "/documentation/#base-functionality", 
            "text": "Optimizers  Objectives  Models  Activations  Initializations  Regularizers  Constraints  Callbacks  Datasets", 
            "title": "Base functionality"
        }, 
        {
            "location": "/documentation/#layers", 
            "text": "Core  Convolutional  Recurrent  Advanced Activations  Normalization  Embeddings", 
            "title": "Layers"
        }, 
        {
            "location": "/documentation/#preprocessing", 
            "text": "Sequence  Text  Image", 
            "title": "Preprocessing"
        }, 
        {
            "location": "/examples/", 
            "text": "Here are a few examples to get you started!\n\n\nIn the examples folder, you will also find example models for real datasets:\n\n\n\n\nCIFAR10 small images classification: Convolutional Neural Network (CNN) with realtime data augmentation\n\n\nIMDB movie review sentiment classification: LSTM over sequences of words\n\n\nReuters newswires topic classification: Multilayer Perceptron (MLP)\n\n\nMNIST handwritten digits classification: MLP \n CNN\n\n\nCharacter-level text generation with LSTM\n\n\n\n\n...and more.\n\n\n\n\nMultilayer Perceptron (MLP) for multi-class softmax classification:\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, input_dim=20, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd)\n\nmodel.fit(X_train, y_train,\n          nb_epoch=20,\n          batch_size=16,\n          show_accuracy=True)\nscore = model.evaluate(X_test, y_test, batch_size=16)\n\n\n\n\n\n\nAlternative implementation of a similar MLP:\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=20, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adadelta')\n\n\n\n\n\n\nMLP for binary classification:\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=20, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop')\n\n\n\n\n\n\nVGG-like convnet:\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# input: 100x100 images with 3 channels -\n (3, 100, 100) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='valid'))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# Note: Keras does automatic shape inference.\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(X_train, Y_train, batch_size=32, nb_epoch=1)\n\n\n\n\n\n\n\nSequence classification with LSTM:\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 256, input_length=maxlen))\nmodel.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop')\n\nmodel.fit(X_train, Y_train, batch_size=16, nb_epoch=10)\nscore = model.evaluate(X_test, Y_test, batch_size=16)\n\n\n\n\nArchitecture for learning image captions with a convnet and a Gated Recurrent Unit:\n\n\n(word-level embedding, caption of maximum length 16 words).\n\n\nNote that getting this to work well will require using a bigger convnet, initialized with pre-trained weights.\n\n\nmax_caption_len = 16\nvocab_size = 10000\n\n# first, let's define an image model that\n# will encode pictures into 128-dimensional vectors.\n# it should be initialized with pre-trained weights.\nimage_model = Sequential()\nimage_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(32, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(64, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Flatten())\nimage_model.add(Dense(128))\n\n# let's load the weights from a save file.\nimage_model.load_weights('weight_file.h5')\n\n# next, let's define a RNN model that encodes sequences of words\n# into sequences of 128-dimensional word vectors.\nlanguage_model = Sequential()\nlanguage_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\nlanguage_model.add(GRU(output_dim=128, return_sequences=True))\nlanguage_model.add(TimeDistributedDense(128))\n\n# let's repeat the image vector to turn it into a sequence.\nimage_model.add(RepeatVector(max_caption_len))\n\n# the output of both models will be tensors of shape (samples, max_caption_len, 128).\n# let's concatenate these 2 vector sequences.\nmodel = Sequential()\nmodel.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n# let's encode this vector sequence into a single vector\nmodel.add(GRU(256, return_sequences=False))\n# which will be used to compute a probability\n# distribution over what the next word in the caption should be!\nmodel.add(Dense(vocab_size))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# \nimages\n is a numpy float array of shape (nb_samples, nb_channels=3, width, height).\n# \ncaptions\n is a numpy integer array of shape (nb_samples, max_caption_len)\n# containing word index sequences representing partial captions.\n# \nnext_words\n is a numpy float array of shape (nb_samples, vocab_size)\n# containing a categorical encoding (0s and 1s) of the next word in the corresponding\n# partial caption.\nmodel.fit([images, partial_captions], next_words, batch_size=16, nb_epoch=100)\n\n\n\n\n\n\nStacked LSTM for sequence classification\n\n\nIn this model, we stack 3 LSTM layers on top of each other,\nmaking the model capable of learning higher-level temporal representations.\n\n\nThe first two LSTMs return their full output sequences, but the last one only returns\nthe last step in its output sequence, thus dropping the temporal dimension\n(i.e. converting the input sequence into a single vector).\n\n\n\n\n(N.B.: in Keras, \"None\" in an input shape indicates a variable dimension. In the graph above, the batch size is \"None\",\nmeaning that any batch size is allowed for the input data).\n\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True,\n               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32))  # return a single vector of dimension 32\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=64, nb_epoch=5, show_accuracy=True,\n          validation_data=(x_val, y_val))\n\n\n\n\n\n\nSame stacked LSTM model, rendered \"stateful\"\n\n\nA stateful recurrent model is one for which the internal states (memories) obtained after processing a batch\nof samples are reused as initial states for the samples of the next batch. This allows to process longer sequences\nwhile keeping computational complexity manageable.\n\n\nYou can read more about stateful RNNs in the FAQ.\n\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\nbatch_size = 32\n\n# expected input batch shape: (batch_size, timesteps, data_dim)\n# note that we have to provide the full batch_input_shape since the network is stateful.\n# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, stateful=True,\n               batch_input_shape=(batch_size, timesteps, data_dim)))\nmodel.add(LSTM(32, return_sequences=True, stateful=True))\nmodel.add(LSTM(32, stateful=True))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train = np.random.random((batch_size * 10, timesteps, data_dim))\ny_train = np.random.random((batch_size * 10, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((batch_size * 3, timesteps, data_dim))\ny_val = np.random.random((batch_size * 3, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size, nb_epoch=5, show_accuracy=True,\n          validation_data=(x_val, y_val))\n\n\n\n\n\n\nTwo merged LSTM encoders for classification over two parallel sequences\n\n\nIn this model, two input sequences are encoded into vectors by two separate LSTM modules.\n\n\nThese two vectors are then concatenated, and a fully connected network is trained on top of the concatenated representations.\n\n\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Merge, LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder_a = Sequential()\nencoder_a.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nencoder_b = Sequential()\nencoder_b.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\ndecoder = Sequential()\ndecoder.add(Merge([encoder_a, encoder_b], mode='concat'))\ndecoder.add(Dense(32, activation='relu'))\ndecoder.add(Dense(nb_classes, activation='softmax'))\n\ndecoder.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\ndecoder.fit([x_train_a, x_train_b], y_train,\n            batch_size=64, nb_epoch=5, show_accuracy=True,\n            validation_data=([x_val_a, x_val_b], y_val))\n\n\n\n\n\n\nSingle shared LSTM over two parallel sequences, for classification\n\n\nThis is a similar setup as above, but now a single LSTM encoder is used for both input sequences.\nSuch a setup makes sense if the two input sequences are the same type of object.\n\n\n\n\nfrom keras.models import Graph\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder = Sequential()\nencoder.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nmodel = Graph()\nmodel.add_input(name='input_a', input_shape=(timesteps, data_dim))\nmodel.add_input(name='input_b', input_shape=(timesteps, data_dim))\nmodel.add_shared_node(encoder, name='shared_encoder', inputs=['input_a', 'input_b'],\n                      merge_mode='concat')\nmodel.add_node(Dense(64, activation='relu'), name='fc1', input='shared_encoder')\nmodel.add_node(Dense(3, activation='softmax'), name='output', input='fc1', create_output=True)\n\nmodel.compile(optimizer='adam', loss={'output': 'categorical_crossentropy'})\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, 3))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, 3))\n\nmodel.fit({'input_a': x_train_a, 'input_b': x_train_b, 'output': y_train},\n          batch_size=64, nb_epoch=5,\n          validation_data={'input_a': x_val_a, 'input_b': x_val_b, 'output': y_val})", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#multilayer-perceptron-mlp-for-multi-class-softmax-classification", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, input_dim=20, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd)\n\nmodel.fit(X_train, y_train,\n          nb_epoch=20,\n          batch_size=16,\n          show_accuracy=True)\nscore = model.evaluate(X_test, y_test, batch_size=16)", 
            "title": "Multilayer Perceptron (MLP) for multi-class softmax classification:"
        }, 
        {
            "location": "/examples/#alternative-implementation-of-a-similar-mlp", 
            "text": "model = Sequential()\nmodel.add(Dense(64, input_dim=20, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adadelta')", 
            "title": "Alternative implementation of a similar MLP:"
        }, 
        {
            "location": "/examples/#mlp-for-binary-classification", 
            "text": "model = Sequential()\nmodel.add(Dense(64, input_dim=20, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop')", 
            "title": "MLP for binary classification:"
        }, 
        {
            "location": "/examples/#vgg-like-convnet", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# input: 100x100 images with 3 channels -  (3, 100, 100) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='valid'))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# Note: Keras does automatic shape inference.\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(X_train, Y_train, batch_size=32, nb_epoch=1)", 
            "title": "VGG-like convnet:"
        }, 
        {
            "location": "/examples/#sequence-classification-with-lstm", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 256, input_length=maxlen))\nmodel.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop')\n\nmodel.fit(X_train, Y_train, batch_size=16, nb_epoch=10)\nscore = model.evaluate(X_test, Y_test, batch_size=16)", 
            "title": "Sequence classification with LSTM:"
        }, 
        {
            "location": "/examples/#architecture-for-learning-image-captions-with-a-convnet-and-a-gated-recurrent-unit", 
            "text": "(word-level embedding, caption of maximum length 16 words).  Note that getting this to work well will require using a bigger convnet, initialized with pre-trained weights.  max_caption_len = 16\nvocab_size = 10000\n\n# first, let's define an image model that\n# will encode pictures into 128-dimensional vectors.\n# it should be initialized with pre-trained weights.\nimage_model = Sequential()\nimage_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(32, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(64, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Flatten())\nimage_model.add(Dense(128))\n\n# let's load the weights from a save file.\nimage_model.load_weights('weight_file.h5')\n\n# next, let's define a RNN model that encodes sequences of words\n# into sequences of 128-dimensional word vectors.\nlanguage_model = Sequential()\nlanguage_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\nlanguage_model.add(GRU(output_dim=128, return_sequences=True))\nlanguage_model.add(TimeDistributedDense(128))\n\n# let's repeat the image vector to turn it into a sequence.\nimage_model.add(RepeatVector(max_caption_len))\n\n# the output of both models will be tensors of shape (samples, max_caption_len, 128).\n# let's concatenate these 2 vector sequences.\nmodel = Sequential()\nmodel.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n# let's encode this vector sequence into a single vector\nmodel.add(GRU(256, return_sequences=False))\n# which will be used to compute a probability\n# distribution over what the next word in the caption should be!\nmodel.add(Dense(vocab_size))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n#  images  is a numpy float array of shape (nb_samples, nb_channels=3, width, height).\n#  captions  is a numpy integer array of shape (nb_samples, max_caption_len)\n# containing word index sequences representing partial captions.\n#  next_words  is a numpy float array of shape (nb_samples, vocab_size)\n# containing a categorical encoding (0s and 1s) of the next word in the corresponding\n# partial caption.\nmodel.fit([images, partial_captions], next_words, batch_size=16, nb_epoch=100)", 
            "title": "Architecture for learning image captions with a convnet and a Gated Recurrent Unit:"
        }, 
        {
            "location": "/examples/#stacked-lstm-for-sequence-classification", 
            "text": "In this model, we stack 3 LSTM layers on top of each other,\nmaking the model capable of learning higher-level temporal representations.  The first two LSTMs return their full output sequences, but the last one only returns\nthe last step in its output sequence, thus dropping the temporal dimension\n(i.e. converting the input sequence into a single vector).   (N.B.: in Keras, \"None\" in an input shape indicates a variable dimension. In the graph above, the batch size is \"None\",\nmeaning that any batch size is allowed for the input data).  from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True,\n               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32))  # return a single vector of dimension 32\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=64, nb_epoch=5, show_accuracy=True,\n          validation_data=(x_val, y_val))", 
            "title": "Stacked LSTM for sequence classification"
        }, 
        {
            "location": "/examples/#same-stacked-lstm-model-rendered-stateful", 
            "text": "A stateful recurrent model is one for which the internal states (memories) obtained after processing a batch\nof samples are reused as initial states for the samples of the next batch. This allows to process longer sequences\nwhile keeping computational complexity manageable.  You can read more about stateful RNNs in the FAQ.  from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\nbatch_size = 32\n\n# expected input batch shape: (batch_size, timesteps, data_dim)\n# note that we have to provide the full batch_input_shape since the network is stateful.\n# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, stateful=True,\n               batch_input_shape=(batch_size, timesteps, data_dim)))\nmodel.add(LSTM(32, return_sequences=True, stateful=True))\nmodel.add(LSTM(32, stateful=True))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train = np.random.random((batch_size * 10, timesteps, data_dim))\ny_train = np.random.random((batch_size * 10, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((batch_size * 3, timesteps, data_dim))\ny_val = np.random.random((batch_size * 3, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size, nb_epoch=5, show_accuracy=True,\n          validation_data=(x_val, y_val))", 
            "title": "Same stacked LSTM model, rendered \"stateful\""
        }, 
        {
            "location": "/examples/#two-merged-lstm-encoders-for-classification-over-two-parallel-sequences", 
            "text": "In this model, two input sequences are encoded into vectors by two separate LSTM modules.  These two vectors are then concatenated, and a fully connected network is trained on top of the concatenated representations.   from keras.models import Sequential\nfrom keras.layers import Merge, LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder_a = Sequential()\nencoder_a.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nencoder_b = Sequential()\nencoder_b.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\ndecoder = Sequential()\ndecoder.add(Merge([encoder_a, encoder_b], mode='concat'))\ndecoder.add(Dense(32, activation='relu'))\ndecoder.add(Dense(nb_classes, activation='softmax'))\n\ndecoder.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\ndecoder.fit([x_train_a, x_train_b], y_train,\n            batch_size=64, nb_epoch=5, show_accuracy=True,\n            validation_data=([x_val_a, x_val_b], y_val))", 
            "title": "Two merged LSTM encoders for classification over two parallel sequences"
        }, 
        {
            "location": "/examples/#single-shared-lstm-over-two-parallel-sequences-for-classification", 
            "text": "This is a similar setup as above, but now a single LSTM encoder is used for both input sequences.\nSuch a setup makes sense if the two input sequences are the same type of object.   from keras.models import Graph\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder = Sequential()\nencoder.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nmodel = Graph()\nmodel.add_input(name='input_a', input_shape=(timesteps, data_dim))\nmodel.add_input(name='input_b', input_shape=(timesteps, data_dim))\nmodel.add_shared_node(encoder, name='shared_encoder', inputs=['input_a', 'input_b'],\n                      merge_mode='concat')\nmodel.add_node(Dense(64, activation='relu'), name='fc1', input='shared_encoder')\nmodel.add_node(Dense(3, activation='softmax'), name='output', input='fc1', create_output=True)\n\nmodel.compile(optimizer='adam', loss={'output': 'categorical_crossentropy'})\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, 3))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, 3))\n\nmodel.fit({'input_a': x_train_a, 'input_b': x_train_b, 'output': y_train},\n          batch_size=64, nb_epoch=5,\n          validation_data={'input_a': x_val_a, 'input_b': x_val_b, 'output': y_val})", 
            "title": "Single shared LSTM over two parallel sequences, for classification"
        }, 
        {
            "location": "/faq/", 
            "text": "Keras FAQ: Frequently Asked Keras Questions\n\n\nHow should I cite Keras?\n\n\nHow can I run Keras on GPU?\n\n\nHow can I save a Keras model?\n\n\nWhy is the training loss much higher than the testing loss?\n\n\nHow can I visualize the output of an intermediate layer?\n\n\nHow can I use Keras with datasets that don't fit in memory?\n\n\nHow can I interrupt training when the validation loss isn't decreasing anymore?\n\n\nHow is the validation split computed?\n\n\nIs the data shuffled during training?\n\n\nHow can I record the training / validation loss / accuracy at each epoch?\n\n\nHow can I use stateful RNNs?\n\n\n\n\nHow should I cite Keras?\n\n\nPlease cite Keras in your publications if it helps your research. Here is an example BibTeX entry:\n\n\n@misc{chollet2015keras,\n  author = {Chollet, Fran\u00e7ois},\n  title = {Keras},\n  year = {2015},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/fchollet/keras}}\n}\n\n\n\n\nHow can I run Keras on GPU?\n\n\nIf you are running on the TensorFlow backend, your code will automatically run on GPU if any available GPU is detected.\nIf you are running on the Theano backend, you can use one of the following methods:\n\n\nMethod 1: use Theano flags.\n\n\nTHEANO_FLAGS=device=gpu,floatX=float32 python my_keras_script.py\n\n\n\n\nThe name 'gpu' might have to be changed depending on your device's identifier (e.g. \ngpu0\n, \ngpu1\n, etc).\n\n\nMethod 2: set up your \n.theanorc\n: \nInstructions\n\n\nMethod 3: manually set \ntheano.config.device\n, \ntheano.config.floatX\n at the beginning of your code:\n\n\nimport theano\ntheano.config.device = 'gpu'\ntheano.config.floatX = 'float32'\n\n\n\n\n\n\nHow can I save a Keras model?\n\n\nIt is not recommended to use pickle or cPickle to save a Keras model.\n\n\nIf you only need to save the architecture of a model, and not its weights, you can do:\n\n\n# save as JSON\njson_string = model.to_json()\n\n# save as YAML\nyaml_string = model.to_yaml()\n\n\n\n\nYou can then build a fresh model from this data:\n\n\n# model reconstruction from JSON:\nfrom keras.models import model_from_json\nmodel = model_from_json(json_string)\n\n# model reconstruction from YAML\nmodel = model_from_yaml(yaml_string)\n\n\n\n\nIf you need to save the weights of a model, you can do so in HDF5 with the code below.\n\n\nNote that you will first need to install HDF5 and the Python library h5py, which do not come bundled with Keras.\n\n\nmodel.save_weights('my_model_weights.h5')\n\n\n\n\nAssuming you have code for instantiating your model, you can then load the weights you saved into a model with the same architecture:\n\n\nmodel.load_weights('my_model_weights.h5')\n\n\n\n\nThis leads us to a way to save and reconstruct models from only serialized data:\n\n\njson_string = model.to_json()\nopen('my_model_architecture.json', 'w').write(json_string)\nmodel.save_weights('my_model_weights.h5')\n\n# elsewhere...\nmodel = model_from_json(open('my_model_architecture.json').read())\nmodel.load_weights('my_model_weights.h5')\n\n\n\n\n\n\nWhy is the training loss much higher than the testing loss?\n\n\nA Keras model has two modes: training and testing. Regularization mechanisms, such as Dropout and L1/L2 weight regularization, are turned off at testing time.\n\n\nBesides, the training loss is the average of the losses over each batch of training data. Because your model is changing over time, the loss over the first batches of an epoch is generally higher than over the last batches. On the other hand, the testing loss for an epoch is computed using the model as it is at the end of the epoch, resulting in a lower loss.\n\n\n\n\nHow can I visualize the output of an intermediate layer?\n\n\nYou can build a Keras function that will return the output of a certain layer given a certain input, for example:\n\n\nfrom keras import backend as K\n\n# with a Sequential model\nget_3rd_layer_output = K.function([model.layers[0].input],\n                                  [model.layers[3].get_output(train=False)])\nlayer_output = get_3rd_layer_output([X])[0]\n\n# with a Graph model\nget_conv_layer_output = K.function([model.inputs[i].input for i in model.input_order],\n                                   [model.nodes['conv'].get_output(train=False)])\nconv_output = get_conv_layer_output([input_data_dict[i] for i in model.input_order])[0]\n\n\n\n\nSimilarly, you could build a Theano and TensorFlow function directly.\n\n\n\n\nHow can I use Keras with datasets that don't fit in memory?\n\n\nYou can do batch training using \nmodel.train_on_batch(X, y)\n and \nmodel.test_on_batch(X, y)\n. See the \nmodels documentation\n.\n\n\nAlternatively, you can write a generator that yields batches of training data and use the method \nmodel.fit_generator(data_generator, samples_per_epoch, nb_epoch)\n.\n\n\nYou can see batch training in action in our \nCIFAR10 example\n.\n\n\n\n\nHow can I interrupt training when the validation loss isn't decreasing anymore?\n\n\nYou can use an \nEarlyStopping\n callback:\n\n\nfrom keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\nmodel.fit(X, y, validation_split=0.2, callbacks=[early_stopping])\n\n\n\n\nFind out more in the \ncallbacks documentation\n.\n\n\n\n\nHow is the validation split computed?\n\n\nIf you set the \nvalidation_split\n argument in \nmodel.fit\n to e.g. 0.1, then the validation data used will be the \nlast 10%\n of the data. If you set it to 0.25, it will be the last 25% of the data, etc.\n\n\n\n\nIs the data shuffled during training?\n\n\nYes, if the \nshuffle\n argument in \nmodel.fit\n is set to \nTrue\n (which is the default), the training data will be randomly shuffled at each epoch.\n\n\nValidation data isn't shuffled.\n\n\n\n\nHow can I record the training / validation loss / accuracy at each epoch?\n\n\nThe \nmodel.fit\n method returns an \nHistory\n callback, which has a \nhistory\n attribute containing the lists of successive losses / accuracies.\n\n\nhist = model.fit(X, y, validation_split=0.2)\nprint(hist.history)\n\n\n\n\n\n\nHow can I use stateful RNNs?\n\n\nMaking a RNN stateful means that the states for the samples of each batch will be reused as initial states for the samples in the next batch.\n\n\nWhen using stateful RNNs, it is therefore assumed that:\n\n\n\n\nall batches have the same number of samples\n\n\nIf \nX1\n and \nX2\n are successive batches of samples, then \nX2[i]\n is the follow-up sequence to \nX1[i]\n, for every \ni\n.\n\n\n\n\nTo use statefulness in RNNs, you need to:\n\n\n\n\nexplicitly specify the batch size you are using, by passing a \nbatch_input_shape\n argument to the first layer in your model. It should be a tuple of integers, e.g. \n(32, 10, 16)\n for a 32-samples batch of sequences of 10 timesteps with 16 features per timestep.\n\n\nset \nstateful=True\n in your RNN layer(s).\n\n\n\n\nTo reset the states accumulated:\n\n\n\n\nuse \nmodel.reset_states()\n to reset the states of all layers in the model\n\n\nuse \nlayer.reset_states()\n to reset the states of a specific stateful RNN layer\n\n\n\n\nExample:\n\n\n\nX  # this is our input data, of shape (32, 21, 16)\n# we will feed it to our model in sequences of length 10\n\nmodel = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(32, 10, 16), stateful=True))\nmodel.add(Dense(16, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# we train the network to predict the 11th timestep given the first 10:\nmodel.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n\n# the state of the network has changed. We can feed the follow-up sequences:\nmodel.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n\n# let's reset the states of the LSTM layer:\nmodel.reset_states()\n\n# another way to do it in this case:\nmodel.layers[0].reset_states()\n\n\n\n\nNotes that the methods \npredict\n, \nfit\n, \ntrain_on_batch\n, \npredict_classes\n, etc. will \nall\n update the states of the stateful layers in a model. This allows you to do not only stateful training, but also stateful prediction.", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/#keras-faq-frequently-asked-keras-questions", 
            "text": "How should I cite Keras?  How can I run Keras on GPU?  How can I save a Keras model?  Why is the training loss much higher than the testing loss?  How can I visualize the output of an intermediate layer?  How can I use Keras with datasets that don't fit in memory?  How can I interrupt training when the validation loss isn't decreasing anymore?  How is the validation split computed?  Is the data shuffled during training?  How can I record the training / validation loss / accuracy at each epoch?  How can I use stateful RNNs?", 
            "title": "Keras FAQ: Frequently Asked Keras Questions"
        }, 
        {
            "location": "/faq/#how-should-i-cite-keras", 
            "text": "Please cite Keras in your publications if it helps your research. Here is an example BibTeX entry:  @misc{chollet2015keras,\n  author = {Chollet, Fran\u00e7ois},\n  title = {Keras},\n  year = {2015},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/fchollet/keras}}\n}", 
            "title": "How should I cite Keras?"
        }, 
        {
            "location": "/faq/#how-can-i-run-keras-on-gpu", 
            "text": "If you are running on the TensorFlow backend, your code will automatically run on GPU if any available GPU is detected.\nIf you are running on the Theano backend, you can use one of the following methods:  Method 1: use Theano flags.  THEANO_FLAGS=device=gpu,floatX=float32 python my_keras_script.py  The name 'gpu' might have to be changed depending on your device's identifier (e.g.  gpu0 ,  gpu1 , etc).  Method 2: set up your  .theanorc :  Instructions  Method 3: manually set  theano.config.device ,  theano.config.floatX  at the beginning of your code:  import theano\ntheano.config.device = 'gpu'\ntheano.config.floatX = 'float32'", 
            "title": "How can I run Keras on GPU?"
        }, 
        {
            "location": "/faq/#how-can-i-save-a-keras-model", 
            "text": "It is not recommended to use pickle or cPickle to save a Keras model.  If you only need to save the architecture of a model, and not its weights, you can do:  # save as JSON\njson_string = model.to_json()\n\n# save as YAML\nyaml_string = model.to_yaml()  You can then build a fresh model from this data:  # model reconstruction from JSON:\nfrom keras.models import model_from_json\nmodel = model_from_json(json_string)\n\n# model reconstruction from YAML\nmodel = model_from_yaml(yaml_string)  If you need to save the weights of a model, you can do so in HDF5 with the code below.  Note that you will first need to install HDF5 and the Python library h5py, which do not come bundled with Keras.  model.save_weights('my_model_weights.h5')  Assuming you have code for instantiating your model, you can then load the weights you saved into a model with the same architecture:  model.load_weights('my_model_weights.h5')  This leads us to a way to save and reconstruct models from only serialized data:  json_string = model.to_json()\nopen('my_model_architecture.json', 'w').write(json_string)\nmodel.save_weights('my_model_weights.h5')\n\n# elsewhere...\nmodel = model_from_json(open('my_model_architecture.json').read())\nmodel.load_weights('my_model_weights.h5')", 
            "title": "How can I save a Keras model?"
        }, 
        {
            "location": "/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss", 
            "text": "A Keras model has two modes: training and testing. Regularization mechanisms, such as Dropout and L1/L2 weight regularization, are turned off at testing time.  Besides, the training loss is the average of the losses over each batch of training data. Because your model is changing over time, the loss over the first batches of an epoch is generally higher than over the last batches. On the other hand, the testing loss for an epoch is computed using the model as it is at the end of the epoch, resulting in a lower loss.", 
            "title": "Why is the training loss much higher than the testing loss?"
        }, 
        {
            "location": "/faq/#how-can-i-visualize-the-output-of-an-intermediate-layer", 
            "text": "You can build a Keras function that will return the output of a certain layer given a certain input, for example:  from keras import backend as K\n\n# with a Sequential model\nget_3rd_layer_output = K.function([model.layers[0].input],\n                                  [model.layers[3].get_output(train=False)])\nlayer_output = get_3rd_layer_output([X])[0]\n\n# with a Graph model\nget_conv_layer_output = K.function([model.inputs[i].input for i in model.input_order],\n                                   [model.nodes['conv'].get_output(train=False)])\nconv_output = get_conv_layer_output([input_data_dict[i] for i in model.input_order])[0]  Similarly, you could build a Theano and TensorFlow function directly.", 
            "title": "How can I visualize the output of an intermediate layer?"
        }, 
        {
            "location": "/faq/#how-can-i-use-keras-with-datasets-that-dont-fit-in-memory", 
            "text": "You can do batch training using  model.train_on_batch(X, y)  and  model.test_on_batch(X, y) . See the  models documentation .  Alternatively, you can write a generator that yields batches of training data and use the method  model.fit_generator(data_generator, samples_per_epoch, nb_epoch) .  You can see batch training in action in our  CIFAR10 example .", 
            "title": "How can I use Keras with datasets that don't fit in memory?"
        }, 
        {
            "location": "/faq/#how-can-i-interrupt-training-when-the-validation-loss-isnt-decreasing-anymore", 
            "text": "You can use an  EarlyStopping  callback:  from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\nmodel.fit(X, y, validation_split=0.2, callbacks=[early_stopping])  Find out more in the  callbacks documentation .", 
            "title": "How can I interrupt training when the validation loss isn't decreasing anymore?"
        }, 
        {
            "location": "/faq/#how-is-the-validation-split-computed", 
            "text": "If you set the  validation_split  argument in  model.fit  to e.g. 0.1, then the validation data used will be the  last 10%  of the data. If you set it to 0.25, it will be the last 25% of the data, etc.", 
            "title": "How is the validation split computed?"
        }, 
        {
            "location": "/faq/#is-the-data-shuffled-during-training", 
            "text": "Yes, if the  shuffle  argument in  model.fit  is set to  True  (which is the default), the training data will be randomly shuffled at each epoch.  Validation data isn't shuffled.", 
            "title": "Is the data shuffled during training?"
        }, 
        {
            "location": "/faq/#how-can-i-record-the-training-validation-loss-accuracy-at-each-epoch", 
            "text": "The  model.fit  method returns an  History  callback, which has a  history  attribute containing the lists of successive losses / accuracies.  hist = model.fit(X, y, validation_split=0.2)\nprint(hist.history)", 
            "title": "How can I record the training / validation loss / accuracy at each epoch?"
        }, 
        {
            "location": "/faq/#how-can-i-use-stateful-rnns", 
            "text": "Making a RNN stateful means that the states for the samples of each batch will be reused as initial states for the samples in the next batch.  When using stateful RNNs, it is therefore assumed that:   all batches have the same number of samples  If  X1  and  X2  are successive batches of samples, then  X2[i]  is the follow-up sequence to  X1[i] , for every  i .   To use statefulness in RNNs, you need to:   explicitly specify the batch size you are using, by passing a  batch_input_shape  argument to the first layer in your model. It should be a tuple of integers, e.g.  (32, 10, 16)  for a 32-samples batch of sequences of 10 timesteps with 16 features per timestep.  set  stateful=True  in your RNN layer(s).   To reset the states accumulated:   use  model.reset_states()  to reset the states of all layers in the model  use  layer.reset_states()  to reset the states of a specific stateful RNN layer   Example:  \nX  # this is our input data, of shape (32, 21, 16)\n# we will feed it to our model in sequences of length 10\n\nmodel = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(32, 10, 16), stateful=True))\nmodel.add(Dense(16, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# we train the network to predict the 11th timestep given the first 10:\nmodel.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n\n# the state of the network has changed. We can feed the follow-up sequences:\nmodel.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n\n# let's reset the states of the LSTM layer:\nmodel.reset_states()\n\n# another way to do it in this case:\nmodel.layers[0].reset_states()  Notes that the methods  predict ,  fit ,  train_on_batch ,  predict_classes , etc. will  all  update the states of the stateful layers in a model. This allows you to do not only stateful training, but also stateful prediction.", 
            "title": "How can I use stateful RNNs?"
        }, 
        {
            "location": "/backend/", 
            "text": "Keras backends\n\n\nWhat is a \"backend\"?\n\n\nKeras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle itself low-level operations such as tensor products, convolutions and so on. Instead, it relies on a specialized, well-optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n\n\nAt this time, Keras has two backend implementations available: the \nTheano\n backend and the \nTensorFlow\n backend.\n\n\n\n\nTheano\n is an open-source symbolic tensor manipulation framework developed by LISA/MILA Lab at Universit\u00e9 de Montr\u00e9al.\n\n\nTensorFlow\n is an open-source symbolic tensor manipulation framework developed by Google, Inc.\n\n\n\n\nSwitching from one backend to another\n\n\nIf you have run Keras at least once, you will find the Keras configuration file at:\n\n\n~/.keras/keras.json\n\n\nIf it isn't there, you can create it.\n\n\nIt probably looks like this:\n\n\n{\"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"theano\"}\n\n\nSimply change the field \nbackend\n to either \n\"theano\"\n or \n\"tensorflow\"\n, and Keras will use the new configuration next time you run any Keras code.\n\n\nYou can also define the environment variable \nKERAS_BACKEND\n and this will\noverride what is defined in your config file :\n\n\nKERAS_BACKEND=tensorflow python -c \nfrom keras import backend; print backend._BACKEND\n\nUsing TensorFlow backend.\ntensorflow\n\n\n\n\nUsing the abstract Keras backend to write new code\n\n\nIf you want the Keras modules you write to be compatible with both Theano and TensorFlow, you have to write them via the abstract Keras backend API. Here's an intro.\n\n\nYou can import the backend module via:\n\n\nfrom keras import backend as K\n\n\n\n\nThe code below instantiates an input placeholder. It's equivalent to \ntf.placeholder()\n or \nT.matrix()\n, \nT.tensor3()\n, etc.\n\n\ninput = K.placeholder(shape=(2, 4, 5))\n# also works:\ninput = K.placeholder(shape=(None, 4, 5))\n# also works:\ninput = K.placeholder(ndim=3)\n\n\n\n\nThe code below instantiates a shared variable. It's equivalent to \ntf.variable()\n or \ntheano.shared()\n.\n\n\nval = np.random.random((3, 4, 5))\nvar = K.variable(value=val)\n\n# all-zeros variable:\nvar = K.zeros(shape=(3, 4, 5))\n# all-ones:\nvar = K.ones(shape=(3, 4, 5))\n\n\n\n\nMost tensor operations you will need can be done as you would in TensorFlow or Theano:\n\n\na = b + c * K.abs(d)\nc = K.dot(a, K.transpose(b))\na = K.sum(b, axis=2)\na = K.softmax(b)\na = concatenate([b, c], axis=-1)\n# etc...\n\n\n\n\nFor more information, see the code at \nkeras/backend/theano_backend.py\n and \nkeras/backend/tensorflow_backend.py\n.", 
            "title": "Backends"
        }, 
        {
            "location": "/backend/#keras-backends", 
            "text": "", 
            "title": "Keras backends"
        }, 
        {
            "location": "/backend/#what-is-a-backend", 
            "text": "Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle itself low-level operations such as tensor products, convolutions and so on. Instead, it relies on a specialized, well-optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.  At this time, Keras has two backend implementations available: the  Theano  backend and the  TensorFlow  backend.   Theano  is an open-source symbolic tensor manipulation framework developed by LISA/MILA Lab at Universit\u00e9 de Montr\u00e9al.  TensorFlow  is an open-source symbolic tensor manipulation framework developed by Google, Inc.", 
            "title": "What is a \"backend\"?"
        }, 
        {
            "location": "/backend/#switching-from-one-backend-to-another", 
            "text": "If you have run Keras at least once, you will find the Keras configuration file at:  ~/.keras/keras.json  If it isn't there, you can create it.  It probably looks like this:  {\"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"theano\"}  Simply change the field  backend  to either  \"theano\"  or  \"tensorflow\" , and Keras will use the new configuration next time you run any Keras code.  You can also define the environment variable  KERAS_BACKEND  and this will\noverride what is defined in your config file :  KERAS_BACKEND=tensorflow python -c  from keras import backend; print backend._BACKEND \nUsing TensorFlow backend.\ntensorflow", 
            "title": "Switching from one backend to another"
        }, 
        {
            "location": "/backend/#using-the-abstract-keras-backend-to-write-new-code", 
            "text": "If you want the Keras modules you write to be compatible with both Theano and TensorFlow, you have to write them via the abstract Keras backend API. Here's an intro.  You can import the backend module via:  from keras import backend as K  The code below instantiates an input placeholder. It's equivalent to  tf.placeholder()  or  T.matrix() ,  T.tensor3() , etc.  input = K.placeholder(shape=(2, 4, 5))\n# also works:\ninput = K.placeholder(shape=(None, 4, 5))\n# also works:\ninput = K.placeholder(ndim=3)  The code below instantiates a shared variable. It's equivalent to  tf.variable()  or  theano.shared() .  val = np.random.random((3, 4, 5))\nvar = K.variable(value=val)\n\n# all-zeros variable:\nvar = K.zeros(shape=(3, 4, 5))\n# all-ones:\nvar = K.ones(shape=(3, 4, 5))  Most tensor operations you will need can be done as you would in TensorFlow or Theano:  a = b + c * K.abs(d)\nc = K.dot(a, K.transpose(b))\na = K.sum(b, axis=2)\na = K.softmax(b)\na = concatenate([b, c], axis=-1)\n# etc...  For more information, see the code at  keras/backend/theano_backend.py  and  keras/backend/tensorflow_backend.py .", 
            "title": "Using the abstract Keras backend to write new code"
        }, 
        {
            "location": "/optimizers/", 
            "text": "Usage of optimizers\n\n\nAn optimizer is one of the two arguments required for compiling a Keras model:\n\n\nmodel = Sequential()\nmodel.add(Dense(64, init='uniform', input_dim=10))\nmodel.add(Activation('tanh'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\n\n\n\n\nYou can either instantiate an optimizer before passing it to \nmodel.compile()\n , as in the above example, or you can call it by its name. In the latter case, the default parameters for the optimizer will be used.\n\n\n# pass optimizer by name: default parameters will be used\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\n\n\n[source]\n\n\nOptimizer\n\n\nkeras.optimizers.Optimizer()\n\n\n\n\nAbstract optimizer base class.\n\n\n\n\nNote\n: this is the parent class of all optimizers, not an actual optimizer\nthat can be used for training models.\n\n\n\n\nAll Keras optimizers support the following keyword arguments:\n\n\n\n\nclipnorm\n: float \n= 0. Gradients will be clipped\n    when their L2 norm exceeds this value.\n\n\nclipvalue\n: float \n= 0. Gradients will be clipped\n    when their absolute value exceeds this value.\n\n\n\n\n\n\n[source]\n\n\nSGD\n\n\nkeras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n\n\n\n\nStochastic gradient descent, with support for momentum,\ndecay, and Nesterov momentum.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate.\n\n\nmomentum\n: float \n= 0. Parameter updates momentum.\n\n\ndecay\n: float \n= 0. Learning rate decay over each update.\n\n\nnesterov\n: boolean. Whether to apply Nesterov momentum.\n\n\n\n\n\n\n[source]\n\n\nRMSprop\n\n\nkeras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n\n\n\n\nRMSProp optimizer.\n\n\nIt is recommended to leave the parameters of this optimizer\nat their default values.\n\n\nThis optimizer is usually a good choice for recurrent\nneural networks.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate.\n\n\nrho\n: float \n= 0.\n\n\nepsilon\n: float \n= 0. Fuzz factor.\n\n\n\n\n\n\n[source]\n\n\nAdagrad\n\n\nkeras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)\n\n\n\n\nAdagrad optimizer.\n\n\nIt is recommended to leave the parameters of this optimizer\nat their default values.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate.\n\n\nepsilon\n: float \n= 0.\n\n\n\n\n\n\n[source]\n\n\nAdadelta\n\n\nkeras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n\n\n\n\nAdadelta optimizer.\n\n\nIt is recommended to leave the parameters of this optimizer\nat their default values.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate. It is recommended to leave it at the default value.\n\n\nrho\n: float \n= 0.\n\n\nepsilon\n: float \n= 0. Fuzz factor.\n\n\n\n\nReferences\n\n\n\n\nAdadelta - an adaptive learning rate method\n\n\n\n\n\n\n[source]\n\n\nAdam\n\n\nkeras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n\n\n\nAdam optimizer.\n\n\nDefault parameters follow those provided in the original paper.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate.\n\n\nbeta_1/beta_2\n: floats, 0 \n beta \n 1. Generally close to 1.\n\n\nepsilon\n: float \n= 0. Fuzz factor.\n\n\n\n\nReferences\n\n\n\n\nAdam - A Method for Stochastic Optimization\n\n\n\n\n\n\n[source]\n\n\nAdamax\n\n\nkeras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n\n\n\nAdamax optimizer from Adam paper's Section 7. It is a variant\n of Adam based on the infinity norm.\n\n\nDefault parameters follow those provided in the paper.\n\n\nArguments\n\n\n\n\nlr\n: float \n= 0. Learning rate.\n\n\nbeta_1/beta_2\n: floats, 0 \n beta \n 1. Generally close to 1.\n\n\nepsilon\n: float \n= 0. Fuzz factor.\n\n\n\n\nReferences\n\n\n\n\nAdam - A Method for Stochastic Optimization", 
            "title": "Optimizers"
        }, 
        {
            "location": "/optimizers/#usage-of-optimizers", 
            "text": "An optimizer is one of the two arguments required for compiling a Keras model:  model = Sequential()\nmodel.add(Dense(64, init='uniform', input_dim=10))\nmodel.add(Activation('tanh'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)  You can either instantiate an optimizer before passing it to  model.compile()  , as in the above example, or you can call it by its name. In the latter case, the default parameters for the optimizer will be used.  # pass optimizer by name: default parameters will be used\nmodel.compile(loss='mean_squared_error', optimizer='sgd')   [source]", 
            "title": "Usage of optimizers"
        }, 
        {
            "location": "/optimizers/#optimizer", 
            "text": "keras.optimizers.Optimizer()  Abstract optimizer base class.   Note : this is the parent class of all optimizers, not an actual optimizer\nthat can be used for training models.   All Keras optimizers support the following keyword arguments:   clipnorm : float  = 0. Gradients will be clipped\n    when their L2 norm exceeds this value.  clipvalue : float  = 0. Gradients will be clipped\n    when their absolute value exceeds this value.    [source]", 
            "title": "Optimizer"
        }, 
        {
            "location": "/optimizers/#sgd", 
            "text": "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)  Stochastic gradient descent, with support for momentum,\ndecay, and Nesterov momentum.  Arguments   lr : float  = 0. Learning rate.  momentum : float  = 0. Parameter updates momentum.  decay : float  = 0. Learning rate decay over each update.  nesterov : boolean. Whether to apply Nesterov momentum.    [source]", 
            "title": "SGD"
        }, 
        {
            "location": "/optimizers/#rmsprop", 
            "text": "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)  RMSProp optimizer.  It is recommended to leave the parameters of this optimizer\nat their default values.  This optimizer is usually a good choice for recurrent\nneural networks.  Arguments   lr : float  = 0. Learning rate.  rho : float  = 0.  epsilon : float  = 0. Fuzz factor.    [source]", 
            "title": "RMSprop"
        }, 
        {
            "location": "/optimizers/#adagrad", 
            "text": "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)  Adagrad optimizer.  It is recommended to leave the parameters of this optimizer\nat their default values.  Arguments   lr : float  = 0. Learning rate.  epsilon : float  = 0.    [source]", 
            "title": "Adagrad"
        }, 
        {
            "location": "/optimizers/#adadelta", 
            "text": "keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)  Adadelta optimizer.  It is recommended to leave the parameters of this optimizer\nat their default values.  Arguments   lr : float  = 0. Learning rate. It is recommended to leave it at the default value.  rho : float  = 0.  epsilon : float  = 0. Fuzz factor.   References   Adadelta - an adaptive learning rate method    [source]", 
            "title": "Adadelta"
        }, 
        {
            "location": "/optimizers/#adam", 
            "text": "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)  Adam optimizer.  Default parameters follow those provided in the original paper.  Arguments   lr : float  = 0. Learning rate.  beta_1/beta_2 : floats, 0   beta   1. Generally close to 1.  epsilon : float  = 0. Fuzz factor.   References   Adam - A Method for Stochastic Optimization    [source]", 
            "title": "Adam"
        }, 
        {
            "location": "/optimizers/#adamax", 
            "text": "keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)  Adamax optimizer from Adam paper's Section 7. It is a variant\n of Adam based on the infinity norm.  Default parameters follow those provided in the paper.  Arguments   lr : float  = 0. Learning rate.  beta_1/beta_2 : floats, 0   beta   1. Generally close to 1.  epsilon : float  = 0. Fuzz factor.   References   Adam - A Method for Stochastic Optimization", 
            "title": "Adamax"
        }, 
        {
            "location": "/objectives/", 
            "text": "Usage of objectives\n\n\nAn objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\nYou can either pass the name of an existing objective, or pass a Theano/TensorFlow symbolic function that returns a scalar for each data-point and takes the following two arguments:\n\n\n\n\ny_true\n: True labels. Theano/TensorFlow tensor.\n\n\ny_pred\n: Predictions. Theano/TensorFlow tensor of the same shape as y_true.\n\n\n\n\nThe actual optimized objective is the mean of the output array across all datapoints.\n\n\nFor a few examples of such functions, check out the \nobjectives source\n.\n\n\nAvailable objectives\n\n\n\n\nmean_squared_error\n / \nmse\n\n\nmean_absolute_error\n / \nmae\n\n\nmean_absolute_percentage_error\n / \nmape\n\n\nmean_squared_logarithmic_error\n / \nmsle\n\n\nsquared_hinge\n\n\nhinge\n\n\nbinary_crossentropy\n: Also known as logloss. \n\n\ncategorical_crossentropy\n: Also known as multiclass logloss. \nNote\n: using this objective requires that your labels are binary arrays of shape \n(nb_samples, nb_classes)\n.\n\n\npoisson\n: mean of \n(predictions - targets * log(predictions))\n\n\ncosine_proximity\n: the opposite (negative) of the mean cosine proximity between predictions and targets.", 
            "title": "Objectives"
        }, 
        {
            "location": "/objectives/#usage-of-objectives", 
            "text": "An objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:  model.compile(loss='mean_squared_error', optimizer='sgd')  You can either pass the name of an existing objective, or pass a Theano/TensorFlow symbolic function that returns a scalar for each data-point and takes the following two arguments:   y_true : True labels. Theano/TensorFlow tensor.  y_pred : Predictions. Theano/TensorFlow tensor of the same shape as y_true.   The actual optimized objective is the mean of the output array across all datapoints.  For a few examples of such functions, check out the  objectives source .", 
            "title": "Usage of objectives"
        }, 
        {
            "location": "/objectives/#available-objectives", 
            "text": "mean_squared_error  /  mse  mean_absolute_error  /  mae  mean_absolute_percentage_error  /  mape  mean_squared_logarithmic_error  /  msle  squared_hinge  hinge  binary_crossentropy : Also known as logloss.   categorical_crossentropy : Also known as multiclass logloss.  Note : using this objective requires that your labels are binary arrays of shape  (nb_samples, nb_classes) .  poisson : mean of  (predictions - targets * log(predictions))  cosine_proximity : the opposite (negative) of the mean cosine proximity between predictions and targets.", 
            "title": "Available objectives"
        }, 
        {
            "location": "/models/", 
            "text": "Keras has two models: \nSequential\n, a linear stack of layers, and \nGraph\n, a directed acyclic graph of layers.\n\n\nUsing the Sequential model\n\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(2, init='uniform', input_dim=64))\nmodel.add(Activation('softmax'))\n\nmodel.compile(optimizer='sgd', loss='mse')\n\n'''\nTrain the model for 3 epochs, in batches of 16 samples,\non data stored in the Numpy array X_train,\nand labels stored in the Numpy array y_train:\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=1)\n'''\nWhat you will see with mode verbose=1:\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\n37800/37800 [==============================] - 7s - loss: 0.0385\nEpoch 1\n37800/37800 [==============================] - 8s - loss: 0.0140\nEpoch 2\n10960/37800 [=======\n......................] - ETA: 4s - loss: 0.0109\n'''\n\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=2)\n'''\nWhat you will see with mode verbose=2:\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\nloss: 0.0190\nEpoch 1\nloss: 0.0146\nEpoch 2\nloss: 0.0049\n'''\n\n'''\nDemonstration of the show_accuracy argument\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=2, show_accuracy=True)\n'''\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\nloss: 0.0190 - acc.: 0.8750\nEpoch 1\nloss: 0.0146 - acc.: 0.8750\nEpoch 2\nloss: 0.0049 - acc.: 1.0000\n'''\n\n'''\nDemonstration of the validation_split argument\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16,\n          validation_split=0.1, show_accuracy=True, verbose=1)\n'''\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\n37800/37800 [==============================] - 7s - loss: 0.0385 - acc.: 0.7258 - val. loss: 0.0160 - val. acc.: 0.9136\nEpoch 1\n37800/37800 [==============================] - 8s - loss: 0.0140 - acc.: 0.9265 - val. loss: 0.0109 - val. acc.: 0.9383\nEpoch 2\n10960/37800 [=======\n......................] - ETA: 4s - loss: 0.0109 - acc.: 0.9420\n'''\n\n\n\n\nUsing the Graph model\n\n\n# graph model with one input and two outputs\ngraph = Graph()\ngraph.add_input(name='input', input_shape=(32,))\ngraph.add_node(Dense(16), name='dense1', input='input')\ngraph.add_node(Dense(4), name='dense2', input='input')\ngraph.add_node(Dense(4), name='dense3', input='dense1')\ngraph.add_output(name='output1', input='dense2')\ngraph.add_output(name='output2', input='dense3')\n\ngraph.compile(optimizer='rmsprop', loss={'output1':'mse', 'output2':'mse'})\nhistory = graph.fit({'input':X_train, 'output1':y_train, 'output2':y2_train}, nb_epoch=10)\n\n\n\n\n\n# graph model with two inputs and one output\ngraph = Graph()\ngraph.add_input(name='input1', input_shape=(32,))\ngraph.add_input(name='input2', input_shape=(32,))\ngraph.add_node(Dense(16), name='dense1', input='input1')\ngraph.add_node(Dense(4), name='dense2', input='input2')\ngraph.add_node(Dense(4), name='dense3', input='dense1')\ngraph.add_output(name='output', inputs=['dense2', 'dense3'], merge_mode='sum')\ngraph.compile(optimizer='rmsprop', loss={'output':'mse'})\n\nhistory = graph.fit({'input1':X_train, 'input2':X2_train, 'output':y_train}, nb_epoch=10)\npredictions = graph.predict({'input1':X_test, 'input2':X2_test}) # {'output':...}\n\n\n\n\n\n\n\nModel API documentation\n\n\n[source]\n\n\nSequential\n\n\nkeras.layers.containers.Sequential(layers=[])\n\n\n\n\nLinear stack of layers.\n\n\nInherits from containers.Sequential.\n\n\nMethods\n\n\ncompile(optimizer, loss, class_mode=None, sample_weight_mode=None)\n\n\n\n\nConfigure the learning process.\n\n\nArguments\n\n\n\n\noptimizer\n: str (name of optimizer) or optimizer object.\n    See \noptimizers\n.\n\n\nloss\n: str (name of objective function) or objective function.\n    See \nobjectives\n.\n\n\nclass_mode\n: deprecated argument,\n    it is set automatically starting with Keras 0.3.3.\n\n\nsample_weight_mode\n: if you need to do timestep-wise\n    sample weighting (2D weights), set this to \"temporal\".\n    \"None\" defaults to sample-wise weights (1D).\n\n\nkwargs\n: for Theano backend, these are passed into K.function.\n    Ignored for Tensorflow backend.\n\n\n\n\nevaluate(X, y, batch_size=128, show_accuracy=False, verbose=1, sample_weight=None)\n\n\n\n\nCompute the loss on some input data, batch by batch.\n\n\nArguments\n\n\n\n\nX\n: input data, as a numpy array.\n\n\ny\n: labels, as a numpy array.\n\n\nbatch_size\n: integer.\n\n\nshow_accuracy\n: boolean.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\nsample_weight\n: sample weights, as a numpy array.\n\n\n\n\nevaluate_generator(generator, val_samples, show_accuracy=False, verbose=1)\n\n\n\n\nEvaluates the model on a generator. The generator should\nreturn the same kind of data with every yield as accepted\nby \nevaluate\n\n\n\n\nArguments\n:\n\n\ngenerator\n:\n    generator yielding dictionaries of the kind accepted\n    by \nevaluate\n, or tuples of such dictionaries and\n    associated dictionaries of sample weights.\n\n\nval_samples\n:\n    total number of samples to generate from \ngenerator\n\n    to use in validation.\n\n\nshow_accuracy\n: whether to display accuracy in logs.\n\n\nverbose\n: verbosity mode, 0 (silent), 1 (per-batch logs),\n    or 2 (per-epoch logs).\n\n\n\n\nfit(X, y, batch_size=128, nb_epoch=100, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, show_accuracy=False, class_weight=None, sample_weight=None)\n\n\n\n\nTrain the model for a fixed number of epochs.\n\n\nReturns a history object. Its \nhistory\n attribute is a record of\ntraining loss values at successive epochs,\nas well as validation loss values (if applicable).\n\n\nArguments\n\n\n\n\nX\n: data, as a numpy array.\n\n\ny\n: labels, as a numpy array.\n\n\nbatch_size\n: int. Number of samples per gradient update.\n\n\nnb_epoch\n: int.\n\n\nverbose\n: 0 for no logging to stdout,\n    1 for progress bar logging, 2 for one log line per epoch.\n\n\ncallbacks\n: \nkeras.callbacks.Callback\n list.\n    List of callbacks to apply during training.\n    See \ncallbacks\n.\n\n\nvalidation_split\n: float (0. \n x \n 1).\n    Fraction of the data to use as held-out validation data.\n\n\nvalidation_data\n: tuple (X, y) to be used as held-out\n    validation data. Will override validation_split.\n\n\nshuffle\n: boolean or str (for 'batch').\n    Whether to shuffle the samples at each epoch.\n    'batch' is a special option for dealing with the\n    limitations of HDF5 data; it shuffles in batch-sized chunks.\n\n\nshow_accuracy\n: boolean. Whether to display\n    class accuracy in the logs to stdout at each epoch.\n\n\nclass_weight\n: dictionary mapping classes to a weight value,\n    used for scaling the loss function (during training only).\n\n\nsample_weight\n: list or numpy array of weights for\n    the training samples, used for scaling the loss function\n    (during training only). You can either pass a flat (1D)\n    Numpy array with the same length as the input samples\n\n\n(1\n:1 mapping between weights and samples),\nor in the case of temporal data,\nyou can pass a 2D array with shape (samples, sequence_length),\nto apply a different weight to every timestep of every sample.\nIn this case you should make sure to specify\nsample_weight_mode=\"temporal\" in compile().\n\n\n\n\n\n\n\n\nfit_generator(generator, samples_per_epoch, nb_epoch, verbose=1, show_accuracy=False, callbacks=[], validation_data=None, nb_val_samples=None, class_weight=None, nb_worker=1, nb_val_worker=None)\n\n\n\n\nFit a model on data generated batch-by-batch by a Python generator.\nThe generator is run in parallel to the model, for efficiency,\nand can be run by multiple workers at the same time.\nFor instance, this allows you to do real-time data augmentation\non images on CPU in parallel to training your model on GPU.\n\n\nArguments\n\n\n\n\ngenerator\n: a Python generator,\n    yielding either (X, y) or (X, y, sample_weight).\n    The generator is expected to loop over its data\n    indefinitely. An epoch finishes when \nsamples_per_epoch\n\n    samples have been seen by the model.\n    The output of the generator must be a tuple of either 2 or 3\n    numpy arrays.\n    If the output tuple has two elements, they are assumed to be\n    (input_data, target_data).\n    If it has three elements, they are assumed to be\n    (input_data, target_data, sample_weight).\n    All arrays should contain the same number of samples.\n\n\nsamples_per_epoch\n: integer, number of samples to process before\n    starting a new epoch.\n\n\nnb_epoch\n: integer, total number of iterations on the data.\n\n\nverbose\n: verbosity mode, 0, 1, or 2.\n\n\nshow_accuracy\n: boolean. Whether to display accuracy (only relevant\n    for classification problems).\n\n\ncallbacks\n: list of callbacks to be called during training.\n\n\nvalidation_data\n: tuple of 2 or 3 numpy arrays, or a generator.\n    If 2 elements, they are assumed to be (input_data, target_data);\n    if 3 elements, they are assumed to be\n    (input_data, target_data, sample weights). If generator,\n    it is assumed to yield tuples of 2 or 3 elements as above.\n    The generator will be called at the end of every epoch until\n    at least \nnb_val_samples\n examples have been obtained,\n    with these examples used for validation.\n\n\nnb_val_samples\n: number of samples to use from validation\n    generator at the end of every epoch.\n\n\nclass_weight\n: dictionary mapping class indices to a weight\n    for the class.\n\n\nnb_worker\n: integer, number of workers to use for running\n    the generator (in parallel to model training).\n    If using multiple workers, the processing order of batches\n    generated by the model will be non-deterministic.\n    If using multiple workers, make sure to protect\n    any thread-unsafe operation done by the generator\n    using a Python mutex.\n\n\nnb_val_worker\n: same as \nnb_worker\n, except for validation data.\n    Has no effect if no validation data or validation data is\n    not a generator. If \nnb_val_worker\n is None, defaults to\n    \nnb_worker\n.\n\n\n\n\nReturns\n\n\nA \nHistory\n object.\n\n\nExamples\n\n\ndef generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x, y = process_line(line)\n        yield x, y\n    f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)\n\n\n\n\nload_weights(filepath)\n\n\n\n\nLoad all layer weights from a HDF5 save file.\n\n\npredict(X, batch_size=128, verbose=0)\n\n\n\n\nGenerate output predictions for the input samples\nbatch by batch.\n\n\nArguments\n\n\n\n\nX\n: the input data, as a numpy array.\n\n\nbatch_size\n: integer.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\n\n\nReturns\n\n\nA numpy array of predictions.\n\n\npredict_classes(X, batch_size=128, verbose=1)\n\n\n\n\nGenerate class predictions for the input samples\nbatch by batch.\n\n\nArguments\n\n\n\n\nX\n: the input data, as a numpy array.\n\n\nbatch_size\n: integer.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\n\n\nReturns\n\n\nA numpy array of class predictions.\n\n\npredict_on_batch(X)\n\n\n\n\nReturns predictions for a single batch of samples.\n\n\npredict_proba(X, batch_size=128, verbose=1)\n\n\n\n\nGenerate class probability predictions for the input samples\nbatch by batch.\n\n\nArguments\n\n\n\n\nX\n: the input data, as a numpy array.\n\n\nbatch_size\n: integer.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\n\n\nReturns\n\n\nA numpy array of probability predictions.\n\n\nsave_weights(filepath, overwrite=False)\n\n\n\n\nDump all layer weights to a HDF5 file.\n\n\ntest_on_batch(X, y, accuracy=False, sample_weight=None)\n\n\n\n\nReturns the loss over a single batch of samples,\nor a tuple \n(loss, accuracy)\n if \naccuracy=True\n.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\ntrain_on_batch(X, y, accuracy=False, class_weight=None, sample_weight=None)\n\n\n\n\nSingle gradient update over one batch of samples.\n\n\nReturns the loss over the data,\nor a tuple \n(loss, accuracy)\n if \naccuracy=True\n.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\nadd(layer)\n\n\n\n\nDefined by \nSequential\n.\n\n\nclear_previous(reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\ncount_params()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_config(verbose=0)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_input(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output_mask(train=None)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_weights()\n\n\n\n\nDefined by \nLayer\n.\n\n\nreset_states()\n\n\n\n\nDefined by \nSequential\n.\n\n\nset_input()\n\n\n\n\nDefined by \nSequential\n.\n\n\nset_input_shape(input_shape)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_previous(layer, reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_weights(weights)\n\n\n\n\nDefined by \nLayer\n.\n\n\nsummary()\n\n\n\n\nDefined by \nModel\n.\n\n\nsupports_masked_input()\n\n\n\n\nDefined by \nLayer\n.\n\n\nto_json()\n\n\n\n\nDefined by \nModel\n.\n\n\nto_yaml()\n\n\n\n\nDefined by \nModel\n.\n\n\n\n\n[source]\n\n\nGraph\n\n\nkeras.layers.containers.Graph()\n\n\n\n\nArbitrary connection graph.\nIt can have any number of inputs and outputs,\nwith each output trained with its own loss function.\nThe quantity being optimized by a Graph model is\nthe sum of all loss functions over the different outputs.\n\n\nInherits from \ncontainers.Graph\n.\n\n\nMethods\n\n\ncompile(optimizer, loss, sample_weight_modes={}, loss_weights={})\n\n\n\n\nConfigure the learning process.\n\n\nArguments\n\n\n\n\noptimizer\n: str (name of optimizer) or optimizer object.\n    See \noptimizers\n.\n\n\nloss\n: dictionary mapping the name(s) of the output(s) to\n    a loss function (string name of objective function or\n    objective function. See \nobjectives\n).\n\n\nsample_weight_modes\n: optional dictionary mapping certain\n    output names to a sample weight mode (\"temporal\" and None\n    are the only supported modes). If you need to do\n    timestep-wise loss weighting on one of your graph outputs,\n    you will need to set the sample weight mode for this output\n    to \"temporal\".\n\n\nloss_weights\n: dictionary you can pass to specify a weight\n    coefficient for each loss function (in a multi-output model).\n    If no loss weight is specified for an output,\n    the weight for this output's loss will be considered to be 1.\n\n\nkwargs\n: for Theano backend, these are passed into K.function.\n    Ignored for Tensorflow backend.\n\n\n\n\nevaluate(data, batch_size=128, show_accuracy=False, verbose=0, sample_weight={})\n\n\n\n\nCompute the loss on some input data, batch by batch.\n\n\nReturns the loss over the data,\nor a tuple \n(loss, accuracy)\n if \nshow_accuracy=True\n.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\nevaluate_generator(generator, nb_val_samples, show_accuracy=False, verbose=1)\n\n\n\n\nEvaluates the model on a generator. The generator should\nreturn the same kind of data with every yield as accepted\nby \nevaluate\n.\n\n\nIf \nshow_accuracy\n, it returns a tuple \n(loss, accuracy)\n,\notherwise it returns the loss value.\n\n\n\n\nArguments\n:\n\n\ngenerator\n:\n    generator yielding dictionaries of the kind accepted\n    by \nevaluate\n, or tuples of such dictionaries and\n    associated dictionaries of sample weights.\n\n\nnb_val_samples\n:\n    total number of samples to generate from \ngenerator\n\n    to use in validation.\n\n\nshow_accuracy\n: whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).\n\n\n\n\nOther arguments are the same as for \nfit\n.\n\n\nfit(data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, show_accuracy=False, class_weight={}, sample_weight={})\n\n\n\n\nTrain the model for a fixed number of epochs.\n\n\nReturns a history object. Its \nhistory\n attribute is a record of\ntraining loss values at successive epochs,\nas well as validation loss values (if applicable).\n\n\nArguments\n\n\n\n\ndata\n: dictionary mapping input names and outputs names to\n    appropriate numpy arrays. All arrays should contain\n    the same number of samples.\n\n\nbatch_size\n: int. Number of samples per gradient update.\n\n\nnb_epoch\n: int.\n\n\nverbose\n: 0 for no logging to stdout,\n    1 for progress bar logging, 2 for one log line per epoch.\n\n\ncallbacks\n: \nkeras.callbacks.Callback\n list. List of callbacks\n    to apply during training. See \ncallbacks\n.\n\n\nvalidation_split\n: float (0. \n x \n 1). Fraction of the data to\n    use as held-out validation data.\n\n\nvalidation_data\n: dictionary mapping input names and outputs names\n    to appropriate numpy arrays to be used as\n    held-out validation data.\n    All arrays should contain the same number of samples.\n    Will override validation_split.\n\n\nshuffle\n: boolean. Whether to shuffle the samples at each epoch.\n\n\nshow_accuracy\n: whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).\n\n\nclass_weight\n: dictionary mapping output names to\n    class weight dictionaries.\n\n\nsample_weight\n: dictionary mapping output names to\n    numpy arrays of sample weights.\n\n\n\n\nfit_generator(generator, samples_per_epoch, nb_epoch, verbose=1, show_accuracy=False, callbacks=[], validation_data=None, nb_val_samples=None, class_weight={}, nb_worker=1, nb_val_worker=None)\n\n\n\n\nFit a model on data generated batch-by-batch by a Python generator.\nThe generator is run in parallel to the model, for efficiency,\nand can be run by multiple workers at the same time.\nFor instance, this allows you to do real-time data augmentation\non images on CPU in parallel to training your model on GPU.\n\n\nArguments\n\n\n\n\ngenerator\n: a generator.\n    The output of the generator must be either a dictionary\n    mapping inputs and outputs names to numpy arrays, or\n    a tuple of dictionaries (input_data, sample_weight).\n    All arrays should contain the same number of samples.\n    The generator is expected to loop over its data\n    indefinitely. An epoch finishes when \nsamples_per_epoch\n\n    samples have been seen by the model.\n\n\nsamples_per_epoch\n: integer, number of samples to process before\n    going to the next epoch.\n\n\nnb_epoch\n: integer, total number of iterations on the data.\n\n\nverbose\n: verbosity mode, 0, 1, or 2.\n\n\nshow_accuracy\n: whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).\n\n\ncallbacks\n: list of callbacks to be called during training.\n\n\nvalidation_data\n: dictionary mapping input names and outputs names\n    to appropriate numpy arrays to be used as\n    held-out validation data, or a generator yielding such\n    dictionaries. All arrays should contain the same number\n    of samples. If a generator, will be called until more than\n    \nnb_val_samples\n examples have been generated at the\n    end of every epoch. These examples will then be used\n    as the validation data.\n\n\nnb_val_samples\n: number of samples to use from validation\n    generator at the end of every epoch.\n\n\nclass_weight\n: dictionary mapping class indices to a weight\n    for the class.\n\n\nnb_worker\n: integer, number of workers to use for running\n    the generator (in parallel to model training).\n    If using multiple workers, the processing order of batches\n    generated by the model will be non-deterministic.\n    If using multiple workers, make sure to protect\n    any thread-unsafe operation done by the generator\n    using a Python mutex.\n\n\nnb_val_worker\n: same as \nnb_worker\n, except for validation data.\n    Has no effect if no validation data or validation data is\n    not a generator. If \nNone\n, defaults to nb_worker.\n\n\n\n\nReturns\n\n\nA \nHistory\n object.\n\n\nExamples\n\n\ndef generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x1, x2, y = process_line(line)\n        yield {'input_1': x1, 'input_2': x2, 'output': y}\n    f.close()\n\ngraph.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)\n\n\n\n\nload_weights(filepath)\n\n\n\n\nLoad weights from a HDF5 file.\n\n\npredict(data, batch_size=128, verbose=0)\n\n\n\n\nGenerate output predictions for the input samples\nbatch by batch.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\npredict_on_batch(data)\n\n\n\n\nGenerate predictions for a single batch of samples.\n\n\nsave_weights(filepath, overwrite=False)\n\n\n\n\nSave weights from all layers to a HDF5 files.\n\n\ntest_on_batch(data, accuracy=False, sample_weight={})\n\n\n\n\nTest the network on a single batch of samples.\n\n\nIf \naccuracy\n, it returns a tuple \n(loss, accuracy)\n,\notherwise it returns the loss value.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\ntrain_on_batch(data, accuracy=False, class_weight={}, sample_weight={})\n\n\n\n\nSingle gradient update on a batch of samples.\n\n\nReturns the loss over the data,\nor a tuple \n(loss, accuracy)\n if \naccuracy=True\n.\n\n\n\n\nArguments\n: see \nfit\n method.\n\n\n\n\nadd_input(name, input_shape=None, batch_input_shape=None, dtype='float')\n\n\n\n\nDefined by \nGraph\n.\n\n\nadd_node(layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False)\n\n\n\n\nDefined by \nGraph\n.\n\n\nadd_output(name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1)\n\n\n\n\nDefined by \nGraph\n.\n\n\nadd_shared_node(layer, name, inputs=[], merge_mode=None, concat_axis=-1, dot_axes=-1, outputs=[], create_output=False)\n\n\n\n\nDefined by \nGraph\n.\n\n\nclear_previous(reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\ncount_params()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_config(verbose=0)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_input(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output_mask(train=None)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_weights()\n\n\n\n\nDefined by \nLayer\n.\n\n\nreset_states()\n\n\n\n\nDefined by \nGraph\n.\n\n\nset_input_shape(input_shape)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_previous(layer, connection_map={}, reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_weights(weights)\n\n\n\n\nDefined by \nLayer\n.\n\n\nsummary()\n\n\n\n\nDefined by \nModel\n.\n\n\nsupports_masked_input()\n\n\n\n\nDefined by \nLayer\n.\n\n\nto_json()\n\n\n\n\nDefined by \nModel\n.\n\n\nto_yaml()\n\n\n\n\nDefined by \nModel\n.\n\n\n\n\n[source]\n\n\nModel\n\n\nkeras.models.Model()\n\n\n\n\nAbstract base model class.", 
            "title": "Models"
        }, 
        {
            "location": "/models/#using-the-sequential-model", 
            "text": "from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(2, init='uniform', input_dim=64))\nmodel.add(Activation('softmax'))\n\nmodel.compile(optimizer='sgd', loss='mse')\n\n'''\nTrain the model for 3 epochs, in batches of 16 samples,\non data stored in the Numpy array X_train,\nand labels stored in the Numpy array y_train:\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=1)\n'''\nWhat you will see with mode verbose=1:\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\n37800/37800 [==============================] - 7s - loss: 0.0385\nEpoch 1\n37800/37800 [==============================] - 8s - loss: 0.0140\nEpoch 2\n10960/37800 [======= ......................] - ETA: 4s - loss: 0.0109\n'''\n\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=2)\n'''\nWhat you will see with mode verbose=2:\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\nloss: 0.0190\nEpoch 1\nloss: 0.0146\nEpoch 2\nloss: 0.0049\n'''\n\n'''\nDemonstration of the show_accuracy argument\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16, verbose=2, show_accuracy=True)\n'''\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\nloss: 0.0190 - acc.: 0.8750\nEpoch 1\nloss: 0.0146 - acc.: 0.8750\nEpoch 2\nloss: 0.0049 - acc.: 1.0000\n'''\n\n'''\nDemonstration of the validation_split argument\n'''\nmodel.fit(X_train, y_train, nb_epoch=3, batch_size=16,\n          validation_split=0.1, show_accuracy=True, verbose=1)\n'''\nTrain on 37800 samples, validate on 4200 samples\nEpoch 0\n37800/37800 [==============================] - 7s - loss: 0.0385 - acc.: 0.7258 - val. loss: 0.0160 - val. acc.: 0.9136\nEpoch 1\n37800/37800 [==============================] - 8s - loss: 0.0140 - acc.: 0.9265 - val. loss: 0.0109 - val. acc.: 0.9383\nEpoch 2\n10960/37800 [======= ......................] - ETA: 4s - loss: 0.0109 - acc.: 0.9420\n'''", 
            "title": "Using the Sequential model"
        }, 
        {
            "location": "/models/#using-the-graph-model", 
            "text": "# graph model with one input and two outputs\ngraph = Graph()\ngraph.add_input(name='input', input_shape=(32,))\ngraph.add_node(Dense(16), name='dense1', input='input')\ngraph.add_node(Dense(4), name='dense2', input='input')\ngraph.add_node(Dense(4), name='dense3', input='dense1')\ngraph.add_output(name='output1', input='dense2')\ngraph.add_output(name='output2', input='dense3')\n\ngraph.compile(optimizer='rmsprop', loss={'output1':'mse', 'output2':'mse'})\nhistory = graph.fit({'input':X_train, 'output1':y_train, 'output2':y2_train}, nb_epoch=10)  # graph model with two inputs and one output\ngraph = Graph()\ngraph.add_input(name='input1', input_shape=(32,))\ngraph.add_input(name='input2', input_shape=(32,))\ngraph.add_node(Dense(16), name='dense1', input='input1')\ngraph.add_node(Dense(4), name='dense2', input='input2')\ngraph.add_node(Dense(4), name='dense3', input='dense1')\ngraph.add_output(name='output', inputs=['dense2', 'dense3'], merge_mode='sum')\ngraph.compile(optimizer='rmsprop', loss={'output':'mse'})\n\nhistory = graph.fit({'input1':X_train, 'input2':X2_train, 'output':y_train}, nb_epoch=10)\npredictions = graph.predict({'input1':X_test, 'input2':X2_test}) # {'output':...}", 
            "title": "Using the Graph model"
        }, 
        {
            "location": "/models/#model-api-documentation", 
            "text": "[source]", 
            "title": "Model API documentation"
        }, 
        {
            "location": "/models/#sequential", 
            "text": "keras.layers.containers.Sequential(layers=[])  Linear stack of layers.  Inherits from containers.Sequential.", 
            "title": "Sequential"
        }, 
        {
            "location": "/models/#methods", 
            "text": "compile(optimizer, loss, class_mode=None, sample_weight_mode=None)  Configure the learning process.  Arguments   optimizer : str (name of optimizer) or optimizer object.\n    See  optimizers .  loss : str (name of objective function) or objective function.\n    See  objectives .  class_mode : deprecated argument,\n    it is set automatically starting with Keras 0.3.3.  sample_weight_mode : if you need to do timestep-wise\n    sample weighting (2D weights), set this to \"temporal\".\n    \"None\" defaults to sample-wise weights (1D).  kwargs : for Theano backend, these are passed into K.function.\n    Ignored for Tensorflow backend.   evaluate(X, y, batch_size=128, show_accuracy=False, verbose=1, sample_weight=None)  Compute the loss on some input data, batch by batch.  Arguments   X : input data, as a numpy array.  y : labels, as a numpy array.  batch_size : integer.  show_accuracy : boolean.  verbose : verbosity mode, 0 or 1.  sample_weight : sample weights, as a numpy array.   evaluate_generator(generator, val_samples, show_accuracy=False, verbose=1)  Evaluates the model on a generator. The generator should\nreturn the same kind of data with every yield as accepted\nby  evaluate   Arguments :  generator :\n    generator yielding dictionaries of the kind accepted\n    by  evaluate , or tuples of such dictionaries and\n    associated dictionaries of sample weights.  val_samples :\n    total number of samples to generate from  generator \n    to use in validation.  show_accuracy : whether to display accuracy in logs.  verbose : verbosity mode, 0 (silent), 1 (per-batch logs),\n    or 2 (per-epoch logs).   fit(X, y, batch_size=128, nb_epoch=100, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, show_accuracy=False, class_weight=None, sample_weight=None)  Train the model for a fixed number of epochs.  Returns a history object. Its  history  attribute is a record of\ntraining loss values at successive epochs,\nas well as validation loss values (if applicable).  Arguments   X : data, as a numpy array.  y : labels, as a numpy array.  batch_size : int. Number of samples per gradient update.  nb_epoch : int.  verbose : 0 for no logging to stdout,\n    1 for progress bar logging, 2 for one log line per epoch.  callbacks :  keras.callbacks.Callback  list.\n    List of callbacks to apply during training.\n    See  callbacks .  validation_split : float (0.   x   1).\n    Fraction of the data to use as held-out validation data.  validation_data : tuple (X, y) to be used as held-out\n    validation data. Will override validation_split.  shuffle : boolean or str (for 'batch').\n    Whether to shuffle the samples at each epoch.\n    'batch' is a special option for dealing with the\n    limitations of HDF5 data; it shuffles in batch-sized chunks.  show_accuracy : boolean. Whether to display\n    class accuracy in the logs to stdout at each epoch.  class_weight : dictionary mapping classes to a weight value,\n    used for scaling the loss function (during training only).  sample_weight : list or numpy array of weights for\n    the training samples, used for scaling the loss function\n    (during training only). You can either pass a flat (1D)\n    Numpy array with the same length as the input samples  (1 :1 mapping between weights and samples),\nor in the case of temporal data,\nyou can pass a 2D array with shape (samples, sequence_length),\nto apply a different weight to every timestep of every sample.\nIn this case you should make sure to specify\nsample_weight_mode=\"temporal\" in compile().     fit_generator(generator, samples_per_epoch, nb_epoch, verbose=1, show_accuracy=False, callbacks=[], validation_data=None, nb_val_samples=None, class_weight=None, nb_worker=1, nb_val_worker=None)  Fit a model on data generated batch-by-batch by a Python generator.\nThe generator is run in parallel to the model, for efficiency,\nand can be run by multiple workers at the same time.\nFor instance, this allows you to do real-time data augmentation\non images on CPU in parallel to training your model on GPU.  Arguments   generator : a Python generator,\n    yielding either (X, y) or (X, y, sample_weight).\n    The generator is expected to loop over its data\n    indefinitely. An epoch finishes when  samples_per_epoch \n    samples have been seen by the model.\n    The output of the generator must be a tuple of either 2 or 3\n    numpy arrays.\n    If the output tuple has two elements, they are assumed to be\n    (input_data, target_data).\n    If it has three elements, they are assumed to be\n    (input_data, target_data, sample_weight).\n    All arrays should contain the same number of samples.  samples_per_epoch : integer, number of samples to process before\n    starting a new epoch.  nb_epoch : integer, total number of iterations on the data.  verbose : verbosity mode, 0, 1, or 2.  show_accuracy : boolean. Whether to display accuracy (only relevant\n    for classification problems).  callbacks : list of callbacks to be called during training.  validation_data : tuple of 2 or 3 numpy arrays, or a generator.\n    If 2 elements, they are assumed to be (input_data, target_data);\n    if 3 elements, they are assumed to be\n    (input_data, target_data, sample weights). If generator,\n    it is assumed to yield tuples of 2 or 3 elements as above.\n    The generator will be called at the end of every epoch until\n    at least  nb_val_samples  examples have been obtained,\n    with these examples used for validation.  nb_val_samples : number of samples to use from validation\n    generator at the end of every epoch.  class_weight : dictionary mapping class indices to a weight\n    for the class.  nb_worker : integer, number of workers to use for running\n    the generator (in parallel to model training).\n    If using multiple workers, the processing order of batches\n    generated by the model will be non-deterministic.\n    If using multiple workers, make sure to protect\n    any thread-unsafe operation done by the generator\n    using a Python mutex.  nb_val_worker : same as  nb_worker , except for validation data.\n    Has no effect if no validation data or validation data is\n    not a generator. If  nb_val_worker  is None, defaults to\n     nb_worker .   Returns  A  History  object.  Examples  def generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x, y = process_line(line)\n        yield x, y\n    f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)  load_weights(filepath)  Load all layer weights from a HDF5 save file.  predict(X, batch_size=128, verbose=0)  Generate output predictions for the input samples\nbatch by batch.  Arguments   X : the input data, as a numpy array.  batch_size : integer.  verbose : verbosity mode, 0 or 1.   Returns  A numpy array of predictions.  predict_classes(X, batch_size=128, verbose=1)  Generate class predictions for the input samples\nbatch by batch.  Arguments   X : the input data, as a numpy array.  batch_size : integer.  verbose : verbosity mode, 0 or 1.   Returns  A numpy array of class predictions.  predict_on_batch(X)  Returns predictions for a single batch of samples.  predict_proba(X, batch_size=128, verbose=1)  Generate class probability predictions for the input samples\nbatch by batch.  Arguments   X : the input data, as a numpy array.  batch_size : integer.  verbose : verbosity mode, 0 or 1.   Returns  A numpy array of probability predictions.  save_weights(filepath, overwrite=False)  Dump all layer weights to a HDF5 file.  test_on_batch(X, y, accuracy=False, sample_weight=None)  Returns the loss over a single batch of samples,\nor a tuple  (loss, accuracy)  if  accuracy=True .   Arguments : see  fit  method.   train_on_batch(X, y, accuracy=False, class_weight=None, sample_weight=None)  Single gradient update over one batch of samples.  Returns the loss over the data,\nor a tuple  (loss, accuracy)  if  accuracy=True .   Arguments : see  fit  method.   add(layer)  Defined by  Sequential .  clear_previous(reset_weights=True)  Defined by  Layer .  count_params()  Defined by  Layer .  get_config(verbose=0)  Defined by  Layer .  get_input(train=False)  Defined by  Layer .  get_output(train=False)  Defined by  Layer .  get_output_mask(train=None)  Defined by  Layer .  get_weights()  Defined by  Layer .  reset_states()  Defined by  Sequential .  set_input()  Defined by  Sequential .  set_input_shape(input_shape)  Defined by  Layer .  set_previous(layer, reset_weights=True)  Defined by  Layer .  set_weights(weights)  Defined by  Layer .  summary()  Defined by  Model .  supports_masked_input()  Defined by  Layer .  to_json()  Defined by  Model .  to_yaml()  Defined by  Model .   [source]", 
            "title": "Methods"
        }, 
        {
            "location": "/models/#graph", 
            "text": "keras.layers.containers.Graph()  Arbitrary connection graph.\nIt can have any number of inputs and outputs,\nwith each output trained with its own loss function.\nThe quantity being optimized by a Graph model is\nthe sum of all loss functions over the different outputs.  Inherits from  containers.Graph .", 
            "title": "Graph"
        }, 
        {
            "location": "/models/#methods_1", 
            "text": "compile(optimizer, loss, sample_weight_modes={}, loss_weights={})  Configure the learning process.  Arguments   optimizer : str (name of optimizer) or optimizer object.\n    See  optimizers .  loss : dictionary mapping the name(s) of the output(s) to\n    a loss function (string name of objective function or\n    objective function. See  objectives ).  sample_weight_modes : optional dictionary mapping certain\n    output names to a sample weight mode (\"temporal\" and None\n    are the only supported modes). If you need to do\n    timestep-wise loss weighting on one of your graph outputs,\n    you will need to set the sample weight mode for this output\n    to \"temporal\".  loss_weights : dictionary you can pass to specify a weight\n    coefficient for each loss function (in a multi-output model).\n    If no loss weight is specified for an output,\n    the weight for this output's loss will be considered to be 1.  kwargs : for Theano backend, these are passed into K.function.\n    Ignored for Tensorflow backend.   evaluate(data, batch_size=128, show_accuracy=False, verbose=0, sample_weight={})  Compute the loss on some input data, batch by batch.  Returns the loss over the data,\nor a tuple  (loss, accuracy)  if  show_accuracy=True .   Arguments : see  fit  method.   evaluate_generator(generator, nb_val_samples, show_accuracy=False, verbose=1)  Evaluates the model on a generator. The generator should\nreturn the same kind of data with every yield as accepted\nby  evaluate .  If  show_accuracy , it returns a tuple  (loss, accuracy) ,\notherwise it returns the loss value.   Arguments :  generator :\n    generator yielding dictionaries of the kind accepted\n    by  evaluate , or tuples of such dictionaries and\n    associated dictionaries of sample weights.  nb_val_samples :\n    total number of samples to generate from  generator \n    to use in validation.  show_accuracy : whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).   Other arguments are the same as for  fit .  fit(data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, show_accuracy=False, class_weight={}, sample_weight={})  Train the model for a fixed number of epochs.  Returns a history object. Its  history  attribute is a record of\ntraining loss values at successive epochs,\nas well as validation loss values (if applicable).  Arguments   data : dictionary mapping input names and outputs names to\n    appropriate numpy arrays. All arrays should contain\n    the same number of samples.  batch_size : int. Number of samples per gradient update.  nb_epoch : int.  verbose : 0 for no logging to stdout,\n    1 for progress bar logging, 2 for one log line per epoch.  callbacks :  keras.callbacks.Callback  list. List of callbacks\n    to apply during training. See  callbacks .  validation_split : float (0.   x   1). Fraction of the data to\n    use as held-out validation data.  validation_data : dictionary mapping input names and outputs names\n    to appropriate numpy arrays to be used as\n    held-out validation data.\n    All arrays should contain the same number of samples.\n    Will override validation_split.  shuffle : boolean. Whether to shuffle the samples at each epoch.  show_accuracy : whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).  class_weight : dictionary mapping output names to\n    class weight dictionaries.  sample_weight : dictionary mapping output names to\n    numpy arrays of sample weights.   fit_generator(generator, samples_per_epoch, nb_epoch, verbose=1, show_accuracy=False, callbacks=[], validation_data=None, nb_val_samples=None, class_weight={}, nb_worker=1, nb_val_worker=None)  Fit a model on data generated batch-by-batch by a Python generator.\nThe generator is run in parallel to the model, for efficiency,\nand can be run by multiple workers at the same time.\nFor instance, this allows you to do real-time data augmentation\non images on CPU in parallel to training your model on GPU.  Arguments   generator : a generator.\n    The output of the generator must be either a dictionary\n    mapping inputs and outputs names to numpy arrays, or\n    a tuple of dictionaries (input_data, sample_weight).\n    All arrays should contain the same number of samples.\n    The generator is expected to loop over its data\n    indefinitely. An epoch finishes when  samples_per_epoch \n    samples have been seen by the model.  samples_per_epoch : integer, number of samples to process before\n    going to the next epoch.  nb_epoch : integer, total number of iterations on the data.  verbose : verbosity mode, 0, 1, or 2.  show_accuracy : whether to log accuracy.\n    Can only be used if your Graph has a single output (otherwise \"accuracy\"\n    is ill-defined).  callbacks : list of callbacks to be called during training.  validation_data : dictionary mapping input names and outputs names\n    to appropriate numpy arrays to be used as\n    held-out validation data, or a generator yielding such\n    dictionaries. All arrays should contain the same number\n    of samples. If a generator, will be called until more than\n     nb_val_samples  examples have been generated at the\n    end of every epoch. These examples will then be used\n    as the validation data.  nb_val_samples : number of samples to use from validation\n    generator at the end of every epoch.  class_weight : dictionary mapping class indices to a weight\n    for the class.  nb_worker : integer, number of workers to use for running\n    the generator (in parallel to model training).\n    If using multiple workers, the processing order of batches\n    generated by the model will be non-deterministic.\n    If using multiple workers, make sure to protect\n    any thread-unsafe operation done by the generator\n    using a Python mutex.  nb_val_worker : same as  nb_worker , except for validation data.\n    Has no effect if no validation data or validation data is\n    not a generator. If  None , defaults to nb_worker.   Returns  A  History  object.  Examples  def generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x1, x2, y = process_line(line)\n        yield {'input_1': x1, 'input_2': x2, 'output': y}\n    f.close()\n\ngraph.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)  load_weights(filepath)  Load weights from a HDF5 file.  predict(data, batch_size=128, verbose=0)  Generate output predictions for the input samples\nbatch by batch.   Arguments : see  fit  method.   predict_on_batch(data)  Generate predictions for a single batch of samples.  save_weights(filepath, overwrite=False)  Save weights from all layers to a HDF5 files.  test_on_batch(data, accuracy=False, sample_weight={})  Test the network on a single batch of samples.  If  accuracy , it returns a tuple  (loss, accuracy) ,\notherwise it returns the loss value.   Arguments : see  fit  method.   train_on_batch(data, accuracy=False, class_weight={}, sample_weight={})  Single gradient update on a batch of samples.  Returns the loss over the data,\nor a tuple  (loss, accuracy)  if  accuracy=True .   Arguments : see  fit  method.   add_input(name, input_shape=None, batch_input_shape=None, dtype='float')  Defined by  Graph .  add_node(layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False)  Defined by  Graph .  add_output(name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1)  Defined by  Graph .  add_shared_node(layer, name, inputs=[], merge_mode=None, concat_axis=-1, dot_axes=-1, outputs=[], create_output=False)  Defined by  Graph .  clear_previous(reset_weights=True)  Defined by  Layer .  count_params()  Defined by  Layer .  get_config(verbose=0)  Defined by  Layer .  get_input(train=False)  Defined by  Layer .  get_output(train=False)  Defined by  Layer .  get_output_mask(train=None)  Defined by  Layer .  get_weights()  Defined by  Layer .  reset_states()  Defined by  Graph .  set_input_shape(input_shape)  Defined by  Layer .  set_previous(layer, connection_map={}, reset_weights=True)  Defined by  Layer .  set_weights(weights)  Defined by  Layer .  summary()  Defined by  Model .  supports_masked_input()  Defined by  Layer .  to_json()  Defined by  Model .  to_yaml()  Defined by  Model .   [source]", 
            "title": "Methods"
        }, 
        {
            "location": "/models/#model", 
            "text": "keras.models.Model()  Abstract base model class.", 
            "title": "Model"
        }, 
        {
            "location": "/activations/", 
            "text": "Usage of activations\n\n\nActivations can either be used through an \nActivation\n layer, or through the \nactivation\n argument supported by all forward layers:\n\n\nfrom keras.layers.core import Activation, Dense\n\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))\n\n\n\n\nis equivalent to:\n\n\nmodel.add(Dense(64, activation='tanh'))\n\n\n\n\nYou can also pass an element-wise Theano/TensorFlow function as an activation:\n\n\nfrom keras import backend as K\n\ndef tanh(x):\n    return K.tanh(x)\n\nmodel.add(Dense(64, activation=tanh))\nmodel.add(Activation(tanh))\n\n\n\n\nAvailable activations\n\n\n\n\nsoftmax\n: Softmax applied across inputs last dimension. Expects shape either \n(nb_samples, nb_timesteps, nb_dims)\n or \n(nb_samples, nb_dims)\n.\n\n\nsoftplus\n\n\nrelu\n\n\ntanh\n\n\nsigmoid\n\n\nhard_sigmoid\n\n\nlinear\n\n\n\n\nOn Advanced Activations\n\n\nActivations that are more complex than a simple Theano/TensorFlow function (eg. learnable activations, configurable activations, etc.) are available as \nAdvanced Activation layers\n, and can be found in the module \nkeras.layers.advanced_activations\n. These include PReLU and LeakyReLU.", 
            "title": "Activations"
        }, 
        {
            "location": "/activations/#usage-of-activations", 
            "text": "Activations can either be used through an  Activation  layer, or through the  activation  argument supported by all forward layers:  from keras.layers.core import Activation, Dense\n\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))  is equivalent to:  model.add(Dense(64, activation='tanh'))  You can also pass an element-wise Theano/TensorFlow function as an activation:  from keras import backend as K\n\ndef tanh(x):\n    return K.tanh(x)\n\nmodel.add(Dense(64, activation=tanh))\nmodel.add(Activation(tanh))", 
            "title": "Usage of activations"
        }, 
        {
            "location": "/activations/#available-activations", 
            "text": "softmax : Softmax applied across inputs last dimension. Expects shape either  (nb_samples, nb_timesteps, nb_dims)  or  (nb_samples, nb_dims) .  softplus  relu  tanh  sigmoid  hard_sigmoid  linear", 
            "title": "Available activations"
        }, 
        {
            "location": "/activations/#on-advanced-activations", 
            "text": "Activations that are more complex than a simple Theano/TensorFlow function (eg. learnable activations, configurable activations, etc.) are available as  Advanced Activation layers , and can be found in the module  keras.layers.advanced_activations . These include PReLU and LeakyReLU.", 
            "title": "On Advanced Activations"
        }, 
        {
            "location": "/initializations/", 
            "text": "Usage of initializations\n\n\nInitializations define the probability distribution used to set the initial random weights of Keras layers.\n\n\nThe keyword arguments used for passing initializations to layers will depend on the layer. Usually it is simply \ninit\n:\n\n\nmodel.add(Dense(64, init='uniform'))\n\n\n\n\nAvailable initializations\n\n\n\n\nuniform\n\n\nlecun_uniform\n: Uniform initialization scaled by the square root of the number of inputs (LeCun 98).\n\n\nnormal\n\n\nidentity\n: Use with square 2D layers (\nshape[0] == shape[1]\n).\n\n\northogonal\n: Use with square 2D layers (\nshape[0] == shape[1]\n).\n\n\nzero\n\n\nglorot_normal\n: Gaussian initialization scaled by fan_in + fan_out (Glorot 2010)\n\n\nglorot_uniform\n\n\nhe_normal\n: Gaussian initialization scaled by fan_in (He et al., 2014)\n\n\nhe_uniform", 
            "title": "Initializations"
        }, 
        {
            "location": "/initializations/#usage-of-initializations", 
            "text": "Initializations define the probability distribution used to set the initial random weights of Keras layers.  The keyword arguments used for passing initializations to layers will depend on the layer. Usually it is simply  init :  model.add(Dense(64, init='uniform'))", 
            "title": "Usage of initializations"
        }, 
        {
            "location": "/initializations/#available-initializations", 
            "text": "uniform  lecun_uniform : Uniform initialization scaled by the square root of the number of inputs (LeCun 98).  normal  identity : Use with square 2D layers ( shape[0] == shape[1] ).  orthogonal : Use with square 2D layers ( shape[0] == shape[1] ).  zero  glorot_normal : Gaussian initialization scaled by fan_in + fan_out (Glorot 2010)  glorot_uniform  he_normal : Gaussian initialization scaled by fan_in (He et al., 2014)  he_uniform", 
            "title": "Available initializations"
        }, 
        {
            "location": "/regularizers/", 
            "text": "Usage of regularizers\n\n\nRegularizers allow to apply penalties on layer parameters or layer activity during optimization. These penalties are incorporated in the loss function that the network optimizes.\n\n\nThe penalties are applied on a per-layer basis. The exact API will depend on the layer, but the layers \nDense\n, \nTimeDistributedDense\n, \nMaxoutDense\n, \nConvolution1D\n and \nConvolution2D\n have a unified API.\n\n\nThese layers expose 3 keyword arguments:\n\n\n\n\nW_regularizer\n: instance of \nkeras.regularizers.WeightRegularizer\n\n\nb_regularizer\n: instance of \nkeras.regularizers.WeightRegularizer\n\n\nactivity_regularizer\n: instance of \nkeras.regularizers.ActivityRegularizer\n\n\n\n\nExample\n\n\nfrom keras.regularizers import l2, activity_l2\nmodel.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n\n\n\n\nAvailable penalties\n\n\nkeras.regularizers.WeightRegularizer(l1=0., l2=0.)\n\n\n\n\nkeras.regularizers.ActivityRegularizer(l1=0., l2=0.)\n\n\n\n\nShortcuts\n\n\nThese are shortcut functions available in \nkeras.regularizers\n.\n\n\n\n\nl1\n(l=0.01): L1 weight regularization penalty, also known as LASSO\n\n\nl2\n(l=0.01): L2 weight regularization penalty, also known as weight decay, or Ridge\n\n\nl1l2\n(l1=0.01, l2=0.01): L1-L2 weight regularization penalty, also known as ElasticNet\n\n\nactivity_l1\n(l=0.01): L1 activity regularization\n\n\nactivity_l2\n(l=0.01): L2 activity regularization\n\n\nactivity_l1l2\n(l1=0.01, l2=0.01): L1+L2 activity regularization", 
            "title": "Regularizers"
        }, 
        {
            "location": "/regularizers/#usage-of-regularizers", 
            "text": "Regularizers allow to apply penalties on layer parameters or layer activity during optimization. These penalties are incorporated in the loss function that the network optimizes.  The penalties are applied on a per-layer basis. The exact API will depend on the layer, but the layers  Dense ,  TimeDistributedDense ,  MaxoutDense ,  Convolution1D  and  Convolution2D  have a unified API.  These layers expose 3 keyword arguments:   W_regularizer : instance of  keras.regularizers.WeightRegularizer  b_regularizer : instance of  keras.regularizers.WeightRegularizer  activity_regularizer : instance of  keras.regularizers.ActivityRegularizer", 
            "title": "Usage of regularizers"
        }, 
        {
            "location": "/regularizers/#example", 
            "text": "from keras.regularizers import l2, activity_l2\nmodel.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))", 
            "title": "Example"
        }, 
        {
            "location": "/regularizers/#available-penalties", 
            "text": "keras.regularizers.WeightRegularizer(l1=0., l2=0.)  keras.regularizers.ActivityRegularizer(l1=0., l2=0.)", 
            "title": "Available penalties"
        }, 
        {
            "location": "/regularizers/#shortcuts", 
            "text": "These are shortcut functions available in  keras.regularizers .   l1 (l=0.01): L1 weight regularization penalty, also known as LASSO  l2 (l=0.01): L2 weight regularization penalty, also known as weight decay, or Ridge  l1l2 (l1=0.01, l2=0.01): L1-L2 weight regularization penalty, also known as ElasticNet  activity_l1 (l=0.01): L1 activity regularization  activity_l2 (l=0.01): L2 activity regularization  activity_l1l2 (l1=0.01, l2=0.01): L1+L2 activity regularization", 
            "title": "Shortcuts"
        }, 
        {
            "location": "/constraints/", 
            "text": "Usage of constraints\n\n\nFunctions from the \nconstraints\n module allow setting constraints (eg. non-negativity) on network parameters during optimization.\n\n\nThe penalties are applied on a per-layer basis. The exact API will depend on the layer, but the layers \nDense\n, \nTimeDistributedDense\n, \nMaxoutDense\n, \nConvolution1D\n and \nConvolution2D\n have a unified API.\n\n\nThese layers expose 2 keyword arguments:\n\n\n\n\nW_constraint\n for the main weights matrix\n\n\nb_constraint\n for the bias.\n\n\n\n\nfrom keras.constraints import maxnorm\nmodel.add(Dense(64, W_constraint = maxnorm(2)))\n\n\n\n\nAvailable constraints\n\n\n\n\nmaxnorm\n(m=2): maximum-norm constraint\n\n\nnonneg\n(): non-negativity constraint\n\n\nunitnorm\n(): unit-norm constraint, enforces the matrix to have unit norm along the last axis", 
            "title": "Constraints"
        }, 
        {
            "location": "/constraints/#usage-of-constraints", 
            "text": "Functions from the  constraints  module allow setting constraints (eg. non-negativity) on network parameters during optimization.  The penalties are applied on a per-layer basis. The exact API will depend on the layer, but the layers  Dense ,  TimeDistributedDense ,  MaxoutDense ,  Convolution1D  and  Convolution2D  have a unified API.  These layers expose 2 keyword arguments:   W_constraint  for the main weights matrix  b_constraint  for the bias.   from keras.constraints import maxnorm\nmodel.add(Dense(64, W_constraint = maxnorm(2)))", 
            "title": "Usage of constraints"
        }, 
        {
            "location": "/constraints/#available-constraints", 
            "text": "maxnorm (m=2): maximum-norm constraint  nonneg (): non-negativity constraint  unitnorm (): unit-norm constraint, enforces the matrix to have unit norm along the last axis", 
            "title": "Available constraints"
        }, 
        {
            "location": "/callbacks/", 
            "text": "Usage of callbacks\n\n\nA callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument \ncallbacks\n) to the \n.fit()\n method of the \nSequential\n model. The relevant methods of the callbacks will then be called at each stage of the training. \n\n\n\n\n[source]\n\n\nCallback\n\n\nkeras.callbacks.Callback()\n\n\n\n\nAbstract base class used to build new callbacks.\n\n\nProperties\n\n\n\n\nparams\n: dict. Training parameters\n    (eg. verbosity, batch size, number of epochs...).\n\n\nmodel\n: instance of \nkeras.models.Model\n.\n    Reference of the model being trained.\n\n\n\n\nThe \nlogs\n dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch.\n\n\nCurrently, the \n.fit()\n method of the \nSequential\n model class\nwill include the following quantities in the \nlogs\n that\nit passes to its callbacks:\n\n\n\n\non_epoch_end\n: logs include \nacc\n and \nloss\n, and\n    optionally include \nval_loss\n\n    (if validation is enabled in \nfit\n), and \nval_acc\n\n    (if validation and accuracy monitoring are enabled).\n\n\non_batch_begin\n: logs include \nsize\n,\n    the number of samples in the current batch.\n\n\non_batch_end\n: logs include \nloss\n, and optionally \nacc\n\n    (if accuracy monitoring is enabled).\n\n\n\n\nMethods\n\n\non_batch_begin(batch, logs={})\n\n\n\n\non_batch_end(batch, logs={})\n\n\n\n\non_epoch_begin(epoch, logs={})\n\n\n\n\non_epoch_end(epoch, logs={})\n\n\n\n\non_train_begin(logs={})\n\n\n\n\non_train_end(logs={})\n\n\n\n\n\n\n[source]\n\n\nBaseLogger\n\n\nkeras.callbacks.BaseLogger()\n\n\n\n\nCallback that accumulates epoch averages of\nthe metrics being monitored.\n\n\nThis callback is automatically applied to\nevery Keras model.\n\n\n\n\n[source]\n\n\nProgbarLogger\n\n\nkeras.callbacks.ProgbarLogger()\n\n\n\n\nCallback that prints metrics to stdout.\n\n\n\n\n[source]\n\n\nHistory\n\n\nkeras.callbacks.History()\n\n\n\n\nCallback that records events\ninto a \nHistory\n object.\n\n\nThis callback is automatically applied to\nevery Keras model. The \nHistory\n object\ngets returned by the \nfit\n method of models.\n\n\n\n\n[source]\n\n\nModelCheckpoint\n\n\nkeras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, mode='auto')\n\n\n\n\nSave the model after every epoch.\n\n\nfilepath\n can contain named formatting options,\nwhich will be filled the value of \nepoch\n and\nkeys in \nlogs\n (passed in \non_epoch_end\n).\n\n\nFor example: if \nfilepath\n is \nweights.{epoch:02d}-{val_loss:.2f}.hdf5\n,\nthen multiple files will be save with the epoch number and\nthe validation loss.\n\n\nArguments\n\n\n\n\nfilepath\n: string, path to save the model file.\n\n\nmonitor\n: quantity to monitor.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\nsave_best_only\n: if \nsave_best_only=True\n,\n    the latest best model according to\n    the validation loss will not be overwritten.\n\n\nmode\n: one of {auto, min, max}.\n    If \nsave_best_only=True\n, the decision\n    to overwrite the current save file is made\n    based on either the maximization or the\n    minization of the monitored. For \nval_acc\n,\n    this should be \nmax\n, for \nval_loss\n this should\n    be \nmin\n, etc. In \nauto\n mode, the direction is\n    automatically inferred from the name of the monitored quantity.\n\n\n\n\n\n\n[source]\n\n\nEarlyStopping\n\n\nkeras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n\n\n\n\nStop training when a monitored quantity has stopped improving.\n\n\nArguments\n\n\n\n\nmonitor\n: quantity to be monitored.\n\n\npatience\n: number of epochs with no improvement\n    after which training will be stopped.\n\n\nverbose\n: verbosity mode.\n\n\nmode\n: one of {auto, min, max}. In 'min' mode,\n    training will stop when the quantity\n    monitored has stopped decreasing; in 'max'\n    mode it will stop when the quantity\n    monitored has stopped increasing.\n\n\n\n\n\n\n[source]\n\n\nRemoteMonitor\n\n\nkeras.callbacks.RemoteMonitor(root='http://localhost:9000')\n\n\n\n\nCallback used to stream events to a server.\n\n\nRequires the \nrequests\n library.\n\n\nArguments\n\n\n\n\nroot\n: root url to which the events will be sent (at the end\n    of every epoch). Events are sent to\n    \nroot + '/publish/epoch/end/'\n. Calls are HTTP POST,\n    with a \ndata\n argument which is a JSON-encoded dictionary\n    of event data.\n\n\n\n\n\n\n[source]\n\n\nLearningRateScheduler\n\n\nkeras.callbacks.LearningRateScheduler(schedule)\n\n\n\n\nLearning rate scheduler.\n\n\nArguments\n\n\n\n\nschedule\n: a function that takes an epoch index as input\n    (integer, indexed from 0) and returns a new\n    learning rate as output (float).\n\n\n\n\n\n\n[source]\n\n\nTensorBoard\n\n\nkeras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)\n\n\n\n\nTensorboard basic visualizations.\n\n\nThis callback writes a log for TensorBoard, which allows\nyou to visualize dynamic graphs of your training and test\nmetrics, as well as activation histograms for the different\nlayers in your model.\n\n\nTensorBoard is a visualization tool provided with TensorFlow.\n\n\nIf you have installed TensorFlow with pip, you should be able\nto launch TensorBoard from the command line:\n\n\ntensorboard --logdir=/full_path_to_your_logs\n\n\n\n\nYou can find more information about TensorBoard\n- __\nhere\n.\n\n\nArguments\n\n\n\n\nlog_dir\n: the path of the directory where to save the log\n    files to be parsed by tensorboard\n\n\nhistogram_freq\n: frequency (in epochs) at which to compute activation\n    histograms for the layers of the model. If set to 0,\n    histograms won't be computed.\n\n\n\n\n\n\nCreate a callback\n\n\nYou can create a custom callback by extending the base class \nkeras.callbacks.Callback\n. A callback has access to its associated model through the class property \nself.model\n.\n\n\nHere's a simple example saving a list of losses over each batch during training:\n\n\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\n\n\n\n\n\nExample: recording loss history\n\n\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nhistory = LossHistory()\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, callbacks=[history])\n\nprint history.losses\n# outputs\n'''\n[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]\n'''\n\n\n\n\n\n\nExample: model checkpoints\n\n\nfrom keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n'''\nsaves the model weights after each epoch if the validation loss decreased\n'''\ncheckpointer = ModelCheckpoint(filepath=\n/tmp/weights.hdf5\n, verbose=1, save_best_only=True)\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])", 
            "title": "Callbacks"
        }, 
        {
            "location": "/callbacks/#usage-of-callbacks", 
            "text": "A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument  callbacks ) to the  .fit()  method of the  Sequential  model. The relevant methods of the callbacks will then be called at each stage of the training.    [source]", 
            "title": "Usage of callbacks"
        }, 
        {
            "location": "/callbacks/#callback", 
            "text": "keras.callbacks.Callback()  Abstract base class used to build new callbacks.  Properties   params : dict. Training parameters\n    (eg. verbosity, batch size, number of epochs...).  model : instance of  keras.models.Model .\n    Reference of the model being trained.   The  logs  dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch.  Currently, the  .fit()  method of the  Sequential  model class\nwill include the following quantities in the  logs  that\nit passes to its callbacks:   on_epoch_end : logs include  acc  and  loss , and\n    optionally include  val_loss \n    (if validation is enabled in  fit ), and  val_acc \n    (if validation and accuracy monitoring are enabled).  on_batch_begin : logs include  size ,\n    the number of samples in the current batch.  on_batch_end : logs include  loss , and optionally  acc \n    (if accuracy monitoring is enabled).", 
            "title": "Callback"
        }, 
        {
            "location": "/callbacks/#methods", 
            "text": "on_batch_begin(batch, logs={})  on_batch_end(batch, logs={})  on_epoch_begin(epoch, logs={})  on_epoch_end(epoch, logs={})  on_train_begin(logs={})  on_train_end(logs={})   [source]", 
            "title": "Methods"
        }, 
        {
            "location": "/callbacks/#baselogger", 
            "text": "keras.callbacks.BaseLogger()  Callback that accumulates epoch averages of\nthe metrics being monitored.  This callback is automatically applied to\nevery Keras model.   [source]", 
            "title": "BaseLogger"
        }, 
        {
            "location": "/callbacks/#progbarlogger", 
            "text": "keras.callbacks.ProgbarLogger()  Callback that prints metrics to stdout.   [source]", 
            "title": "ProgbarLogger"
        }, 
        {
            "location": "/callbacks/#history", 
            "text": "keras.callbacks.History()  Callback that records events\ninto a  History  object.  This callback is automatically applied to\nevery Keras model. The  History  object\ngets returned by the  fit  method of models.   [source]", 
            "title": "History"
        }, 
        {
            "location": "/callbacks/#modelcheckpoint", 
            "text": "keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, mode='auto')  Save the model after every epoch.  filepath  can contain named formatting options,\nwhich will be filled the value of  epoch  and\nkeys in  logs  (passed in  on_epoch_end ).  For example: if  filepath  is  weights.{epoch:02d}-{val_loss:.2f}.hdf5 ,\nthen multiple files will be save with the epoch number and\nthe validation loss.  Arguments   filepath : string, path to save the model file.  monitor : quantity to monitor.  verbose : verbosity mode, 0 or 1.  save_best_only : if  save_best_only=True ,\n    the latest best model according to\n    the validation loss will not be overwritten.  mode : one of {auto, min, max}.\n    If  save_best_only=True , the decision\n    to overwrite the current save file is made\n    based on either the maximization or the\n    minization of the monitored. For  val_acc ,\n    this should be  max , for  val_loss  this should\n    be  min , etc. In  auto  mode, the direction is\n    automatically inferred from the name of the monitored quantity.    [source]", 
            "title": "ModelCheckpoint"
        }, 
        {
            "location": "/callbacks/#earlystopping", 
            "text": "keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')  Stop training when a monitored quantity has stopped improving.  Arguments   monitor : quantity to be monitored.  patience : number of epochs with no improvement\n    after which training will be stopped.  verbose : verbosity mode.  mode : one of {auto, min, max}. In 'min' mode,\n    training will stop when the quantity\n    monitored has stopped decreasing; in 'max'\n    mode it will stop when the quantity\n    monitored has stopped increasing.    [source]", 
            "title": "EarlyStopping"
        }, 
        {
            "location": "/callbacks/#remotemonitor", 
            "text": "keras.callbacks.RemoteMonitor(root='http://localhost:9000')  Callback used to stream events to a server.  Requires the  requests  library.  Arguments   root : root url to which the events will be sent (at the end\n    of every epoch). Events are sent to\n     root + '/publish/epoch/end/' . Calls are HTTP POST,\n    with a  data  argument which is a JSON-encoded dictionary\n    of event data.    [source]", 
            "title": "RemoteMonitor"
        }, 
        {
            "location": "/callbacks/#learningratescheduler", 
            "text": "keras.callbacks.LearningRateScheduler(schedule)  Learning rate scheduler.  Arguments   schedule : a function that takes an epoch index as input\n    (integer, indexed from 0) and returns a new\n    learning rate as output (float).    [source]", 
            "title": "LearningRateScheduler"
        }, 
        {
            "location": "/callbacks/#tensorboard", 
            "text": "keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)  Tensorboard basic visualizations.  This callback writes a log for TensorBoard, which allows\nyou to visualize dynamic graphs of your training and test\nmetrics, as well as activation histograms for the different\nlayers in your model.  TensorBoard is a visualization tool provided with TensorFlow.  If you have installed TensorFlow with pip, you should be able\nto launch TensorBoard from the command line:  tensorboard --logdir=/full_path_to_your_logs  You can find more information about TensorBoard\n- __ here .  Arguments   log_dir : the path of the directory where to save the log\n    files to be parsed by tensorboard  histogram_freq : frequency (in epochs) at which to compute activation\n    histograms for the layers of the model. If set to 0,\n    histograms won't be computed.", 
            "title": "TensorBoard"
        }, 
        {
            "location": "/callbacks/#create-a-callback", 
            "text": "You can create a custom callback by extending the base class  keras.callbacks.Callback . A callback has access to its associated model through the class property  self.model .  Here's a simple example saving a list of losses over each batch during training:  class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))", 
            "title": "Create a callback"
        }, 
        {
            "location": "/callbacks/#example-recording-loss-history", 
            "text": "class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nhistory = LossHistory()\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, callbacks=[history])\n\nprint history.losses\n# outputs\n'''\n[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]\n'''", 
            "title": "Example: recording loss history"
        }, 
        {
            "location": "/callbacks/#example-model-checkpoints", 
            "text": "from keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n'''\nsaves the model weights after each epoch if the validation loss decreased\n'''\ncheckpointer = ModelCheckpoint(filepath= /tmp/weights.hdf5 , verbose=1, save_best_only=True)\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])", 
            "title": "Example: model checkpoints"
        }, 
        {
            "location": "/datasets/", 
            "text": "Datasets\n\n\nCIFAR10 small image classification\n\n\nkeras.datasets.cifar10\n\n\nDataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images.\n\n\nUsage:\n\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\n\n\n\n\n\nReturn:\n\n\n2 tuples:\n\n\nX_train, X_test\n: uint8 array of RGB image data with shape (nb_samples, 3, 32, 32).\n\n\ny_train, y_test\n: uint8 array of category labels (integers in range 0-9) with shape (nb_samples,).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCIFAR100 small image classification\n\n\nkeras.datasets.cifar100\n\n\nDataset of 50,000 32x32 color training images, labeled over 100 categories, and 10,000 test images.\n\n\nUsage:\n\n\n(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n\n\n\n\n\n\n\n\nReturn:\n\n\n\n\n2 tuples:\n\n\nX_train, X_test\n: uint8 array of RGB image data with shape (nb_samples, 3, 32, 32).\n\n\ny_train, y_test\n: uint8 array of category labels with shape (nb_samples,).\n\n\n\n\n\n\n\n\n\n\n\n\nArguments:\n\n\n\n\nlabel_mode\n: \"fine\" or \"coarse\".\n\n\n\n\n\n\n\n\n\n\nIMDB Movie reviews sentiment classification\n\n\nkeras.datasets.imdb\n\n\nDataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a \nsequence\n of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n\n\nAs a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n\n\nUsage:\n\n\n(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\nimdb.pkl\n, \\\nnb_words=None, skip_top=0, maxlen=None, test_split=0.1, seed=113)\n\n\n\n\n\n\n\n\nReturn:\n\n\n\n\n2 tuples:\n\n\nX_train, X_test\n: list of sequences, which are lists of indexes (integers). If the nb_words argument was specific, the maximum possible index value is nb_words-1. If the maxlen argument was specified, the largest possible sequence length is maxlen.\n\n\ny_train, y_test\n: list of integer labels (1 or 0). \n\n\n\n\n\n\n\n\n\n\n\n\nArguments:\n\n\n\n\npath\n: if you do have the data locally (at \n'~/.keras/datasets/' + path\n), if will be downloaded to this location (in cPickle format).\n\n\nnb_words\n: integer or None. Top most frequent words to consider. Any less frequent word will appear as 0 in the sequence data.\n\n\nskip_top\n: integer. Top most frequent words to ignore (they will appear as 0s in the sequence data).\n\n\nmaxlen\n: int. Maximum sequence length. Any longer sequence will be truncated.\n\n\ntest_split\n: float. Fraction of the dataset to be used as test data.\n\n\nseed\n: int. Seed for reproducible data shuffling.\n\n\n\n\n\n\n\n\n\n\nReuters newswire topics classification\n\n\nkeras.datasets.reuters\n\n\nDataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions).\n\n\nUsage:\n\n\n(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\nreuters.pkl\n, \\\nnb_words=None, skip_top=0, maxlen=None, test_split=0.1, seed=113)\n\n\n\n\nThe specifications are the same as that of the IMDB dataset.\n\n\nThis dataset also makes available the word index used for encoding the sequences:\n\n\nword_index = reuters.get_word_index(path=\nreuters_word_index.pkl\n)\n\n\n\n\n\n\n\n\nReturn:\n A dictionary where key are words (str) and values are indexes (integer). eg. \nword_index[\"giraffe\"]\n might return \n1234\n. \n\n\n\n\n\n\nArguments:\n\n\n\n\npath\n: if you do have the index file locally (at \n'~/.keras/datasets/' + path\n), if will be downloaded to this location (in cPickle format).\n\n\n\n\n\n\n\n\nMNIST database of handwritten digits\n\n\nkeras.datasets.mnist\n\n\nDataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n\n\nUsage:\n\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n\n\n\n\n\n\n\nReturn:\n\n\n\n\n2 tuples:\n\n\nX_train, X_test\n: uint8 array of grayscale image data with shape (nb_samples, 28, 28).\n\n\ny_train, y_test\n: uint8 array of digit labels (integers in range 0-9) with shape (nb_samples,).\n\n\n\n\n\n\n\n\n\n\n\n\nArguments:\n\n\n\n\npath\n: if you do have the index file locally (at \n'~/.keras/datasets/' + path\n), if will be downloaded to this location (in cPickle format).", 
            "title": "Datasets"
        }, 
        {
            "location": "/datasets/#datasets", 
            "text": "", 
            "title": "Datasets"
        }, 
        {
            "location": "/datasets/#cifar10-small-image-classification", 
            "text": "keras.datasets.cifar10  Dataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images.", 
            "title": "CIFAR10 small image classification"
        }, 
        {
            "location": "/datasets/#usage", 
            "text": "(X_train, y_train), (X_test, y_test) = cifar10.load_data()   Return:  2 tuples:  X_train, X_test : uint8 array of RGB image data with shape (nb_samples, 3, 32, 32).  y_train, y_test : uint8 array of category labels (integers in range 0-9) with shape (nb_samples,).", 
            "title": "Usage:"
        }, 
        {
            "location": "/datasets/#cifar100-small-image-classification", 
            "text": "keras.datasets.cifar100  Dataset of 50,000 32x32 color training images, labeled over 100 categories, and 10,000 test images.", 
            "title": "CIFAR100 small image classification"
        }, 
        {
            "location": "/datasets/#usage_1", 
            "text": "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')    Return:   2 tuples:  X_train, X_test : uint8 array of RGB image data with shape (nb_samples, 3, 32, 32).  y_train, y_test : uint8 array of category labels with shape (nb_samples,).       Arguments:   label_mode : \"fine\" or \"coarse\".", 
            "title": "Usage:"
        }, 
        {
            "location": "/datasets/#imdb-movie-reviews-sentiment-classification", 
            "text": "keras.datasets.imdb  Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a  sequence  of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".  As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.", 
            "title": "IMDB Movie reviews sentiment classification"
        }, 
        {
            "location": "/datasets/#usage_2", 
            "text": "(X_train, y_train), (X_test, y_test) = imdb.load_data(path= imdb.pkl , \\\nnb_words=None, skip_top=0, maxlen=None, test_split=0.1, seed=113)    Return:   2 tuples:  X_train, X_test : list of sequences, which are lists of indexes (integers). If the nb_words argument was specific, the maximum possible index value is nb_words-1. If the maxlen argument was specified, the largest possible sequence length is maxlen.  y_train, y_test : list of integer labels (1 or 0).        Arguments:   path : if you do have the data locally (at  '~/.keras/datasets/' + path ), if will be downloaded to this location (in cPickle format).  nb_words : integer or None. Top most frequent words to consider. Any less frequent word will appear as 0 in the sequence data.  skip_top : integer. Top most frequent words to ignore (they will appear as 0s in the sequence data).  maxlen : int. Maximum sequence length. Any longer sequence will be truncated.  test_split : float. Fraction of the dataset to be used as test data.  seed : int. Seed for reproducible data shuffling.", 
            "title": "Usage:"
        }, 
        {
            "location": "/datasets/#reuters-newswire-topics-classification", 
            "text": "keras.datasets.reuters  Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions).", 
            "title": "Reuters newswire topics classification"
        }, 
        {
            "location": "/datasets/#usage_3", 
            "text": "(X_train, y_train), (X_test, y_test) = reuters.load_data(path= reuters.pkl , \\\nnb_words=None, skip_top=0, maxlen=None, test_split=0.1, seed=113)  The specifications are the same as that of the IMDB dataset.  This dataset also makes available the word index used for encoding the sequences:  word_index = reuters.get_word_index(path= reuters_word_index.pkl )    Return:  A dictionary where key are words (str) and values are indexes (integer). eg.  word_index[\"giraffe\"]  might return  1234 .     Arguments:   path : if you do have the index file locally (at  '~/.keras/datasets/' + path ), if will be downloaded to this location (in cPickle format).", 
            "title": "Usage:"
        }, 
        {
            "location": "/datasets/#mnist-database-of-handwritten-digits", 
            "text": "keras.datasets.mnist  Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.", 
            "title": "MNIST database of handwritten digits"
        }, 
        {
            "location": "/datasets/#usage_4", 
            "text": "(X_train, y_train), (X_test, y_test) = mnist.load_data()    Return:   2 tuples:  X_train, X_test : uint8 array of grayscale image data with shape (nb_samples, 28, 28).  y_train, y_test : uint8 array of digit labels (integers in range 0-9) with shape (nb_samples,).       Arguments:   path : if you do have the index file locally (at  '~/.keras/datasets/' + path ), if will be downloaded to this location (in cPickle format).", 
            "title": "Usage:"
        }, 
        {
            "location": "/visualization/", 
            "text": "Model visualization\n\n\nThe \nkeras.utils.visualize_util\n module provides utility functions to plot\na Keras model (using graphviz).\n\n\nThis will plot a graph of the model and save it to a file:\n\n\nfrom keras.utils.visualize_util import plot\nplot(model, to_file='model.png')\n\n\n\n\nplot\n takes two optional arguments:\n\n\n\n\nrecursive\n (defaults to True) controls whether we recursively explore container layers.\n\n\nshow_shape\n (defaults to False) controls whether output shapes are shown in the graph.\n\n\n\n\nYou can also directly obtain the \npydot.Graph\n object and render it yourself,\nfor example to show it in an ipython notebook :\n\n\nfrom IPython.display import SVG\nfrom keras.utils.visualize_util import to_graph\n\nSVG(to_graph(model).create(prog='dot', format='svg'))", 
            "title": "Visualization"
        }, 
        {
            "location": "/visualization/#model-visualization", 
            "text": "The  keras.utils.visualize_util  module provides utility functions to plot\na Keras model (using graphviz).  This will plot a graph of the model and save it to a file:  from keras.utils.visualize_util import plot\nplot(model, to_file='model.png')  plot  takes two optional arguments:   recursive  (defaults to True) controls whether we recursively explore container layers.  show_shape  (defaults to False) controls whether output shapes are shown in the graph.   You can also directly obtain the  pydot.Graph  object and render it yourself,\nfor example to show it in an ipython notebook :  from IPython.display import SVG\nfrom keras.utils.visualize_util import to_graph\n\nSVG(to_graph(model).create(prog='dot', format='svg'))", 
            "title": "Model visualization"
        }, 
        {
            "location": "/layers/core/", 
            "text": "[source]\n\n\nLayer\n\n\nkeras.layers.core.Layer()\n\n\n\n\nAbstract base layer class.\n\n\nAll Keras layers accept certain keyword arguments:\n\n\n\n\ntrainable\n: boolean. Set to \"False\" before model compilation\n    to freeze layer weights (they won't be updated further\n    during training).\n\n\ninput_shape\n: a tuple of integers specifying the expected shape\n    of the input samples. Does not includes the batch size.\n    (e.g. \n(100,)\n for 100-dimensional inputs).\n\n\nbatch_input_shape\n: a tuple of integers specifying the expected\n    shape of a batch of input samples. Includes the batch size\n    (e.g. \n(32, 100)\n for a batch of 32 100-dimensional inputs).\n\n\n\n\nMethods\n\n\nclear_previous(reset_weights=True)\n\n\n\n\nUnlink a layer from its parent in the computational graph.\n\n\nThis is only allowed if the layer has an \ninput\n attribute.\n\n\ncount_params()\n\n\n\n\nReturn the total number of floats (or ints)\ncomposing the weights of the layer.\n\n\nget_config()\n\n\n\n\nReturn the parameters of the layer, as a dictionary.\n\n\nget_input(train=False)\n\n\n\n\nget_output(train=False)\n\n\n\n\nget_output_mask(train=None)\n\n\n\n\nFor some models (such as RNNs) you want a way of being able to mark\nsome output data-points as \"masked\",\nso they are not used in future calculations.\nIn such a model, get_output_mask() should return a mask\nof one less dimension than get_output()\n(so if get_output is (nb_samples, nb_timesteps, nb_dimensions),\nthen the mask is (nb_samples, nb_timesteps),\nwith a one for every unmasked datapoint,\nand a zero for every masked one.\n\n\nIf there is \nno\n masking then it shall return None.\nFor instance if you attach an Activation layer (they support masking)\nto a layer with an output_mask, then that Activation shall\nalso have an output_mask.\nIf you attach it to a layer with no such mask,\nthen the Activation's get_output_mask shall return None.\n\n\nSome layers have an output_mask even if their input is unmasked,\nnotably Embedding which can turn the entry \"0\" into\na mask.\n\n\nget_weights()\n\n\n\n\nReturn the weights of the layer,\nas a list of numpy arrays.\n\n\nset_input_shape(input_shape)\n\n\n\n\nset_previous(layer, reset_weights=True)\n\n\n\n\nConnect a layer to its parent in the computational graph.\n\n\nset_weights(weights)\n\n\n\n\nSet the weights of the layer.\n\n\n\n\nweights\n: a list of numpy arrays. The number\nof arrays and their shape must match\nnumber of the dimensions of the weights\nof the layer (i.e. it should match the\noutput of \nget_weights\n).\n\n\n\n\nsupports_masked_input()\n\n\n\n\nWhether or not this layer respects the output mask of its previous\nlayer in its calculations.\nIf you try to attach a layer that does \nnot\n support masked_input to\na layer that gives a non-None output_mask(), an error will be raised.\n\n\n\n\n[source]\n\n\nMasking\n\n\nkeras.layers.core.Masking(mask_value=0.0)\n\n\n\n\nMask an input sequence by using a mask value to identify padding.\n\n\nThis layer copies the input to the output layer with identified padding\nreplaced with 0s and creates an output mask in the process.\n\n\nAt each timestep, if the values all equal \nmask_value\n,\nthen the corresponding mask value for the timestep is 0 (skipped),\notherwise it is 1.\n\n\n\n\n[source]\n\n\nMerge\n\n\nkeras.layers.core.Merge(layers, mode='sum', concat_axis=-1, dot_axes=-1)\n\n\n\n\nMerge the output of a list of layers or containers into a single tensor.\n\n\nArguments\n\n\n\n\nmode\n: one of {sum, mul, concat, ave, join, cos, dot}.\n\n\nsum\n: sum the outputs (shapes must match)\n\n\nmul\n: multiply the outputs element-wise (shapes must match)\n\n\nconcat\n: concatenate the outputs along the axis specified by \nconcat_axis\n\n\nave\n: average the outputs (shapes must match)\n\n\njoin\n: places the outputs in an OrderedDict (inputs must be named)\n\n\n\n\n\n\nconcat_axis\n: axis to use in \nconcat\n mode.\n\n\ndot_axes\n: axis or axes to use in \ndot\n mode\n    (see \nthe Numpy documentation\n for more details).\n\n\n\n\nExamples\n\n\nleft = Sequential()\nleft.add(Dense(50, input_shape=(784,)))\nleft.add(Activation('relu'))\n\nright = Sequential()\nright.add(Dense(50, input_shape=(784,)))\nright.add(Activation('relu'))\n\nmodel = Sequential()\nmodel.add(Merge([left, right], mode='sum'))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nmodel.fit([X_train, X_train], Y_train, batch_size=128, nb_epoch=20,\n      validation_data=([X_test, X_test], Y_test))\n\n\n\n\n\n\n[source]\n\n\nTimeDistributedMerge\n\n\nkeras.layers.core.TimeDistributedMerge(mode='sum')\n\n\n\n\nSum/multiply/average over the outputs of a TimeDistributed layer.\n\n\nInput shape\n\n\n3D tensor with shape: \n(samples, steps, features)\n.\n\n\nOutput shape\n\n\n2D tensor with shape: \n(samples, features)\n.\n\n\nArguments\n\n\n\n\nmode\n: one of {'sum', 'mul', 'ave'}\n\n\n\n\n\n\n[source]\n\n\nDropout\n\n\nkeras.layers.core.Dropout(p)\n\n\n\n\nApply Dropout to the input. Dropout consists in randomly setting\na fraction \np\n of input units to 0 at each update during training time,\nwhich helps prevent overfitting.\n\n\nArguments\n\n\n\n\np\n: float between 0 and 1. Fraction of the input units to drop.\n\n\n\n\nReferences\n\n\n\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting\n\n\n\n\n\n\n[source]\n\n\nActivation\n\n\nkeras.layers.core.Activation(activation)\n\n\n\n\nApply an activation function to an output.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as input.\n\n\n\n\n\n\n_Arguments\n_:\n\n\n\n\n\n\nactivation\n: name of activation function to use\n\n\n\n\n(see\n: \nactivations\n),\nor alternatively, a Theano or TensorFlow operation.\n\n\n\n\n\n\n\n\n\n\n[source]\n\n\nReshape\n\n\nkeras.layers.core.Reshape(dims)\n\n\n\n\nReshape an output to a certain shape.\n\n\nInput shape\n\n\nArbitrary, although all dimensions in the input shaped must be fixed.\nUse the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\n(batch_size,) + dims\n\n\nArguments\n\n\n\n\ndims\n: target shape. Tuple of integers,\n    does not include the samples dimension (batch size).\n\n\n\n\n\n\n[source]\n\n\nPermute\n\n\nkeras.layers.core.Permute(dims)\n\n\n\n\nPermute the dimensions of the input according to a given pattern.\n\n\nUseful for e.g. connecting RNNs and convnets together.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame as the input shape, but with the dimensions re-ordered according\nto the specified pattern.\n\n\nArguments\n\n\n\n\ndims\n: Tuple of integers. Permutation pattern, does not include the\n    samples dimension. Indexing starts at 1.\n    For instance, \n(2, 1)\n permutes the first and second dimension\n    of the input.\n\n\n\n\n\n\n[source]\n\n\nFlatten\n\n\nkeras.layers.core.Flatten()\n\n\n\n\nFlatten the input. Does not affect the batch size.\n\n\nInput shape\n\n\nArbitrary, although all dimensions in the input shape must be fixed.\nUse the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\n(batch_size,)\n\n\n\n\n[source]\n\n\nRepeatVector\n\n\nkeras.layers.core.RepeatVector(n)\n\n\n\n\nRepeat the input n times.\n\n\nInput shape\n\n\n2D tensor of shape \n(nb_samples, features)\n.\n\n\nOutput shape\n\n\n3D tensor of shape \n(nb_samples, n, features)\n.\n\n\nArguments\n\n\n\n\nn\n: integer, repetition factor.\n\n\n\n\n\n\n[source]\n\n\nDense\n\n\nkeras.layers.core.Dense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)\n\n\n\n\nJust your regular fully connected NN layer.\n\n\nInput shape\n\n\n2D tensor with shape: \n(nb_samples, input_dim)\n.\n\n\nOutput shape\n\n\n2D tensor with shape: \n(nb_samples, output_dim)\n.\n\n\nArguments\n\n\n\n\noutput_dim\n: int \n 0.\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a \nweights\n argument.\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape \n(input_dim, output_dim)\n\n    and (output_dim,) for weights and biases respectively.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ninput_dim\n: dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument \ninput_shape\n)\n    is required when using this layer as the first layer in a model.\n\n\n\n\n\n\n[source]\n\n\nTimeDistributedDense\n\n\nkeras.layers.core.TimeDistributedDense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None, input_length=None)\n\n\n\n\nApply a same Dense layer for each dimension[1] (time_dimension) input.\nEspecially useful after a recurrent network with 'return_sequence=True'.\n\n\nInput shape\n\n\n3D tensor with shape \n(nb_sample, time_dimension, input_dim)\n.\n\n\nOutput shape\n\n\n3D tensor with shape \n(nb_sample, time_dimension, output_dim)\n.\n\n\nArguments\n\n\n\n\noutput_dim\n: int \n 0.\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a \nweights\n argument.\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape \n(input_dim, output_dim)\n\n    and (output_dim,) for weights and biases respectively.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ninput_dim\n: dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument \ninput_shape\n)\n    is required when using this layer as the first layer in a model.\n\n\n\n\n\n\n[source]\n\n\nActivityRegularization\n\n\nkeras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)\n\n\n\n\nLayer that passes through its input unchanged, but applies an update\nto the cost function based on the activity.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as input.\n\n\nArguments\n\n\n\n\nl1\n: L1 regularization factor.\n\n\nl2\n: L2 regularization factor.\n\n\n\n\n\n\n[source]\n\n\nAutoEncoder\n\n\nkeras.layers.core.AutoEncoder(encoder, decoder, output_reconstruction=True, weights=None)\n\n\n\n\nA customizable autoencoder model.\n\n\nInput shape\n\n\nSame as encoder input.\n\n\nOutput shape\n\n\nIf \noutput_reconstruction = True\n then dim(input) = dim(output)\nelse dim(output) = dim(hidden).\n\n\nArguments\n\n\n\n\nencoder\n: A \nlayer\n or \nlayer container\n.\n\n\ndecoder\n: A \nlayer\n or \nlayer container\n.\n\n\noutput_reconstruction\n: If this is \nFalse\n,\n    the output of the autoencoder is the output of\n    the deepest hidden layer.\n    Otherwise, the output of the final decoder layer is returned.\n\n\nweights\n: list of numpy arrays to set as initial weights.\n\n\n\n\nExamples\n\n\nfrom keras.layers import containers, AutoEncoder, Dense\nfrom keras import models\n\n# input shape: (nb_samples, 32)\nencoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])\ndecoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])\n\nautoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)\nmodel = models.Sequential()\nmodel.add(autoencoder)\n\n# training the autoencoder:\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(X_train, X_train, nb_epoch=10)\n\n# predicting compressed representations of inputs:\nautoencoder.output_reconstruction = False  # the model has to be recompiled after modifying this property\nmodel.compile(optimizer='sgd', loss='mse')\nrepresentations = model.predict(X_test)\n\n# the model is still trainable, although it now expects compressed representations as targets:\nmodel.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless\n\n# to keep training against the original inputs, just switch back output_reconstruction to True:\nautoencoder.output_reconstruction = True\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(X_train, X_train, nb_epoch=10)\n\n\n\n\n\n\n[source]\n\n\nMaxoutDense\n\n\nkeras.layers.core.MaxoutDense(output_dim, nb_feature=4, init='glorot_uniform', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)\n\n\n\n\nA dense maxout layer.\n\n\nA \nMaxoutDense\n layer takes the element-wise maximum of\n\nnb_feature\n \nDense(input_dim, output_dim)\n linear layers.\nThis allows the layer to learn a convex,\npiecewise linear activation function over the inputs.\n\n\nNote that this is a \nlinear\n layer;\nif you wish to apply activation function\n(you shouldn't need to --they are universal function approximators),\nan \nActivation\n layer must be added after.\n\n\nInput shape\n\n\n2D tensor with shape: \n(nb_samples, input_dim)\n.\n\n\nOutput shape\n\n\n2D tensor with shape: \n(nb_samples, output_dim)\n.\n\n\nReferences\n\n\n\n\nMaxout Networks\n\n\n\n\n\n\n[source]\n\n\nLambda\n\n\nkeras.layers.core.Lambda(function, output_shape=None, arguments={})\n\n\n\n\nUsed for evaluating an arbitrary Theano / TensorFlow expression\non the output of the previous layer.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument input_shape\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSpecified by \noutput_shape\n argument.\n\n\nArguments\n\n\n\n\nfunction\n: The function to be evaluated.\n    Takes one argument: the output of previous layer\n\n\noutput_shape\n: Expected output shape from function.\n    Could be a tuple or a function of the shape of the input\n\n\narguments\n: optional dictionary of keyword arguments to be passed\n    to the function.\n\n\n\n\n\n\n[source]\n\n\nLambdaMerge\n\n\nkeras.layers.core.LambdaMerge(layers, function, output_shape=None, arguments={})\n\n\n\n\nLambdaMerge layer for evaluating an arbitrary Theano / TensorFlow\nfunction over multiple inputs.\n\n\nOutput shape\n\n\nSpecified by output_shape argument\n\n\nArguments\n\n\nlayers - Input layers. Similar to layers argument of Merge\nfunction - The function to be evaluated. Takes one argument:\n    list of outputs from input layers\noutput_shape - Expected output shape from function.\n    Could be a tuple or a function of list of input shapes\n- \narguments\n: optional dictionary of keyword arguments to be passed\n    to the function.\n\n\n\n\n[source]\n\n\nSiamese\n\n\nkeras.layers.core.Siamese(layer, inputs, merge_mode='concat', concat_axis=1, dot_axes=-1, is_graph=False)\n\n\n\n\nShare a layer accross multiple inputs.\n\n\nFor instance, this allows you to applied e.g.\na same \nDense\n layer to the output of two\ndifferent layers in a graph.\n\n\nOutput shape\n\n\nDepends on merge_mode argument\n\n\nArguments\n\n\n\n\nlayer\n: The layer to be shared across multiple inputs\n\n\ninputs\n: Inputs to the shared layer\n\n\nmerge_mode\n: Same meaning as \nmode\n argument of Merge layer\n\n\nconcat_axis\n: Same meaning as \nconcat_axis\n argument of Merge layer\n\n\ndot_axes\n: Same meaning as \ndot_axes\n argument of Merge layer\n\n\nis_graph\n: Should be set to True when used inside \nGraph\n\n\n\n\n\n\n[source]\n\n\nHighway\n\n\nkeras.layers.core.Highway(init='glorot_uniform', transform_bias=-2, activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)\n\n\n\n\nDensely connected highway network,\na natural extension of LSTMs to feedforward networks.\n\n\nInput shape\n\n\n2D tensor with shape: \n(nb_samples, input_dim)\n.\n\n\nOutput shape\n\n\n2D tensor with shape: \n(nb_samples, input_dim)\n.\n\n\nArguments\n\n\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a \nweights\n argument.\n\n\ntransform_bias\n: value for the bias to take on initially (default -2)\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape \n(input_dim, output_dim)\n\n    and (output_dim,) for weights and biases respectively.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ninput_dim\n: dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument \ninput_shape\n)\n    is required when using this layer as the first layer in a model.\n\n\n\n\nReferences\n\n\n\n\nHighway Networks", 
            "title": "Core Layers"
        }, 
        {
            "location": "/layers/core/#layer", 
            "text": "keras.layers.core.Layer()  Abstract base layer class.  All Keras layers accept certain keyword arguments:   trainable : boolean. Set to \"False\" before model compilation\n    to freeze layer weights (they won't be updated further\n    during training).  input_shape : a tuple of integers specifying the expected shape\n    of the input samples. Does not includes the batch size.\n    (e.g.  (100,)  for 100-dimensional inputs).  batch_input_shape : a tuple of integers specifying the expected\n    shape of a batch of input samples. Includes the batch size\n    (e.g.  (32, 100)  for a batch of 32 100-dimensional inputs).", 
            "title": "Layer"
        }, 
        {
            "location": "/layers/core/#methods", 
            "text": "clear_previous(reset_weights=True)  Unlink a layer from its parent in the computational graph.  This is only allowed if the layer has an  input  attribute.  count_params()  Return the total number of floats (or ints)\ncomposing the weights of the layer.  get_config()  Return the parameters of the layer, as a dictionary.  get_input(train=False)  get_output(train=False)  get_output_mask(train=None)  For some models (such as RNNs) you want a way of being able to mark\nsome output data-points as \"masked\",\nso they are not used in future calculations.\nIn such a model, get_output_mask() should return a mask\nof one less dimension than get_output()\n(so if get_output is (nb_samples, nb_timesteps, nb_dimensions),\nthen the mask is (nb_samples, nb_timesteps),\nwith a one for every unmasked datapoint,\nand a zero for every masked one.  If there is  no  masking then it shall return None.\nFor instance if you attach an Activation layer (they support masking)\nto a layer with an output_mask, then that Activation shall\nalso have an output_mask.\nIf you attach it to a layer with no such mask,\nthen the Activation's get_output_mask shall return None.  Some layers have an output_mask even if their input is unmasked,\nnotably Embedding which can turn the entry \"0\" into\na mask.  get_weights()  Return the weights of the layer,\nas a list of numpy arrays.  set_input_shape(input_shape)  set_previous(layer, reset_weights=True)  Connect a layer to its parent in the computational graph.  set_weights(weights)  Set the weights of the layer.   weights : a list of numpy arrays. The number\nof arrays and their shape must match\nnumber of the dimensions of the weights\nof the layer (i.e. it should match the\noutput of  get_weights ).   supports_masked_input()  Whether or not this layer respects the output mask of its previous\nlayer in its calculations.\nIf you try to attach a layer that does  not  support masked_input to\na layer that gives a non-None output_mask(), an error will be raised.   [source]", 
            "title": "Methods"
        }, 
        {
            "location": "/layers/core/#masking", 
            "text": "keras.layers.core.Masking(mask_value=0.0)  Mask an input sequence by using a mask value to identify padding.  This layer copies the input to the output layer with identified padding\nreplaced with 0s and creates an output mask in the process.  At each timestep, if the values all equal  mask_value ,\nthen the corresponding mask value for the timestep is 0 (skipped),\notherwise it is 1.   [source]", 
            "title": "Masking"
        }, 
        {
            "location": "/layers/core/#merge", 
            "text": "keras.layers.core.Merge(layers, mode='sum', concat_axis=-1, dot_axes=-1)  Merge the output of a list of layers or containers into a single tensor.  Arguments   mode : one of {sum, mul, concat, ave, join, cos, dot}.  sum : sum the outputs (shapes must match)  mul : multiply the outputs element-wise (shapes must match)  concat : concatenate the outputs along the axis specified by  concat_axis  ave : average the outputs (shapes must match)  join : places the outputs in an OrderedDict (inputs must be named)    concat_axis : axis to use in  concat  mode.  dot_axes : axis or axes to use in  dot  mode\n    (see  the Numpy documentation  for more details).   Examples  left = Sequential()\nleft.add(Dense(50, input_shape=(784,)))\nleft.add(Activation('relu'))\n\nright = Sequential()\nright.add(Dense(50, input_shape=(784,)))\nright.add(Activation('relu'))\n\nmodel = Sequential()\nmodel.add(Merge([left, right], mode='sum'))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nmodel.fit([X_train, X_train], Y_train, batch_size=128, nb_epoch=20,\n      validation_data=([X_test, X_test], Y_test))   [source]", 
            "title": "Merge"
        }, 
        {
            "location": "/layers/core/#timedistributedmerge", 
            "text": "keras.layers.core.TimeDistributedMerge(mode='sum')  Sum/multiply/average over the outputs of a TimeDistributed layer.  Input shape  3D tensor with shape:  (samples, steps, features) .  Output shape  2D tensor with shape:  (samples, features) .  Arguments   mode : one of {'sum', 'mul', 'ave'}    [source]", 
            "title": "TimeDistributedMerge"
        }, 
        {
            "location": "/layers/core/#dropout", 
            "text": "keras.layers.core.Dropout(p)  Apply Dropout to the input. Dropout consists in randomly setting\na fraction  p  of input units to 0 at each update during training time,\nwhich helps prevent overfitting.  Arguments   p : float between 0 and 1. Fraction of the input units to drop.   References   Dropout: A Simple Way to Prevent Neural Networks from Overfitting    [source]", 
            "title": "Dropout"
        }, 
        {
            "location": "/layers/core/#activation", 
            "text": "keras.layers.core.Activation(activation)  Apply an activation function to an output.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as input.    _Arguments _:    activation : name of activation function to use   (see :  activations ),\nor alternatively, a Theano or TensorFlow operation.      [source]", 
            "title": "Activation"
        }, 
        {
            "location": "/layers/core/#reshape", 
            "text": "keras.layers.core.Reshape(dims)  Reshape an output to a certain shape.  Input shape  Arbitrary, although all dimensions in the input shaped must be fixed.\nUse the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  (batch_size,) + dims  Arguments   dims : target shape. Tuple of integers,\n    does not include the samples dimension (batch size).    [source]", 
            "title": "Reshape"
        }, 
        {
            "location": "/layers/core/#permute", 
            "text": "keras.layers.core.Permute(dims)  Permute the dimensions of the input according to a given pattern.  Useful for e.g. connecting RNNs and convnets together.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same as the input shape, but with the dimensions re-ordered according\nto the specified pattern.  Arguments   dims : Tuple of integers. Permutation pattern, does not include the\n    samples dimension. Indexing starts at 1.\n    For instance,  (2, 1)  permutes the first and second dimension\n    of the input.    [source]", 
            "title": "Permute"
        }, 
        {
            "location": "/layers/core/#flatten", 
            "text": "keras.layers.core.Flatten()  Flatten the input. Does not affect the batch size.  Input shape  Arbitrary, although all dimensions in the input shape must be fixed.\nUse the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  (batch_size,)   [source]", 
            "title": "Flatten"
        }, 
        {
            "location": "/layers/core/#repeatvector", 
            "text": "keras.layers.core.RepeatVector(n)  Repeat the input n times.  Input shape  2D tensor of shape  (nb_samples, features) .  Output shape  3D tensor of shape  (nb_samples, n, features) .  Arguments   n : integer, repetition factor.    [source]", 
            "title": "RepeatVector"
        }, 
        {
            "location": "/layers/core/#dense", 
            "text": "keras.layers.core.Dense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)  Just your regular fully connected NN layer.  Input shape  2D tensor with shape:  (nb_samples, input_dim) .  Output shape  2D tensor with shape:  (nb_samples, output_dim) .  Arguments   output_dim : int   0.  init : name of initialization function for the weights of the layer\n    (see  initializations ),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a  weights  argument.  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape  (input_dim, output_dim) \n    and (output_dim,) for weights and biases respectively.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  input_dim : dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument  input_shape )\n    is required when using this layer as the first layer in a model.    [source]", 
            "title": "Dense"
        }, 
        {
            "location": "/layers/core/#timedistributeddense", 
            "text": "keras.layers.core.TimeDistributedDense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None, input_length=None)  Apply a same Dense layer for each dimension[1] (time_dimension) input.\nEspecially useful after a recurrent network with 'return_sequence=True'.  Input shape  3D tensor with shape  (nb_sample, time_dimension, input_dim) .  Output shape  3D tensor with shape  (nb_sample, time_dimension, output_dim) .  Arguments   output_dim : int   0.  init : name of initialization function for the weights of the layer\n    (see  initializations ),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a  weights  argument.  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape  (input_dim, output_dim) \n    and (output_dim,) for weights and biases respectively.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  input_dim : dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument  input_shape )\n    is required when using this layer as the first layer in a model.    [source]", 
            "title": "TimeDistributedDense"
        }, 
        {
            "location": "/layers/core/#activityregularization", 
            "text": "keras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)  Layer that passes through its input unchanged, but applies an update\nto the cost function based on the activity.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as input.  Arguments   l1 : L1 regularization factor.  l2 : L2 regularization factor.    [source]", 
            "title": "ActivityRegularization"
        }, 
        {
            "location": "/layers/core/#autoencoder", 
            "text": "keras.layers.core.AutoEncoder(encoder, decoder, output_reconstruction=True, weights=None)  A customizable autoencoder model.  Input shape  Same as encoder input.  Output shape  If  output_reconstruction = True  then dim(input) = dim(output)\nelse dim(output) = dim(hidden).  Arguments   encoder : A  layer  or  layer container .  decoder : A  layer  or  layer container .  output_reconstruction : If this is  False ,\n    the output of the autoencoder is the output of\n    the deepest hidden layer.\n    Otherwise, the output of the final decoder layer is returned.  weights : list of numpy arrays to set as initial weights.   Examples  from keras.layers import containers, AutoEncoder, Dense\nfrom keras import models\n\n# input shape: (nb_samples, 32)\nencoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])\ndecoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])\n\nautoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)\nmodel = models.Sequential()\nmodel.add(autoencoder)\n\n# training the autoencoder:\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(X_train, X_train, nb_epoch=10)\n\n# predicting compressed representations of inputs:\nautoencoder.output_reconstruction = False  # the model has to be recompiled after modifying this property\nmodel.compile(optimizer='sgd', loss='mse')\nrepresentations = model.predict(X_test)\n\n# the model is still trainable, although it now expects compressed representations as targets:\nmodel.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless\n\n# to keep training against the original inputs, just switch back output_reconstruction to True:\nautoencoder.output_reconstruction = True\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(X_train, X_train, nb_epoch=10)   [source]", 
            "title": "AutoEncoder"
        }, 
        {
            "location": "/layers/core/#maxoutdense", 
            "text": "keras.layers.core.MaxoutDense(output_dim, nb_feature=4, init='glorot_uniform', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)  A dense maxout layer.  A  MaxoutDense  layer takes the element-wise maximum of nb_feature   Dense(input_dim, output_dim)  linear layers.\nThis allows the layer to learn a convex,\npiecewise linear activation function over the inputs.  Note that this is a  linear  layer;\nif you wish to apply activation function\n(you shouldn't need to --they are universal function approximators),\nan  Activation  layer must be added after.  Input shape  2D tensor with shape:  (nb_samples, input_dim) .  Output shape  2D tensor with shape:  (nb_samples, output_dim) .  References   Maxout Networks    [source]", 
            "title": "MaxoutDense"
        }, 
        {
            "location": "/layers/core/#lambda", 
            "text": "keras.layers.core.Lambda(function, output_shape=None, arguments={})  Used for evaluating an arbitrary Theano / TensorFlow expression\non the output of the previous layer.  Input shape  Arbitrary. Use the keyword argument input_shape\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Specified by  output_shape  argument.  Arguments   function : The function to be evaluated.\n    Takes one argument: the output of previous layer  output_shape : Expected output shape from function.\n    Could be a tuple or a function of the shape of the input  arguments : optional dictionary of keyword arguments to be passed\n    to the function.    [source]", 
            "title": "Lambda"
        }, 
        {
            "location": "/layers/core/#lambdamerge", 
            "text": "keras.layers.core.LambdaMerge(layers, function, output_shape=None, arguments={})  LambdaMerge layer for evaluating an arbitrary Theano / TensorFlow\nfunction over multiple inputs.  Output shape  Specified by output_shape argument  Arguments  layers - Input layers. Similar to layers argument of Merge\nfunction - The function to be evaluated. Takes one argument:\n    list of outputs from input layers\noutput_shape - Expected output shape from function.\n    Could be a tuple or a function of list of input shapes\n-  arguments : optional dictionary of keyword arguments to be passed\n    to the function.   [source]", 
            "title": "LambdaMerge"
        }, 
        {
            "location": "/layers/core/#siamese", 
            "text": "keras.layers.core.Siamese(layer, inputs, merge_mode='concat', concat_axis=1, dot_axes=-1, is_graph=False)  Share a layer accross multiple inputs.  For instance, this allows you to applied e.g.\na same  Dense  layer to the output of two\ndifferent layers in a graph.  Output shape  Depends on merge_mode argument  Arguments   layer : The layer to be shared across multiple inputs  inputs : Inputs to the shared layer  merge_mode : Same meaning as  mode  argument of Merge layer  concat_axis : Same meaning as  concat_axis  argument of Merge layer  dot_axes : Same meaning as  dot_axes  argument of Merge layer  is_graph : Should be set to True when used inside  Graph    [source]", 
            "title": "Siamese"
        }, 
        {
            "location": "/layers/core/#highway", 
            "text": "keras.layers.core.Highway(init='glorot_uniform', transform_bias=-2, activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None)  Densely connected highway network,\na natural extension of LSTMs to feedforward networks.  Input shape  2D tensor with shape:  (nb_samples, input_dim) .  Output shape  2D tensor with shape:  (nb_samples, input_dim) .  Arguments   init : name of initialization function for the weights of the layer\n    (see  initializations ),\n    or alternatively, Theano function to use for weights\n    initialization. This parameter is only relevant\n    if you don't pass a  weights  argument.  transform_bias : value for the bias to take on initially (default -2)  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.\n    The list should have 2 elements, of shape  (input_dim, output_dim) \n    and (output_dim,) for weights and biases respectively.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  input_dim : dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument  input_shape )\n    is required when using this layer as the first layer in a model.   References   Highway Networks", 
            "title": "Highway"
        }, 
        {
            "location": "/layers/convolutional/", 
            "text": "[source]\n\n\nMaxPooling1D\n\n\nkeras.layers.convolutional.MaxPooling1D(pool_length=2, stride=None, border_mode='valid')\n\n\n\n\nMax pooling operation for temporal data.\n\n\nInput shape\n\n\n3D tensor with shape: \n(samples, steps, features)\n.\n\n\nOutput shape\n\n\n3D tensor with shape: \n(samples, downsampled_steps, features)\n.\n\n\nArguments\n\n\n\n\npool_length\n: factor by which to downscale. 2 will halve the input.\n\n\nstride\n: integer or None. Stride value.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nNote\n: 'same' will only work with TensorFlow for the time being.\n\n\n\n\n\n\n\n\n\n\n[source]\n\n\nAveragePooling1D\n\n\nkeras.layers.convolutional.AveragePooling1D(pool_length=2, stride=None, border_mode='valid')\n\n\n\n\nAverage pooling for temporal data.\n\n\nInput shape\n\n\n3D tensor with shape: \n(samples, steps, features)\n.\n\n\nOutput shape\n\n\n3D tensor with shape: \n(samples, downsampled_steps, features)\n.\n\n\nArguments\n\n\n\n\npool_length\n: factor by which to downscale. 2 will halve the input.\n\n\nstride\n: integer or None. Stride value.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nNote\n: 'same' will only work with TensorFlow for the time being.\n\n\n\n\n\n\n\n\n\n\n[source]\n\n\nMaxPooling2D\n\n\nkeras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\nMax pooling operation for spatial data.\n\n\nInput shape\n\n\n4D tensor with shape:\n\n(samples, channels, rows, cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, rows, cols, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n4D tensor with shape:\n\n(nb_samples, channels, pooled_rows, pooled_cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, pooled_rows, pooled_cols, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\npool_size\n: tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the image in each dimension.\n\n\nstrides\n: tuple of 2 integers, or None. Strides values.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nNote\n: 'same' will only work with TensorFlow for the time being.\n\n\n\n\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.\n\n\n\n\n\n\n[source]\n\n\nAveragePooling2D\n\n\nkeras.layers.convolutional.AveragePooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\nAverage pooling operation for spatial data.\n\n\nInput shape\n\n\n4D tensor with shape:\n\n(samples, channels, rows, cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, rows, cols, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n4D tensor with shape:\n\n(nb_samples, channels, pooled_rows, pooled_cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, pooled_rows, pooled_cols, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\npool_size\n: tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the image in each dimension.\n\n\nstrides\n: tuple of 2 integers, or None. Strides values.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nNote\n: 'same' will only work with TensorFlow for the time being.\n\n\n\n\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.\n\n\n\n\n\n\n[source]\n\n\nMaxPooling3D\n\n\nkeras.layers.convolutional.MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\nMax pooling operation for 3D data (spatial or spatio-temporal).\n\n\n\n\nNote\n: this layer will only work with Theano for the time being.\n\n\n\n\nInput shape\n\n\n5D tensor with shape:\n\n(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n5D tensor with shape:\n\n(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\npool_size\n: tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.\n\n\nstrides\n: tuple of 3 integers, or None. Strides values.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.\n\n\n\n\n\n\n[source]\n\n\nConvolution1D\n\n\nkeras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None, input_length=None)\n\n\n\n\nConvolution operator for filtering neighborhoods of one-dimensional inputs.\nWhen using this layer as the first layer in a model,\neither provide the keyword argument \ninput_dim\n\n(int, e.g. 128 for sequences of 128-dimensional vectors),\nor \ninput_shape\n (tuple of integers, e.g. (10, 128) for sequences\nof 10 vectors of 128-dimensional vectors).\n\n\nInput shape\n\n\n3D tensor with shape: \n(samples, steps, input_dim)\n.\n\n\nOutput shape\n\n\n3D tensor with shape: \n(samples, new_steps, nb_filter)\n.\n\nsteps\n value might have changed due to padding.\n\n\nArguments\n\n\n\n\nnb_filter\n: Number of convolution kernels to use\n    (dimensionality of the output).\n\n\nfilter_length\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n),\n    or alternatively, Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass a \nweights\n argument.\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nsubsample_length\n: factor by which to subsample output.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ninput_dim\n: Number of channels/dimensions in the input.\n    Either this argument or the keyword argument \ninput_shape\nmust be\n    provided when using this layer as the first layer in a model.\n\n\ninput_length\n: Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n    \nFlatten\n then \nDense\n layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n\n\n\n\n\n\n[source]\n\n\nConvolution2D\n\n\nkeras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None)\n\n\n\n\nConvolution operator for filtering windows of two-dimensional inputs.\nWhen using this layer as the first layer in a model,\nprovide the keyword argument \ninput_shape\n\n(tuple of integers, does not include the sample axis),\ne.g. \ninput_shape=(3, 128, 128)\n for 128x128 RGB pictures.\n\n\nInput shape\n\n\n4D tensor with shape:\n\n(samples, channels, rows, cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, rows, cols, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n4D tensor with shape:\n\n(samples, nb_filter, new_rows, new_cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, new_rows, new_cols, nb_filter)\n if dim_ordering='tf'.\n\nrows\n and \ncols\n values might have changed due to padding.\n\n\nArguments\n\n\n\n\nnb_filter\n: Number of convolution filters to use.\n\n\nnb_row\n: Number of rows in the convolution kernel.\n\n\nnb_col\n: Number of columns in the convolution kernel.\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n), or alternatively,\n    Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass\n    a \nweights\n argument.\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nsubsample\n: tuple of length 2. Factor by which to subsample output.\n    Also called strides elsewhere.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.\n\n\n\n\n\n\n[source]\n\n\nConvolution3D\n\n\nkeras.layers.convolutional.Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None)\n\n\n\n\nConvolution operator for filtering windows of three-dimensional inputs.\nWhen using this layer as the first layer in a model,\nprovide the keyword argument \ninput_shape\n\n(tuple of integers, does not include the sample axis),\ne.g. \ninput_shape=(3, 10, 128, 128)\n for 10 frames of 128x128 RGB pictures.\n\n\n\n\nNote\n: this layer will only work with Theano for the time being.\n\n\n\n\nInput shape\n\n\n5D tensor with shape:\n\n(samples, channels, conv_dim1, conv_dim2, conv_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, conv_dim1, conv_dim2, conv_dim3, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n5D tensor with shape:\n\n(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)\n if dim_ordering='tf'.\n\nnew_conv_dim1\n, \nnew_conv_dim2\n and \nnew_conv_dim3\n values might have changed due to padding.\n\n\nArguments\n\n\n\n\nnb_filter\n: Number of convolution filters to use.\n\n\nkernel_dim1\n: Length of the first dimension in the covolution kernel.\n\n\nkernel_dim2\n: Length of the second dimension in the convolution kernel.\n\n\nkernel_dim3\n: Length of the third dimension in the convolution kernel.\n\n\ninit\n: name of initialization function for the weights of the layer\n    (see \ninitializations\n), or alternatively,\n    Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass\n    a \nweights\n argument.\n\n\nactivation\n: name of activation function to use\n    (see \nactivations\n),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).\n\n\nweights\n: list of numpy arrays to set as initial weights.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\nsubsample\n: tuple of length 3. Factor by which to subsample output.\n    Also called strides elsewhere.\n\n\nNote\n: 'subsample' is implemented by slicing the output of conv3d with strides=(1,1,1).\n\n\n\n\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the main weights matrix.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\nactivity_regularizer\n: instance of \nActivityRegularizer\n,\n    applied to the network output.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.\n\n\nb_constraint\n: instance of the \nconstraints\n module,\n    applied to the bias.\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.\n\n\n\n\n\n\n[source]\n\n\nAveragePooling3D\n\n\nkeras.layers.convolutional.AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\nAverage pooling operation for 3D data (spatial or spatio-temporal).\n\n\n\n\nNote\n: this layer will only work with Theano for the time being.\n\n\n\n\nInput shape\n\n\n5D tensor with shape:\n\n(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n5D tensor with shape:\n\n(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\npool_size\n: tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.\n\n\nstrides\n: tuple of 3 integers, or None. Strides values.\n\n\nborder_mode\n: 'valid' or 'same'.\n\n\ndim_ordering\n: 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.\n\n\n\n\n\n\n[source]\n\n\nUpSampling1D\n\n\nkeras.layers.convolutional.UpSampling1D(length=2)\n\n\n\n\nRepeat each temporal step \nlength\n times along the time axis.\n\n\nInput shape\n\n\n3D tensor with shape: \n(samples, steps, features)\n.\n\n\nOutput shape\n\n\n3D tensor with shape: \n(samples, upsampled_steps, features)\n.\n\n\n\n\n\n\n_Arguments\n_:\n\n\n\n\n\n\nlength\n: integer. Upsampling factor.\n\n\n\n\n\n\n\n\n[source]\n\n\nUpSampling2D\n\n\nkeras.layers.convolutional.UpSampling2D(size=(2, 2), dim_ordering='th')\n\n\n\n\nRepeat the rows and columns of the data\nby size[0] and size[1] respectively.\n\n\nInput shape\n\n\n4D tensor with shape:\n\n(samples, channels, rows, cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, rows, cols, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n4D tensor with shape:\n\n(samples, channels, upsampled_rows, upsampled_cols)\n if dim_ordering='th'\nor 4D tensor with shape:\n\n(samples, upsampled_rows, upsampled_cols, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\nsize\n: tuple of 2 integers. The upsampling factors for rows and columns.\n\n\ndim_ordering\n: 'th' or 'tf'.\n    In 'th' mode, the channels dimension (the depth)\n    is at index 1, in 'tf' mode is it at index 3.\n\n\n\n\n\n\n[source]\n\n\nUpSampling3D\n\n\nkeras.layers.convolutional.UpSampling3D(size=(2, 2, 2), dim_ordering='th')\n\n\n\n\nRepeat the first, second and third dimension of the data\nby size[0], size[1] and size[2] respectively.\n\n\n\n\nNote\n: this layer will only work with Theano for the time being.\n\n\n\n\nInput shape\n\n\n5D tensor with shape:\n\n(samples, channels, dim1, dim2, dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, dim1, dim2, dim3, channels)\n if dim_ordering='tf'.\n\n\nOutput shape\n\n\n5D tensor with shape:\n\n(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)\n if dim_ordering='th'\nor 5D tensor with shape:\n\n(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)\n if dim_ordering='tf'.\n\n\nArguments\n\n\n\n\nsize\n: tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.\n\n\ndim_ordering\n: 'th' or 'tf'.\n    In 'th' mode, the channels dimension (the depth)\n    is at index 1, in 'tf' mode is it at index 4.\n\n\n\n\n\n\n[source]\n\n\nZeroPadding1D\n\n\nkeras.layers.convolutional.ZeroPadding1D(padding=1)\n\n\n\n\nZero-padding layer for 1D input (e.g. temporal sequence).\n\n\nInput shape\n\n\n3D tensor with shape (samples, axis_to_pad, features)\n\n\nOutput shape\n\n\n3D tensor with shape (samples, padded_axis, features)\n\n\nArguments\n\n\n\n\npadding\n: int\n    How many zeros to add at the beginning and end of\n    the padding dimension (axis 1).\n\n\n\n\n\n\n[source]\n\n\nZeroPadding2D\n\n\nkeras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')\n\n\n\n\nZero-padding layer for 2D input (e.g. picture).\n\n\nInput shape\n\n\n4D tensor with shape:\n(samples, depth, first_axis_to_pad, second_axis_to_pad)\n\n\nOutput shape\n\n\n4D tensor with shape:\n(samples, depth, first_padded_axis, second_padded_axis)\n\n\nArguments\n\n\n\n\npadding\n: tuple of int (length 2)\n    How many zeros to add at the beginning and end of\n    the 2 padding dimensions (axis 3 and 4).\n\n\n\n\n\n\n[source]\n\n\nZeroPadding3D\n\n\nkeras.layers.convolutional.ZeroPadding3D(padding=(1, 1, 1), dim_ordering='th')\n\n\n\n\nZero-padding layer for 3D data (spatial or spatio-temporal).\n\n\n\n\nNote\n: this layer will only work with Theano for the time being.\n\n\n\n\nInput shape\n\n\n5D tensor with shape:\n(samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)\n\n\nOutput shape\n\n\n5D tensor with shape:\n(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)\n\n\nArguments\n\n\n\n\npadding\n: tuple of int (length 3)\n    How many zeros to add at the beginning and end of\n    the 3 padding dimensions (axis 3, 4 and 5).", 
            "title": "Convolutional Layers"
        }, 
        {
            "location": "/layers/convolutional/#maxpooling1d", 
            "text": "keras.layers.convolutional.MaxPooling1D(pool_length=2, stride=None, border_mode='valid')  Max pooling operation for temporal data.  Input shape  3D tensor with shape:  (samples, steps, features) .  Output shape  3D tensor with shape:  (samples, downsampled_steps, features) .  Arguments   pool_length : factor by which to downscale. 2 will halve the input.  stride : integer or None. Stride value.  border_mode : 'valid' or 'same'.  Note : 'same' will only work with TensorFlow for the time being.      [source]", 
            "title": "MaxPooling1D"
        }, 
        {
            "location": "/layers/convolutional/#averagepooling1d", 
            "text": "keras.layers.convolutional.AveragePooling1D(pool_length=2, stride=None, border_mode='valid')  Average pooling for temporal data.  Input shape  3D tensor with shape:  (samples, steps, features) .  Output shape  3D tensor with shape:  (samples, downsampled_steps, features) .  Arguments   pool_length : factor by which to downscale. 2 will halve the input.  stride : integer or None. Stride value.  border_mode : 'valid' or 'same'.  Note : 'same' will only work with TensorFlow for the time being.      [source]", 
            "title": "AveragePooling1D"
        }, 
        {
            "location": "/layers/convolutional/#maxpooling2d", 
            "text": "keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')  Max pooling operation for spatial data.  Input shape  4D tensor with shape: (samples, channels, rows, cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, rows, cols, channels)  if dim_ordering='tf'.  Output shape  4D tensor with shape: (nb_samples, channels, pooled_rows, pooled_cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, pooled_rows, pooled_cols, channels)  if dim_ordering='tf'.  Arguments   pool_size : tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the image in each dimension.  strides : tuple of 2 integers, or None. Strides values.  border_mode : 'valid' or 'same'.  Note : 'same' will only work with TensorFlow for the time being.    dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.    [source]", 
            "title": "MaxPooling2D"
        }, 
        {
            "location": "/layers/convolutional/#averagepooling2d", 
            "text": "keras.layers.convolutional.AveragePooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')  Average pooling operation for spatial data.  Input shape  4D tensor with shape: (samples, channels, rows, cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, rows, cols, channels)  if dim_ordering='tf'.  Output shape  4D tensor with shape: (nb_samples, channels, pooled_rows, pooled_cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, pooled_rows, pooled_cols, channels)  if dim_ordering='tf'.  Arguments   pool_size : tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the image in each dimension.  strides : tuple of 2 integers, or None. Strides values.  border_mode : 'valid' or 'same'.  Note : 'same' will only work with TensorFlow for the time being.    dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.    [source]", 
            "title": "AveragePooling2D"
        }, 
        {
            "location": "/layers/convolutional/#maxpooling3d", 
            "text": "keras.layers.convolutional.MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')  Max pooling operation for 3D data (spatial or spatio-temporal).   Note : this layer will only work with Theano for the time being.   Input shape  5D tensor with shape: (samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)  if dim_ordering='tf'.  Output shape  5D tensor with shape: (nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)  if dim_ordering='tf'.  Arguments   pool_size : tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.  strides : tuple of 3 integers, or None. Strides values.  border_mode : 'valid' or 'same'.  dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.    [source]", 
            "title": "MaxPooling3D"
        }, 
        {
            "location": "/layers/convolutional/#convolution1d", 
            "text": "keras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, input_dim=None, input_length=None)  Convolution operator for filtering neighborhoods of one-dimensional inputs.\nWhen using this layer as the first layer in a model,\neither provide the keyword argument  input_dim \n(int, e.g. 128 for sequences of 128-dimensional vectors),\nor  input_shape  (tuple of integers, e.g. (10, 128) for sequences\nof 10 vectors of 128-dimensional vectors).  Input shape  3D tensor with shape:  (samples, steps, input_dim) .  Output shape  3D tensor with shape:  (samples, new_steps, nb_filter) . steps  value might have changed due to padding.  Arguments   nb_filter : Number of convolution kernels to use\n    (dimensionality of the output).  filter_length : The extension (spatial or temporal) of each filter.  init : name of initialization function for the weights of the layer\n    (see  initializations ),\n    or alternatively, Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass a  weights  argument.  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.  border_mode : 'valid' or 'same'.  subsample_length : factor by which to subsample output.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  input_dim : Number of channels/dimensions in the input.\n    Either this argument or the keyword argument  input_shape must be\n    provided when using this layer as the first layer in a model.  input_length : Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n     Flatten  then  Dense  layers upstream\n    (without it, the shape of the dense outputs cannot be computed).    [source]", 
            "title": "Convolution1D"
        }, 
        {
            "location": "/layers/convolutional/#convolution2d", 
            "text": "keras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None)  Convolution operator for filtering windows of two-dimensional inputs.\nWhen using this layer as the first layer in a model,\nprovide the keyword argument  input_shape \n(tuple of integers, does not include the sample axis),\ne.g.  input_shape=(3, 128, 128)  for 128x128 RGB pictures.  Input shape  4D tensor with shape: (samples, channels, rows, cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, rows, cols, channels)  if dim_ordering='tf'.  Output shape  4D tensor with shape: (samples, nb_filter, new_rows, new_cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, new_rows, new_cols, nb_filter)  if dim_ordering='tf'. rows  and  cols  values might have changed due to padding.  Arguments   nb_filter : Number of convolution filters to use.  nb_row : Number of rows in the convolution kernel.  nb_col : Number of columns in the convolution kernel.  init : name of initialization function for the weights of the layer\n    (see  initializations ), or alternatively,\n    Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass\n    a  weights  argument.  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.  border_mode : 'valid' or 'same'.  subsample : tuple of length 2. Factor by which to subsample output.\n    Also called strides elsewhere.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 3.    [source]", 
            "title": "Convolution2D"
        }, 
        {
            "location": "/layers/convolutional/#convolution3d", 
            "text": "keras.layers.convolutional.Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None)  Convolution operator for filtering windows of three-dimensional inputs.\nWhen using this layer as the first layer in a model,\nprovide the keyword argument  input_shape \n(tuple of integers, does not include the sample axis),\ne.g.  input_shape=(3, 10, 128, 128)  for 10 frames of 128x128 RGB pictures.   Note : this layer will only work with Theano for the time being.   Input shape  5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels)  if dim_ordering='tf'.  Output shape  5D tensor with shape: (samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)  if dim_ordering='tf'. new_conv_dim1 ,  new_conv_dim2  and  new_conv_dim3  values might have changed due to padding.  Arguments   nb_filter : Number of convolution filters to use.  kernel_dim1 : Length of the first dimension in the covolution kernel.  kernel_dim2 : Length of the second dimension in the convolution kernel.  kernel_dim3 : Length of the third dimension in the convolution kernel.  init : name of initialization function for the weights of the layer\n    (see  initializations ), or alternatively,\n    Theano function to use for weights initialization.\n    This parameter is only relevant if you don't pass\n    a  weights  argument.  activation : name of activation function to use\n    (see  activations ),\n    or alternatively, elementwise Theano function.\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: a(x) = x).  weights : list of numpy arrays to set as initial weights.  border_mode : 'valid' or 'same'.  subsample : tuple of length 3. Factor by which to subsample output.\n    Also called strides elsewhere.  Note : 'subsample' is implemented by slicing the output of conv3d with strides=(1,1,1).    W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the main weights matrix.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  activity_regularizer : instance of  ActivityRegularizer ,\n    applied to the network output.  W_constraint : instance of the  constraints  module\n    (eg. maxnorm, nonneg), applied to the main weights matrix.  b_constraint : instance of the  constraints  module,\n    applied to the bias.  dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.    [source]", 
            "title": "Convolution3D"
        }, 
        {
            "location": "/layers/convolutional/#averagepooling3d", 
            "text": "keras.layers.convolutional.AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')  Average pooling operation for 3D data (spatial or spatio-temporal).   Note : this layer will only work with Theano for the time being.   Input shape  5D tensor with shape: (samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)  if dim_ordering='tf'.  Output shape  5D tensor with shape: (nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)  if dim_ordering='tf'.  Arguments   pool_size : tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.  strides : tuple of 3 integers, or None. Strides values.  border_mode : 'valid' or 'same'.  dim_ordering : 'th' or 'tf'. In 'th' mode, the channels dimension\n    (the depth) is at index 1, in 'tf' mode is it at index 4.    [source]", 
            "title": "AveragePooling3D"
        }, 
        {
            "location": "/layers/convolutional/#upsampling1d", 
            "text": "keras.layers.convolutional.UpSampling1D(length=2)  Repeat each temporal step  length  times along the time axis.  Input shape  3D tensor with shape:  (samples, steps, features) .  Output shape  3D tensor with shape:  (samples, upsampled_steps, features) .    _Arguments _:    length : integer. Upsampling factor.     [source]", 
            "title": "UpSampling1D"
        }, 
        {
            "location": "/layers/convolutional/#upsampling2d", 
            "text": "keras.layers.convolutional.UpSampling2D(size=(2, 2), dim_ordering='th')  Repeat the rows and columns of the data\nby size[0] and size[1] respectively.  Input shape  4D tensor with shape: (samples, channels, rows, cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, rows, cols, channels)  if dim_ordering='tf'.  Output shape  4D tensor with shape: (samples, channels, upsampled_rows, upsampled_cols)  if dim_ordering='th'\nor 4D tensor with shape: (samples, upsampled_rows, upsampled_cols, channels)  if dim_ordering='tf'.  Arguments   size : tuple of 2 integers. The upsampling factors for rows and columns.  dim_ordering : 'th' or 'tf'.\n    In 'th' mode, the channels dimension (the depth)\n    is at index 1, in 'tf' mode is it at index 3.    [source]", 
            "title": "UpSampling2D"
        }, 
        {
            "location": "/layers/convolutional/#upsampling3d", 
            "text": "keras.layers.convolutional.UpSampling3D(size=(2, 2, 2), dim_ordering='th')  Repeat the first, second and third dimension of the data\nby size[0], size[1] and size[2] respectively.   Note : this layer will only work with Theano for the time being.   Input shape  5D tensor with shape: (samples, channels, dim1, dim2, dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, dim1, dim2, dim3, channels)  if dim_ordering='tf'.  Output shape  5D tensor with shape: (samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)  if dim_ordering='th'\nor 5D tensor with shape: (samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)  if dim_ordering='tf'.  Arguments   size : tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.  dim_ordering : 'th' or 'tf'.\n    In 'th' mode, the channels dimension (the depth)\n    is at index 1, in 'tf' mode is it at index 4.    [source]", 
            "title": "UpSampling3D"
        }, 
        {
            "location": "/layers/convolutional/#zeropadding1d", 
            "text": "keras.layers.convolutional.ZeroPadding1D(padding=1)  Zero-padding layer for 1D input (e.g. temporal sequence).  Input shape  3D tensor with shape (samples, axis_to_pad, features)  Output shape  3D tensor with shape (samples, padded_axis, features)  Arguments   padding : int\n    How many zeros to add at the beginning and end of\n    the padding dimension (axis 1).    [source]", 
            "title": "ZeroPadding1D"
        }, 
        {
            "location": "/layers/convolutional/#zeropadding2d", 
            "text": "keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')  Zero-padding layer for 2D input (e.g. picture).  Input shape  4D tensor with shape:\n(samples, depth, first_axis_to_pad, second_axis_to_pad)  Output shape  4D tensor with shape:\n(samples, depth, first_padded_axis, second_padded_axis)  Arguments   padding : tuple of int (length 2)\n    How many zeros to add at the beginning and end of\n    the 2 padding dimensions (axis 3 and 4).    [source]", 
            "title": "ZeroPadding2D"
        }, 
        {
            "location": "/layers/convolutional/#zeropadding3d", 
            "text": "keras.layers.convolutional.ZeroPadding3D(padding=(1, 1, 1), dim_ordering='th')  Zero-padding layer for 3D data (spatial or spatio-temporal).   Note : this layer will only work with Theano for the time being.   Input shape  5D tensor with shape:\n(samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)  Output shape  5D tensor with shape:\n(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)  Arguments   padding : tuple of int (length 3)\n    How many zeros to add at the beginning and end of\n    the 3 padding dimensions (axis 3, 4 and 5).", 
            "title": "ZeroPadding3D"
        }, 
        {
            "location": "/layers/recurrent/", 
            "text": "[source]\n\n\nRecurrent\n\n\nkeras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, input_dim=None, input_length=None)\n\n\n\n\nAbstract base class for recurrent layers.\nDo not use in a model -- it's not a functional layer!\n\n\nAll recurrent layers (GRU, LSTM, SimpleRNN) also\nfollow the specifications of this class and accept\nthe keyword arguments listed below.\n\n\nInput shape\n\n\n3D tensor with shape \n(nb_samples, timesteps, input_dim)\n.\n\n\nOutput shape\n\n\n\n\nif \nreturn_sequences\n: 3D tensor with shape\n    \n(nb_samples, timesteps, output_dim)\n.\n\n\nelse, 2D tensor with shape \n(nb_samples, output_dim)\n.\n\n\n\n\nArguments\n\n\n\n\nweights\n: list of numpy arrays to set as initial weights.\n    The list should have 3 elements, of shapes:\n    \n[(input_dim, output_dim), (output_dim, output_dim), (output_dim,)]\n.\n\n\nreturn_sequences\n: Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.\n\n\ngo_backwards\n: Boolean (default False).\n    If True, process the input sequence backwards.\n\n\nstateful\n: Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n\n\ninput_dim\n: dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument \ninput_shape\n)\n    is required when using this layer as the first layer in a model.\n\n\ninput_length\n: Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n    \nFlatten\n then \nDense\n layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the \ninput_shape\n argument)\n\n\n\n\nMasking\n\n\nThis layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse an \nEmbedding\n layer with the \nmask_zero\n parameter\nset to \nTrue\n.\n\n\nTensorFlow warning\n\n\nFor the time being, when using the TensorFlow backend,\nthe number of timesteps used must be specified in your model.\nMake sure to pass an \ninput_length\n int argument to your\nrecurrent layer (if it comes first in your model),\nor to pass a complete \ninput_shape\n argument to the first layer\nin your model otherwise.\n\n\nNote on using statefulness in RNNs\n\n\nYou can set RNN layers to be 'stateful', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch.\nThis assumes a one-to-one mapping between\nsamples in different successive batches.\n\n\nTo enable statefulness:\n    - specify \nstateful=True\n in the layer constructor.\n    - specify a fixed batch size for your model, by passing\n    a \nbatch_input_shape=(...)\n to the first layer in your model.\n    This is the expected shape of your inputs \nincluding the batch size\n.\n    It should be a tuple of integers, e.g. \n(32, 10, 100)\n.\n\n\nTo reset the states of your model, call \n.reset_states()\n on either\na specific layer, or on your entire model.\n\n\nNote on using dropout with TensorFlow\n\n\nWhen using the TensorFlow backend, specify a fixed batch size for your model\nfollowing the notes on statefulness RNNs.\n\n\n\n\n[source]\n\n\nSimpleRNN\n\n\nkeras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\nFully-connected RNN where the output is to be fed back to input.\n\n\nArguments\n\n\n\n\noutput_dim\n: dimension of the internal projections and the final output.\n\n\ninit\n: weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \ninitializations\n).\n\n\ninner_init\n: initialization function of the inner cells.\n\n\nactivation\n: activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \nactivations\n).\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nU_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\ndropout_W\n: float between 0 and 1. Fraction of the input units to drop for input gates.\n\n\ndropout_U\n: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n\n\n\n\nReferences\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n\n\n\n\n\n\n[source]\n\n\nGRU\n\n\nkeras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\nGated Recurrent Unit - Cho et al. 2014.\n\n\nArguments\n\n\n\n\noutput_dim\n: dimension of the internal projections and the final output.\n\n\ninit\n: weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \ninitializations\n).\n\n\ninner_init\n: initialization function of the inner cells.\n\n\nactivation\n: activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \nactivations\n).\n\n\ninner_activation\n: activation function for the inner cells.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nU_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\ndropout_W\n: float between 0 and 1. Fraction of the input units to drop for input gates.\n\n\ndropout_U\n: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n\n\n\n\nReferences\n\n\n\n\nOn the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches\n\n\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n\n\n\n\n\n\n[source]\n\n\nLSTM\n\n\nkeras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\nLong-Short Term Memory unit - Hochreiter 1997.\n\n\nFor a step-by-step description of the algorithm, see\n\nthis tutorial\n.\n\n\nArguments\n\n\n\n\noutput_dim\n: dimension of the internal projections and the final output.\n\n\ninit\n: weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \ninitializations\n).\n\n\ninner_init\n: initialization function of the inner cells.\n\n\nforget_bias_init\n: initialization function for the bias of the forget gate.\n    \nJozefowicz et al.\n\n    recommend initializing with ones.\n\n\nactivation\n: activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see: \nactivations\n).\n\n\ninner_activation\n: activation function for the inner cells.\n\n\nW_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nU_regularizer\n: instance of \nWeightRegularizer\n\n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nb_regularizer\n: instance of \nWeightRegularizer\n,\n    applied to the bias.\n\n\ndropout_W\n: float between 0 and 1. Fraction of the input units to drop for input gates.\n\n\ndropout_U\n: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n\n\n\n\nReferences\n\n\n\n\nLong short-term memory\n (original 1997 paper)\n\n\nLearning to forget: Continual prediction with LSTM\n\n\nSupervised sequence labelling with recurrent neural networks\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/layers/recurrent/#recurrent", 
            "text": "keras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, input_dim=None, input_length=None)  Abstract base class for recurrent layers.\nDo not use in a model -- it's not a functional layer!  All recurrent layers (GRU, LSTM, SimpleRNN) also\nfollow the specifications of this class and accept\nthe keyword arguments listed below.  Input shape  3D tensor with shape  (nb_samples, timesteps, input_dim) .  Output shape   if  return_sequences : 3D tensor with shape\n     (nb_samples, timesteps, output_dim) .  else, 2D tensor with shape  (nb_samples, output_dim) .   Arguments   weights : list of numpy arrays to set as initial weights.\n    The list should have 3 elements, of shapes:\n     [(input_dim, output_dim), (output_dim, output_dim), (output_dim,)] .  return_sequences : Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.  go_backwards : Boolean (default False).\n    If True, process the input sequence backwards.  stateful : Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.  input_dim : dimensionality of the input (integer).\n    This argument (or alternatively, the keyword argument  input_shape )\n    is required when using this layer as the first layer in a model.  input_length : Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n     Flatten  then  Dense  layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the  input_shape  argument)   Masking  This layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse an  Embedding  layer with the  mask_zero  parameter\nset to  True .  TensorFlow warning  For the time being, when using the TensorFlow backend,\nthe number of timesteps used must be specified in your model.\nMake sure to pass an  input_length  int argument to your\nrecurrent layer (if it comes first in your model),\nor to pass a complete  input_shape  argument to the first layer\nin your model otherwise.  Note on using statefulness in RNNs  You can set RNN layers to be 'stateful', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch.\nThis assumes a one-to-one mapping between\nsamples in different successive batches.  To enable statefulness:\n    - specify  stateful=True  in the layer constructor.\n    - specify a fixed batch size for your model, by passing\n    a  batch_input_shape=(...)  to the first layer in your model.\n    This is the expected shape of your inputs  including the batch size .\n    It should be a tuple of integers, e.g.  (32, 10, 100) .  To reset the states of your model, call  .reset_states()  on either\na specific layer, or on your entire model.  Note on using dropout with TensorFlow  When using the TensorFlow backend, specify a fixed batch size for your model\nfollowing the notes on statefulness RNNs.   [source]", 
            "title": "Recurrent"
        }, 
        {
            "location": "/layers/recurrent/#simplernn", 
            "text": "keras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  Fully-connected RNN where the output is to be fed back to input.  Arguments   output_dim : dimension of the internal projections and the final output.  init : weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  initializations ).  inner_init : initialization function of the inner cells.  activation : activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  activations ).  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the input weights matrices.  U_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  dropout_W : float between 0 and 1. Fraction of the input units to drop for input gates.  dropout_U : float between 0 and 1. Fraction of the input units to drop for recurrent connections.   References   A Theoretically Grounded Application of Dropout in Recurrent Neural Networks    [source]", 
            "title": "SimpleRNN"
        }, 
        {
            "location": "/layers/recurrent/#gru", 
            "text": "keras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  Gated Recurrent Unit - Cho et al. 2014.  Arguments   output_dim : dimension of the internal projections and the final output.  init : weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  initializations ).  inner_init : initialization function of the inner cells.  activation : activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  activations ).  inner_activation : activation function for the inner cells.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the input weights matrices.  U_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  dropout_W : float between 0 and 1. Fraction of the input units to drop for input gates.  dropout_U : float between 0 and 1. Fraction of the input units to drop for recurrent connections.   References   On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches  Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling  A Theoretically Grounded Application of Dropout in Recurrent Neural Networks    [source]", 
            "title": "GRU"
        }, 
        {
            "location": "/layers/recurrent/#lstm", 
            "text": "keras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  Long-Short Term Memory unit - Hochreiter 1997.  For a step-by-step description of the algorithm, see this tutorial .  Arguments   output_dim : dimension of the internal projections and the final output.  init : weight initialization function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  initializations ).  inner_init : initialization function of the inner cells.  forget_bias_init : initialization function for the bias of the forget gate.\n     Jozefowicz et al. \n    recommend initializing with ones.  activation : activation function.\n    Can be the name of an existing function (str),\n    or a Theano function (see:  activations ).  inner_activation : activation function for the inner cells.  W_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the input weights matrices.  U_regularizer : instance of  WeightRegularizer \n    (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  b_regularizer : instance of  WeightRegularizer ,\n    applied to the bias.  dropout_W : float between 0 and 1. Fraction of the input units to drop for input gates.  dropout_U : float between 0 and 1. Fraction of the input units to drop for recurrent connections.   References   Long short-term memory  (original 1997 paper)  Learning to forget: Continual prediction with LSTM  Supervised sequence labelling with recurrent neural networks  A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "LSTM"
        }, 
        {
            "location": "/layers/advanced_activations/", 
            "text": "[source]\n\n\nLeakyReLU\n\n\nkeras.layers.advanced_activations.LeakyReLU(alpha=0.3)\n\n\n\n\nSpecial version of a Rectified Linear Unit\nthat allows a small gradient when the unit is not active:\n\nf(x) = alpha*x for x \n 0\n.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\nalpha\n: float \n= 0. Negative slope coefficient.\n\n\n\n\n\n\n[source]\n\n\nPReLU\n\n\nkeras.layers.advanced_activations.PReLU(init='zero', weights=None)\n\n\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\n\n\n\n\n_Arguments\n_:\n\n\n\n\n\n\ninit\n: initialization function for the weights.\n\n\n\n\n\n\nweights\n: initial weights, as a list of a single numpy array.\n\n\n\n\n\n\n_References\n_:\n\n\n\n\n\n\nDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n\n\n\n\n\n\n\n\n[source]\n\n\nELU\n\n\nkeras.layers.advanced_activations.ELU(alpha=1.0)\n\n\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\nalpha\n: scale for the negative factor.\n\n\n\n\nReferences\n\n\n\n\nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n\n\n\n\n\n\n[source]\n\n\nParametricSoftplus\n\n\nkeras.layers.advanced_activations.ParametricSoftplus(alpha_init=0.2, beta_init=5.0, weights=None)\n\n\n\n\nParametric Softplus of the form: alpha * log(1 + exp(beta * X))\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\nalpha_init\n: float. Initial value of the alpha weights.\n\n\nbeta_init\n: float. Initial values of the beta weights.\n\n\n\n\nweights\n: initial weights, as a list of 2 numpy arrays.\n\n\n\n\n\n\n_References\n_:\n\n\n\n\n\n\nInferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs\n\n\n\n\n\n\n\n\n[source]\n\n\nThresholdedLinear\n\n\nkeras.layers.advanced_activations.ThresholdedLinear(theta=1.0)\n\n\n\n\nThresholded Linear Activation.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\ntheta\n: float \n= 0. Threshold location of activation.\n\n\n\n\nReferences\n\n\nZero-Bias Autoencoders and the Benefits of Co-Adapting Features\n\n\n\n\n[source]\n\n\nThresholdedReLU\n\n\nkeras.layers.advanced_activations.ThresholdedReLU(theta=1.0)\n\n\n\n\nThresholded Rectified Activation.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\ntheta\n: float \n= 0. Threshold location of activation.\n\n\n\n\nReferences\n\n\nZero-Bias Autoencoders and the Benefits of Co-Adapting Features\n\n\n\n\n[source]\n\n\nSReLU\n\n\nkeras.layers.advanced_activations.SReLU(t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one')\n\n\n\n\nSReLU\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as the input.\n\n\nArguments\n\n\n\n\nt_left_init\n: initialization function for the left part intercept\n\n\na_left_init\n: initialization function for the left part slope\n\n\nt_right_init\n: initialization function for the right part intercept\n\n\na_right_init\n: initialization function for the right part slope\n\n\n\n\nReferences\n\n\nDeep Learning with S-shaped Rectified Linear Activation Units", 
            "title": "Advanced Activations Layers"
        }, 
        {
            "location": "/layers/advanced_activations/#leakyrelu", 
            "text": "keras.layers.advanced_activations.LeakyReLU(alpha=0.3)  Special version of a Rectified Linear Unit\nthat allows a small gradient when the unit is not active: f(x) = alpha*x for x   0 .  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   alpha : float  = 0. Negative slope coefficient.    [source]", 
            "title": "LeakyReLU"
        }, 
        {
            "location": "/layers/advanced_activations/#prelu", 
            "text": "keras.layers.advanced_activations.PReLU(init='zero', weights=None)  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.    _Arguments _:    init : initialization function for the weights.    weights : initial weights, as a list of a single numpy array.    _References _:    Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification     [source]", 
            "title": "PReLU"
        }, 
        {
            "location": "/layers/advanced_activations/#elu", 
            "text": "keras.layers.advanced_activations.ELU(alpha=1.0)  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   alpha : scale for the negative factor.   References   Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)    [source]", 
            "title": "ELU"
        }, 
        {
            "location": "/layers/advanced_activations/#parametricsoftplus", 
            "text": "keras.layers.advanced_activations.ParametricSoftplus(alpha_init=0.2, beta_init=5.0, weights=None)  Parametric Softplus of the form: alpha * log(1 + exp(beta * X))  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   alpha_init : float. Initial value of the alpha weights.  beta_init : float. Initial values of the beta weights.   weights : initial weights, as a list of 2 numpy arrays.    _References _:    Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs     [source]", 
            "title": "ParametricSoftplus"
        }, 
        {
            "location": "/layers/advanced_activations/#thresholdedlinear", 
            "text": "keras.layers.advanced_activations.ThresholdedLinear(theta=1.0)  Thresholded Linear Activation.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   theta : float  = 0. Threshold location of activation.   References  Zero-Bias Autoencoders and the Benefits of Co-Adapting Features   [source]", 
            "title": "ThresholdedLinear"
        }, 
        {
            "location": "/layers/advanced_activations/#thresholdedrelu", 
            "text": "keras.layers.advanced_activations.ThresholdedReLU(theta=1.0)  Thresholded Rectified Activation.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   theta : float  = 0. Threshold location of activation.   References  Zero-Bias Autoencoders and the Benefits of Co-Adapting Features   [source]", 
            "title": "ThresholdedReLU"
        }, 
        {
            "location": "/layers/advanced_activations/#srelu", 
            "text": "keras.layers.advanced_activations.SReLU(t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one')  SReLU  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as the input.  Arguments   t_left_init : initialization function for the left part intercept  a_left_init : initialization function for the left part slope  t_right_init : initialization function for the right part intercept  a_right_init : initialization function for the right part slope   References  Deep Learning with S-shaped Rectified Linear Activation Units", 
            "title": "SReLU"
        }, 
        {
            "location": "/layers/normalization/", 
            "text": "[source]\n\n\nBatchNormalization\n\n\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, axis=-1, momentum=0.9, weights=None, beta_init='zero', gamma_init='one')\n\n\n\n\nNormalize the activations of the previous layer at each batch,\ni.e. applies a transformation that maintains the mean activation\nclose to 0 and the activation standard deviation close to 1.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as input.\n\n\nArguments\n\n\n\n\nepsilon\n: small float \n 0. Fuzz parameter.\n\n\nmode\n: integer, 0 or 1.\n\n\n0: feature-wise normalization.\nEach feature map in the input will\nbe normalized separately. The axis on which\nto normalize is specified by the \naxis\n argument.\nNote that if the input is a 4D image tensor\nusing Theano conventions (samples, channels, rows, cols)\nthen you should set \naxis\n to \n1\n to normalize along\nthe channels axis.\n\n\n1: sample-wise normalization. This mode assumes a 2D input.\n\n\n\n\n\n\naxis\n: integer, axis along which to normalize in mode 0. For instance,\n    if your input tensor has shape (samples, channels, rows, cols),\n    set axis to 1 to normalize per feature map (channels axis).\n\n\nmomentum\n: momentum in the computation of the\n    exponential average of the mean and standard deviation\n    of the data, for feature-wise normalization.\n\n\nweights\n: Initialization weights.\n    List of 2 numpy arrays, with shapes:\n    \n[(input_shape,), (input_shape,)]\n\n\nbeta_init\n: name of initialization function for shift parameter\n    (see \ninitializations\n), or alternatively,\n    Theano/TensorFlow function to use for weights initialization.\n    This parameter is only relevant if you don't pass a \nweights\n argument.\n\n\n\n\ngamma_init\n: name of initialization function for scale parameter (see\n    \ninitializations\n), or alternatively,\n    Theano/TensorFlow function to use for weights initialization.\n    This parameter is only relevant if you don't pass a \nweights\n argument.\n\nReferences\n\n\n\n\n\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/layers/normalization/#batchnormalization", 
            "text": "keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, axis=-1, momentum=0.9, weights=None, beta_init='zero', gamma_init='one')  Normalize the activations of the previous layer at each batch,\ni.e. applies a transformation that maintains the mean activation\nclose to 0 and the activation standard deviation close to 1.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as input.  Arguments   epsilon : small float   0. Fuzz parameter.  mode : integer, 0 or 1.  0: feature-wise normalization.\nEach feature map in the input will\nbe normalized separately. The axis on which\nto normalize is specified by the  axis  argument.\nNote that if the input is a 4D image tensor\nusing Theano conventions (samples, channels, rows, cols)\nthen you should set  axis  to  1  to normalize along\nthe channels axis.  1: sample-wise normalization. This mode assumes a 2D input.    axis : integer, axis along which to normalize in mode 0. For instance,\n    if your input tensor has shape (samples, channels, rows, cols),\n    set axis to 1 to normalize per feature map (channels axis).  momentum : momentum in the computation of the\n    exponential average of the mean and standard deviation\n    of the data, for feature-wise normalization.  weights : Initialization weights.\n    List of 2 numpy arrays, with shapes:\n     [(input_shape,), (input_shape,)]  beta_init : name of initialization function for shift parameter\n    (see  initializations ), or alternatively,\n    Theano/TensorFlow function to use for weights initialization.\n    This parameter is only relevant if you don't pass a  weights  argument.   gamma_init : name of initialization function for scale parameter (see\n     initializations ), or alternatively,\n    Theano/TensorFlow function to use for weights initialization.\n    This parameter is only relevant if you don't pass a  weights  argument. References    Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", 
            "title": "BatchNormalization"
        }, 
        {
            "location": "/layers/embeddings/", 
            "text": "[source]\n\n\nEmbedding\n\n\nkeras.layers.embeddings.Embedding(input_dim, output_dim, init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)\n\n\n\n\nTurn positive integers (indexes) into dense vectors of fixed size.\neg. [[4], [20]] -\n [[0.25, 0.1], [0.6, -0.2]]\n\n\nThis layer can only be used as the first layer in a model.\n\n\nInput shape\n\n\n2D tensor with shape: \n(nb_samples, sequence_length)\n.\n\n\nOutput shape\n\n\n3D tensor with shape: \n(nb_samples, sequence_length, output_dim)\n.\n\n\nArguments\n\n\n\n\ninput_dim\n: int \n= 0. Size of the vocabulary, ie.\n  1 + maximum integer index occurring in the input data.\n\n\noutput_dim\n: int \n= 0. Dimension of the dense embedding.\n\n\ninit\n: name of initialization function for the weights\n  of the layer (see: \ninitializations\n),\n  or alternatively, Theano function to use for weights initialization.\n  This parameter is only relevant if you don't pass a \nweights\n argument.\n\n\nweights\n: list of numpy arrays to set as initial weights.\n  The list should have 1 element, of shape \n(input_dim, output_dim)\n.\n\n\nW_regularizer\n: instance of the \nregularizers\n module\n(eg. L1 or L2 regularization), applied to the embedding matrix.\n\n\nW_constraint\n: instance of the \nconstraints\n module\n  (eg. maxnorm, nonneg), applied to the embedding matrix.\n\n\nmask_zero\n: Whether or not the input value 0 is a special \"padding\"\n  value that should be masked out.\n  This is useful for \nrecurrent layers\n which may take\n  variable length input. If this is \nTrue\n then all subsequent layers\n  in the model need to support masking or an exception will be raised.\n\n\ninput_length\n: Length of input sequences, when it is constant.\n  This argument is required if you are going to connect\n  \nFlatten\n then \nDense\n layers upstream\n  (without it, the shape of the dense outputs cannot be computed).\n\n\ndropout\n: float between 0 and 1. Fraction of the embeddings to drop.\n\n\n\n\nReferences\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/layers/embeddings/#embedding", 
            "text": "keras.layers.embeddings.Embedding(input_dim, output_dim, init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)  Turn positive integers (indexes) into dense vectors of fixed size.\neg. [[4], [20]] -  [[0.25, 0.1], [0.6, -0.2]]  This layer can only be used as the first layer in a model.  Input shape  2D tensor with shape:  (nb_samples, sequence_length) .  Output shape  3D tensor with shape:  (nb_samples, sequence_length, output_dim) .  Arguments   input_dim : int  = 0. Size of the vocabulary, ie.\n  1 + maximum integer index occurring in the input data.  output_dim : int  = 0. Dimension of the dense embedding.  init : name of initialization function for the weights\n  of the layer (see:  initializations ),\n  or alternatively, Theano function to use for weights initialization.\n  This parameter is only relevant if you don't pass a  weights  argument.  weights : list of numpy arrays to set as initial weights.\n  The list should have 1 element, of shape  (input_dim, output_dim) .  W_regularizer : instance of the  regularizers  module\n(eg. L1 or L2 regularization), applied to the embedding matrix.  W_constraint : instance of the  constraints  module\n  (eg. maxnorm, nonneg), applied to the embedding matrix.  mask_zero : Whether or not the input value 0 is a special \"padding\"\n  value that should be masked out.\n  This is useful for  recurrent layers  which may take\n  variable length input. If this is  True  then all subsequent layers\n  in the model need to support masking or an exception will be raised.  input_length : Length of input sequences, when it is constant.\n  This argument is required if you are going to connect\n   Flatten  then  Dense  layers upstream\n  (without it, the shape of the dense outputs cannot be computed).  dropout : float between 0 and 1. Fraction of the embeddings to drop.   References   A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "Embedding"
        }, 
        {
            "location": "/layers/noise/", 
            "text": "[source]\n\n\nGaussianNoise\n\n\nkeras.layers.noise.GaussianNoise(sigma)\n\n\n\n\nApply to the input an additive zero-centred gaussian noise with\nstandard deviation \nsigma\n. This is useful to mitigate overfitting\n(you could see it as a kind of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process\nfor real valued inputs.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nInput shape\n\n\nArbitrary. Use the keyword argument \ninput_shape\n\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\n\n\nOutput shape\n\n\nSame shape as input.\n\n\nArguments\n\n\n\n\nsigma\n: float, standard deviation of the noise distribution.\n\n\n\n\n\n\n[source]\n\n\nGaussianDropout\n\n\nkeras.layers.noise.GaussianDropout(p)\n\n\n\n\nApply to the input an multiplicative one-centred gaussian noise\nwith standard deviation \nsqrt(p/(1-p))\n.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nArguments\n\n\n\n\n\n\np\n: float, drop probability (as with \nDropout\n).\n\n\n\n\n\n\n_References\n_:\n\n\n\n\n\n\n__\nDropout__: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014", 
            "title": "Noise layers"
        }, 
        {
            "location": "/layers/noise/#gaussiannoise", 
            "text": "keras.layers.noise.GaussianNoise(sigma)  Apply to the input an additive zero-centred gaussian noise with\nstandard deviation  sigma . This is useful to mitigate overfitting\n(you could see it as a kind of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process\nfor real valued inputs.  As it is a regularization layer, it is only active at training time.  Input shape  Arbitrary. Use the keyword argument  input_shape \n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.  Output shape  Same shape as input.  Arguments   sigma : float, standard deviation of the noise distribution.    [source]", 
            "title": "GaussianNoise"
        }, 
        {
            "location": "/layers/noise/#gaussiandropout", 
            "text": "keras.layers.noise.GaussianDropout(p)  Apply to the input an multiplicative one-centred gaussian noise\nwith standard deviation  sqrt(p/(1-p)) .  As it is a regularization layer, it is only active at training time.  Arguments    p : float, drop probability (as with  Dropout ).    _References _:    __ Dropout__: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014", 
            "title": "GaussianDropout"
        }, 
        {
            "location": "/layers/containers/", 
            "text": "[source]\n\n\nSequential\n\n\nkeras.layers.containers.Sequential(layers=[])\n\n\n\n\nThe Sequential container is a linear stack of layers.\nApart from the \nadd\n methods and the \nlayers\n constructor argument,\nthe API is identical to that of the \nLayer\n class.\n\n\nThis class is also the basis for the \nkeras.models.Sequential\n model.\n\n\nArguments\n\n\n\n\nlayers\n: list of layers to be added to the container.\n\n\n\n\nMethods\n\n\nadd(layer)\n\n\n\n\nreset_states()\n\n\n\n\nset_input()\n\n\n\n\nclear_previous(reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\ncount_params()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_config()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_input(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output_mask(train=None)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_weights()\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_input_shape(input_shape)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_previous(layer, reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_weights(weights)\n\n\n\n\nDefined by \nLayer\n.\n\n\nsupports_masked_input()\n\n\n\n\nDefined by \nLayer\n.\n\n\n\n\n[source]\n\n\nGraph\n\n\nkeras.layers.containers.Graph()\n\n\n\n\nImplement a NN graph with arbitrary layer connections,\narbitrary number of inputs and arbitrary number of outputs.\n\n\nThis class is also the basis for the \nkeras.models.Graph\n model.\n\n\n\n\nNote\n: \nGraph\n can only be used as a layer\n(connect, input, get_input, get_output)\nwhen it has exactly one input and one output.\n\n\n\n\nMethods\n\n\nadd_input(name, input_shape=None, batch_input_shape=None, dtype='float')\n\n\n\n\nAdd an input to the graph.\n\n\n\n\n\n\n_Arguments\n_:\n\n\n\n\n\n\nname\n: string. The name of the new input. Must be unique in the graph.\n\n\n\n\ninput_shape\n: a tuple of integers, the expected shape of the input samples.\n    Does not include the batch size.\n\n\nbatch_input_shape\n: a tuple of integers, the expected shape of the\n    whole input batch, including the batch size.\n\n\ndtype\n: 'float' or 'int'.\n\n\n\n\nadd_node(layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False)\n\n\n\n\nAdd a node in the graph. It can be connected to multiple\ninputs, which will first be merged into one tensor\naccording to the mode specified.\n\n\nArguments\n\n\n\n\nlayer\n: the layer at the node.\n\n\nname\n: name for the node.\n\n\ninput\n: when connecting the layer to a single input,\n    this is the name of the incoming node.\n\n\ninputs\n: when connecting the layer to multiple inputs,\n    this is a list of names of incoming nodes.\n\n\nmerge_mode\n: one of {concat, sum, dot, ave, mul}\n\n\nconcat_axis\n: when \nmerge_mode=='concat'\n, this is the\n    input concatenation axis.\n\n\ndot_axes\n: when \nmerge_mode='dot'\n, this is the contraction axes\n    specification; see the `Merge layer for details.\n\n\ncreate_output\n: boolean. Set this to \nTrue\n if you want the output\n    of your node to be an output of the graph.\n\n\n\n\nadd_output(name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1)\n\n\n\n\nAdd an output to the graph.\n\n\nThis output can merge several node outputs into a single output.\n\n\nArguments\n\n\n\n\nname\n: name of the output.\n\n\ninput\n: when connecting the layer to a single input,\n    this is the name of the incoming node.\n\n\ninputs\n: when connecting the layer to multiple inputs,\n    this is a list of names of incoming nodes.\n\n\nmerge_mode\n: one of {concat, sum, dot, ave, mul}\n\n\nconcat_axis\n: when \nmerge_mode=='concat'\n, this is the\n    input concatenation axis.\n\n\ndot_axes\n: when \nmerge_mode='dot'\n, this is the contraction axes\n    specification; see the `Merge layer for details.\n\n\n\n\nadd_shared_node(layer, name, inputs=[], merge_mode=None, concat_axis=-1, dot_axes=-1, outputs=[], create_output=False)\n\n\n\n\nUsed to share a same layer across multiple nodes.\n\n\nSupposed, for instance, that you want to apply one same \nDense\n\nlayer after to the output of two different nodes.\nYou can then add the \nDense\n layer as a shared node.\n\n\nArguments\n\n\n\n\nlayer\n: The layer to be shared across multiple inputs\n\n\nname\n: Name of the shared node\n\n\ninputs\n: List of names of input nodes\n\n\nmerge_mode\n: Same meaning as \nmerge_mode\n argument of \nadd_node()\n\n\nconcat_axis\n: Same meaning as \nconcat_axis\n argument of \nadd_node()\n\n\ndot_axes\n: Same meaning as \ndot_axes\n argument of \nadd_node()\n\n\noutputs\n: Used when \nmerge_mode=None\n. Names for the output nodes.\n\n\ncreate_output\n: Same meaning as \ncreate_output\n argument of \nadd_node()\n.\n\n\n\n\nreset_states()\n\n\n\n\nclear_previous(reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\ncount_params()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_config()\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_input(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output(train=False)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_output_mask(train=None)\n\n\n\n\nDefined by \nLayer\n.\n\n\nget_weights()\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_input_shape(input_shape)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_previous(layer, connection_map={}, reset_weights=True)\n\n\n\n\nDefined by \nLayer\n.\n\n\nset_weights(weights)\n\n\n\n\nDefined by \nLayer\n.\n\n\nsupports_masked_input()\n\n\n\n\nDefined by \nLayer\n.", 
            "title": "Containers"
        }, 
        {
            "location": "/layers/containers/#sequential", 
            "text": "keras.layers.containers.Sequential(layers=[])  The Sequential container is a linear stack of layers.\nApart from the  add  methods and the  layers  constructor argument,\nthe API is identical to that of the  Layer  class.  This class is also the basis for the  keras.models.Sequential  model.  Arguments   layers : list of layers to be added to the container.", 
            "title": "Sequential"
        }, 
        {
            "location": "/layers/containers/#methods", 
            "text": "add(layer)  reset_states()  set_input()  clear_previous(reset_weights=True)  Defined by  Layer .  count_params()  Defined by  Layer .  get_config()  Defined by  Layer .  get_input(train=False)  Defined by  Layer .  get_output(train=False)  Defined by  Layer .  get_output_mask(train=None)  Defined by  Layer .  get_weights()  Defined by  Layer .  set_input_shape(input_shape)  Defined by  Layer .  set_previous(layer, reset_weights=True)  Defined by  Layer .  set_weights(weights)  Defined by  Layer .  supports_masked_input()  Defined by  Layer .   [source]", 
            "title": "Methods"
        }, 
        {
            "location": "/layers/containers/#graph", 
            "text": "keras.layers.containers.Graph()  Implement a NN graph with arbitrary layer connections,\narbitrary number of inputs and arbitrary number of outputs.  This class is also the basis for the  keras.models.Graph  model.   Note :  Graph  can only be used as a layer\n(connect, input, get_input, get_output)\nwhen it has exactly one input and one output.", 
            "title": "Graph"
        }, 
        {
            "location": "/layers/containers/#methods_1", 
            "text": "add_input(name, input_shape=None, batch_input_shape=None, dtype='float')  Add an input to the graph.    _Arguments _:    name : string. The name of the new input. Must be unique in the graph.   input_shape : a tuple of integers, the expected shape of the input samples.\n    Does not include the batch size.  batch_input_shape : a tuple of integers, the expected shape of the\n    whole input batch, including the batch size.  dtype : 'float' or 'int'.   add_node(layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False)  Add a node in the graph. It can be connected to multiple\ninputs, which will first be merged into one tensor\naccording to the mode specified.  Arguments   layer : the layer at the node.  name : name for the node.  input : when connecting the layer to a single input,\n    this is the name of the incoming node.  inputs : when connecting the layer to multiple inputs,\n    this is a list of names of incoming nodes.  merge_mode : one of {concat, sum, dot, ave, mul}  concat_axis : when  merge_mode=='concat' , this is the\n    input concatenation axis.  dot_axes : when  merge_mode='dot' , this is the contraction axes\n    specification; see the `Merge layer for details.  create_output : boolean. Set this to  True  if you want the output\n    of your node to be an output of the graph.   add_output(name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, dot_axes=-1)  Add an output to the graph.  This output can merge several node outputs into a single output.  Arguments   name : name of the output.  input : when connecting the layer to a single input,\n    this is the name of the incoming node.  inputs : when connecting the layer to multiple inputs,\n    this is a list of names of incoming nodes.  merge_mode : one of {concat, sum, dot, ave, mul}  concat_axis : when  merge_mode=='concat' , this is the\n    input concatenation axis.  dot_axes : when  merge_mode='dot' , this is the contraction axes\n    specification; see the `Merge layer for details.   add_shared_node(layer, name, inputs=[], merge_mode=None, concat_axis=-1, dot_axes=-1, outputs=[], create_output=False)  Used to share a same layer across multiple nodes.  Supposed, for instance, that you want to apply one same  Dense \nlayer after to the output of two different nodes.\nYou can then add the  Dense  layer as a shared node.  Arguments   layer : The layer to be shared across multiple inputs  name : Name of the shared node  inputs : List of names of input nodes  merge_mode : Same meaning as  merge_mode  argument of  add_node()  concat_axis : Same meaning as  concat_axis  argument of  add_node()  dot_axes : Same meaning as  dot_axes  argument of  add_node()  outputs : Used when  merge_mode=None . Names for the output nodes.  create_output : Same meaning as  create_output  argument of  add_node() .   reset_states()  clear_previous(reset_weights=True)  Defined by  Layer .  count_params()  Defined by  Layer .  get_config()  Defined by  Layer .  get_input(train=False)  Defined by  Layer .  get_output(train=False)  Defined by  Layer .  get_output_mask(train=None)  Defined by  Layer .  get_weights()  Defined by  Layer .  set_input_shape(input_shape)  Defined by  Layer .  set_previous(layer, connection_map={}, reset_weights=True)  Defined by  Layer .  set_weights(weights)  Defined by  Layer .  supports_masked_input()  Defined by  Layer .", 
            "title": "Methods"
        }, 
        {
            "location": "/preprocessing/sequence/", 
            "text": "pad_sequences\n\n\nkeras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32')\n\n\n\n\nTransform a list of \nnb_samples sequences\n (lists of scalars) into a 2D numpy array of shape \n(nb_samples, nb_timesteps)\n. \nnb_timesteps\n is either the \nmaxlen\n argument if provided, or the length of the longest sequence otherwise. Sequences that are shorter than \nnb_timesteps\n are padded with zeros at the end.\n\n\n\n\n\n\nReturn\n: 2D numpy array of shape \n(nb_samples, nb_timesteps)\n.\n\n\n\n\n\n\nArguments\n:\n\n\n\n\nsequences\n: List of lists of int or float.\n\n\nmaxlen\n: None or int. Maximum sequence length, longer sequences are truncated and shorter sequences are padded with zeros at the end.\n\n\ndtype\n: datatype of the numpy array returned.\n\n\npadding\n: 'pre' or 'post', pad either before or after each sequence.\n\n\ntruncating\n: 'pre' or 'post', remove values from sequences larger than maxlen either in the beginning or in the end of the sequence\n\n\nvalue\n: float, value to pad the sequences to the desired value.\n\n\n\n\n\n\n\n\n\n\nskipgrams\n\n\nkeras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, \n    window_size=4, negative_samples=1., shuffle=True, \n    categorical=False, sampling_table=None)\n\n\n\n\nTransforms a sequence of word indexes (list of int) into couples of the form: \n\n\n\n\n(word, word in the same window), with label 1 (positive samples).\n\n\n(word, random word from the vocabulary), with label 0 (negative samples).\n\n\n\n\nRead more about Skipgram in this gnomic paper by Mikolov et al.: \nEfficient Estimation of Word Representations in\nVector Space\n\n\n\n\n\n\nReturn\n: tuple \n(couples, labels)\n. \n\n\n\n\ncouples\n is a list of 2-elements lists of int: \n[word_index, other_word_index]\n. \n\n\nlabels\n is a list of 0 and 1, where 1 indicates that \nother_word_index\n was found in the same window as \nword_index\n, and 0 indicates that \nother_word_index\n was random.\n\n\nif categorical is set to True, the labels are categorical, ie. 1 becomes [0,1], and 0 becomes [1, 0].\n\n\n\n\n\n\n\n\nArguments\n:\n\n\n\n\nsequence\n: list of int indexes. If using a sampling_table, the index of a word should be its the rank in the dataset (starting at 1).\n\n\nvocabulary_size\n: int.\n\n\nwindow_size\n: int. maximum distance between two words in a positive couple.\n\n\nnegative_samples\n: float \n= 0. 0 for no negative (=random) samples. 1 for same number as positive samples. etc.\n\n\nshuffle\n: boolean. Whether to shuffle the samples.\n\n\ncategorical\n: boolean. Whether to make the returned labels categorical.\n\n\nsampling_table\n: numpy array of shape \n(vocabulary_size,)\n where \nsampling_table[i]\n is the probability of sampling the word with index i (assumed to be i-th most common word in the dataset).\n\n\n\n\n\n\n\n\n\n\nmake_sampling_table\n\n\nkeras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-5)\n\n\n\n\nUsed for generating the \nsampling_table\n argument for \nskipgrams\n. \nsampling_table[i]\n is the probability of sampling the word i-th most common word in a dataset (more common words should be sampled less frequently, for balance).\n\n\n\n\n\n\nReturn\n: numpy array of shape \n(size,)\n.\n\n\n\n\n\n\nArguments\n:\n\n\n\n\nsize\n: size of the vocabulary considered.\n\n\nsampling_factor\n: lower values result in a longer probability decay (common words will be sampled less frequently). If set to 1, no subsampling will be performed (all sampling probabilities will be 1).", 
            "title": "Sequence Preprocessing"
        }, 
        {
            "location": "/preprocessing/sequence/#pad_sequences", 
            "text": "keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32')  Transform a list of  nb_samples sequences  (lists of scalars) into a 2D numpy array of shape  (nb_samples, nb_timesteps) .  nb_timesteps  is either the  maxlen  argument if provided, or the length of the longest sequence otherwise. Sequences that are shorter than  nb_timesteps  are padded with zeros at the end.    Return : 2D numpy array of shape  (nb_samples, nb_timesteps) .    Arguments :   sequences : List of lists of int or float.  maxlen : None or int. Maximum sequence length, longer sequences are truncated and shorter sequences are padded with zeros at the end.  dtype : datatype of the numpy array returned.  padding : 'pre' or 'post', pad either before or after each sequence.  truncating : 'pre' or 'post', remove values from sequences larger than maxlen either in the beginning or in the end of the sequence  value : float, value to pad the sequences to the desired value.", 
            "title": "pad_sequences"
        }, 
        {
            "location": "/preprocessing/sequence/#skipgrams", 
            "text": "keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, \n    window_size=4, negative_samples=1., shuffle=True, \n    categorical=False, sampling_table=None)  Transforms a sequence of word indexes (list of int) into couples of the form:    (word, word in the same window), with label 1 (positive samples).  (word, random word from the vocabulary), with label 0 (negative samples).   Read more about Skipgram in this gnomic paper by Mikolov et al.:  Efficient Estimation of Word Representations in\nVector Space    Return : tuple  (couples, labels) .    couples  is a list of 2-elements lists of int:  [word_index, other_word_index] .   labels  is a list of 0 and 1, where 1 indicates that  other_word_index  was found in the same window as  word_index , and 0 indicates that  other_word_index  was random.  if categorical is set to True, the labels are categorical, ie. 1 becomes [0,1], and 0 becomes [1, 0].     Arguments :   sequence : list of int indexes. If using a sampling_table, the index of a word should be its the rank in the dataset (starting at 1).  vocabulary_size : int.  window_size : int. maximum distance between two words in a positive couple.  negative_samples : float  = 0. 0 for no negative (=random) samples. 1 for same number as positive samples. etc.  shuffle : boolean. Whether to shuffle the samples.  categorical : boolean. Whether to make the returned labels categorical.  sampling_table : numpy array of shape  (vocabulary_size,)  where  sampling_table[i]  is the probability of sampling the word with index i (assumed to be i-th most common word in the dataset).", 
            "title": "skipgrams"
        }, 
        {
            "location": "/preprocessing/sequence/#make_sampling_table", 
            "text": "keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-5)  Used for generating the  sampling_table  argument for  skipgrams .  sampling_table[i]  is the probability of sampling the word i-th most common word in a dataset (more common words should be sampled less frequently, for balance).    Return : numpy array of shape  (size,) .    Arguments :   size : size of the vocabulary considered.  sampling_factor : lower values result in a longer probability decay (common words will be sampled less frequently). If set to 1, no subsampling will be performed (all sampling probabilities will be 1).", 
            "title": "make_sampling_table"
        }, 
        {
            "location": "/preprocessing/text/", 
            "text": "text_to_word_sequence\n\n\nkeras.preprocessing.text.text_to_word_sequence(text, \n    filters=base_filter(), lower=True, split=\n \n)\n\n\n\n\nSplit a sentence into a list of words.\n\n\n\n\n\n\nReturn\n: List of words (str).\n\n\n\n\n\n\nArguments\n:\n\n\n\n\ntext\n: str.\n\n\nfilters\n: list (or concatenation) of characters to filter out, such as punctuation. Default: base_filter(), includes basic punctuation, tabs, and newlines.\n\n\nlower\n: boolean. Whether to set the text to lowercase.\n\n\nsplit\n: str. Separator for word splitting.\n\n\n\n\n\n\n\n\none_hot\n\n\nkeras.preprocessing.text.one_hot(text, n,\n    filters=base_filter(), lower=True, split=\n \n)\n\n\n\n\nOne-hot encode a text into a list of word indexes in a vocabulary of size n.\n\n\n\n\n\n\nReturn\n: List of integers in [1, n]. Each integer encodes a word (unicity non-guaranteed).\n\n\n\n\n\n\nArguments\n: Same as \ntext_to_word_sequence\n above.\n\n\n\n\nn\n: int. Size of vocabulary.\n\n\n\n\n\n\n\n\nTokenizer\n\n\nkeras.preprocessing.text.Tokenizer(nb_words=None, filters=base_filter(), \n    lower=True, split=\n \n)\n\n\n\n\nClass for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n\n\n\n\n\n\nArguments\n: Same as \ntext_to_word_sequence\n above.\n\n\n\n\nnb_words\n: None or int. Maximum number of words to work with (if set, tokenization will be restricted to the top nb_words most common words in the dataset).\n\n\n\n\n\n\n\n\nMethods\n:\n\n\n\n\n\n\nfit_on_texts(texts)\n: \n\n\n\n\nArguments\n:\n\n\ntexts\n: list of texts to train on.\n\n\n\n\n\n\n\n\n\n\n\n\ntexts_to_sequences(texts)\n\n\n\n\nArguments\n: \n\n\ntexts\n: list of texts to turn to sequences.\n\n\n\n\n\n\nReturn\n: list of sequences (one per text input).\n\n\n\n\n\n\n\n\ntexts_to_sequences_generator(texts)\n: generator version of the above. \n\n\n\n\nReturn\n: yield one sequence per input text.\n\n\n\n\n\n\n\n\ntexts_to_matrix(texts)\n:\n\n\n\n\nReturn\n: numpy array of shape \n(len(texts), nb_words)\n.\n\n\nArguments\n:\n\n\ntexts\n: list of texts to vectorize.\n\n\nmode\n: one of \"binary\", \"count\", \"tfidf\", \"freq\" (default: \"binary\").\n\n\n\n\n\n\n\n\n\n\n\n\nfit_on_sequences(sequences)\n: \n\n\n\n\nArguments\n:\n\n\nsequences\n: list of sequences to train on. \n\n\n\n\n\n\n\n\n\n\n\n\nsequences_to_matrix(sequences)\n:\n\n\n\n\nReturn\n: numpy array of shape \n(len(sequences), nb_words)\n.\n\n\nArguments\n:\n\n\nsequences\n: list of sequences to vectorize.\n\n\nmode\n: one of \"binary\", \"count\", \"tfidf\", \"freq\" (default: \"binary\").\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttributes\n:\n\n\n\n\nword_counts\n: dictionary mapping words (str) to the number of times they appeared on during fit. Only set after fit_on_texts was called. \n\n\nword_docs\n: dictionary mapping words (str) to the number of documents/texts they appeared on during fit. Only set after fit_on_texts was called.\n\n\nword_index\n: dictionary mapping words (str) to their rank/index (int). Only set after fit_on_texts was called.\n\n\ndocument_count\n: int. Number of documents (texts/sequences) the tokenizer was trained on. Only set after fit_on_texts or fit_on_sequences was called.", 
            "title": "Text Preprocessing"
        }, 
        {
            "location": "/preprocessing/text/#text_to_word_sequence", 
            "text": "keras.preprocessing.text.text_to_word_sequence(text, \n    filters=base_filter(), lower=True, split=   )  Split a sentence into a list of words.    Return : List of words (str).    Arguments :   text : str.  filters : list (or concatenation) of characters to filter out, such as punctuation. Default: base_filter(), includes basic punctuation, tabs, and newlines.  lower : boolean. Whether to set the text to lowercase.  split : str. Separator for word splitting.", 
            "title": "text_to_word_sequence"
        }, 
        {
            "location": "/preprocessing/text/#one_hot", 
            "text": "keras.preprocessing.text.one_hot(text, n,\n    filters=base_filter(), lower=True, split=   )  One-hot encode a text into a list of word indexes in a vocabulary of size n.    Return : List of integers in [1, n]. Each integer encodes a word (unicity non-guaranteed).    Arguments : Same as  text_to_word_sequence  above.   n : int. Size of vocabulary.", 
            "title": "one_hot"
        }, 
        {
            "location": "/preprocessing/text/#tokenizer", 
            "text": "keras.preprocessing.text.Tokenizer(nb_words=None, filters=base_filter(), \n    lower=True, split=   )  Class for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).    Arguments : Same as  text_to_word_sequence  above.   nb_words : None or int. Maximum number of words to work with (if set, tokenization will be restricted to the top nb_words most common words in the dataset).     Methods :    fit_on_texts(texts) :    Arguments :  texts : list of texts to train on.       texts_to_sequences(texts)   Arguments :   texts : list of texts to turn to sequences.    Return : list of sequences (one per text input).     texts_to_sequences_generator(texts) : generator version of the above.    Return : yield one sequence per input text.     texts_to_matrix(texts) :   Return : numpy array of shape  (len(texts), nb_words) .  Arguments :  texts : list of texts to vectorize.  mode : one of \"binary\", \"count\", \"tfidf\", \"freq\" (default: \"binary\").       fit_on_sequences(sequences) :    Arguments :  sequences : list of sequences to train on.        sequences_to_matrix(sequences) :   Return : numpy array of shape  (len(sequences), nb_words) .  Arguments :  sequences : list of sequences to vectorize.  mode : one of \"binary\", \"count\", \"tfidf\", \"freq\" (default: \"binary\").         Attributes :   word_counts : dictionary mapping words (str) to the number of times they appeared on during fit. Only set after fit_on_texts was called.   word_docs : dictionary mapping words (str) to the number of documents/texts they appeared on during fit. Only set after fit_on_texts was called.  word_index : dictionary mapping words (str) to their rank/index (int). Only set after fit_on_texts was called.  document_count : int. Number of documents (texts/sequences) the tokenizer was trained on. Only set after fit_on_texts or fit_on_sequences was called.", 
            "title": "Tokenizer"
        }, 
        {
            "location": "/preprocessing/image/", 
            "text": "ImageDataGenerator\n\n\nkeras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n    samplewise_center=False,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=0.,\n    width_shift_range=0.,\n    height_shift_range=0.,\n    shear_range=0.,\n    horizontal_flip=False,\n    vertical_flip=False)\n\n\n\n\nGenerate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely.\n\n\n\n\n\n\nArguments\n:\n\n\n\n\nfeaturewise_center\n: Boolean. Set input mean to 0 over the dataset.\n\n\nsamplewise_center\n: Boolean. Set each sample mean to 0.\n\n\nfeaturewise_std_normalization\n: Boolean. Divide inputs by std of the dataset.\n\n\nsamplewise_std_normalization\n: Boolean. Divide each input by its std.\n\n\nzca_whitening\n: Boolean. Apply ZCA whitening.\n\n\nrotation_range\n: Int. Degree range for random rotations.\n\n\nwidth_shift_range\n: Float (fraction of total width). Range for random horizontal shifts.\n\n\nheight_shift_range\n: Float (fraction of total height). Range for random vertical shifts.\n\n\nshear_range\n: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n\n\nhorizontal_flip\n: Boolean. Randomly flip inputs horizontally.\n\n\nvertical_flip\n: Boolean. Randomly flip inputs vertically.\n\n\n\n\n\n\n\n\nMethods\n:\n\n\n\n\nfit(X)\n: Required if featurewise_center or featurewise_std_normalization or zca_whitening. Compute necessary quantities on some sample data.\n\n\nArguments\n:\n\n\nX\n: sample data.\n\n\naugment\n: Boolean (default: False). Whether to fit on randomly augmented samples.\n\n\nrounds\n: int (default: 1). If augment, how many augmentation passes over the data to use.\n\n\n\n\n\n\n\n\n\n\nflow(X, y)\n:\n\n\nArguments\n:\n\n\nX\n: data.\n\n\ny\n: labels.\n\n\nbatch_size\n: int (default: 32).\n\n\nshuffle\n: boolean (defaut: False).\n\n\nsave_to_dir\n: None or str. This allows you to optimally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).\n\n\nsave_prefix\n: str. Prefix to use for filenames of saved pictures.\n\n\nsave_format\n: one of \"png\", jpeg\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n:\n\n\n\n\n\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data(test_split=0.1)\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n                    samples_per_epoch=len(X_train), nb_epoch=nb_epoch)\n\n# here's a more \nmanual\n example\nfor e in range(nb_epoch):\n    print 'Epoch', e\n    batches = 0\n    for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n        loss = model.train(X_batch, Y_batch)\n        batches += 1\n        if batches \n= len(X_train) / 32:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break", 
            "title": "Image Preprocessing"
        }, 
        {
            "location": "/preprocessing/image/#imagedatagenerator", 
            "text": "keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n    samplewise_center=False,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=0.,\n    width_shift_range=0.,\n    height_shift_range=0.,\n    shear_range=0.,\n    horizontal_flip=False,\n    vertical_flip=False)  Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely.    Arguments :   featurewise_center : Boolean. Set input mean to 0 over the dataset.  samplewise_center : Boolean. Set each sample mean to 0.  featurewise_std_normalization : Boolean. Divide inputs by std of the dataset.  samplewise_std_normalization : Boolean. Divide each input by its std.  zca_whitening : Boolean. Apply ZCA whitening.  rotation_range : Int. Degree range for random rotations.  width_shift_range : Float (fraction of total width). Range for random horizontal shifts.  height_shift_range : Float (fraction of total height). Range for random vertical shifts.  shear_range : Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)  horizontal_flip : Boolean. Randomly flip inputs horizontally.  vertical_flip : Boolean. Randomly flip inputs vertically.     Methods :   fit(X) : Required if featurewise_center or featurewise_std_normalization or zca_whitening. Compute necessary quantities on some sample data.  Arguments :  X : sample data.  augment : Boolean (default: False). Whether to fit on randomly augmented samples.  rounds : int (default: 1). If augment, how many augmentation passes over the data to use.      flow(X, y) :  Arguments :  X : data.  y : labels.  batch_size : int (default: 32).  shuffle : boolean (defaut: False).  save_to_dir : None or str. This allows you to optimally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).  save_prefix : str. Prefix to use for filenames of saved pictures.  save_format : one of \"png\", jpeg\".         Example :    (X_train, y_train), (X_test, y_test) = cifar10.load_data(test_split=0.1)\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n                    samples_per_epoch=len(X_train), nb_epoch=nb_epoch)\n\n# here's a more  manual  example\nfor e in range(nb_epoch):\n    print 'Epoch', e\n    batches = 0\n    for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n        loss = model.train(X_batch, Y_batch)\n        batches += 1\n        if batches  = len(X_train) / 32:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break", 
            "title": "ImageDataGenerator"
        }
    ]
}